{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qADDZYtsvY_"
      },
      "outputs": [],
      "source": [
        "# Install core dependencies\n",
        "!pip install -q numpy scipy matplotlib mpmath\n",
        "\n",
        "# Optional: if your script uses CLI arguments and file access\n",
        "!pip install -q argparse\n",
        "\n",
        "# Optional: for faster file loading or JSON operations (usually pre-installed)\n",
        "!pip install -q orjson\n",
        "\n",
        "# GPU-accelerated FFTs and array ops (for CuPy port version)\n",
        "# Comment this out if using CPU-only mpmath/NumPy version\n",
        "#!pip install -q cupy-cuda11x  # or `cupy-cuda12x` for CUDA 12 Colab runtimes\n",
        "\n",
        "# Make output directory\n",
        "!mkdir -p /content/output\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile proof_colab.py\n",
        "import os\n",
        "try:\n",
        "    import cupy as cp\n",
        "    from cupy.fft import fftn, ifftn\n",
        "    gpu_mode = True\n",
        "    print(\"Using CuPy (GPU) for arrays and FFTs\")\n",
        "except ImportError:\n",
        "    import numpy as cp\n",
        "    from numpy.fft import fftn, ifftn\n",
        "    gpu_mode = False\n",
        "    print(\"CuPy not found! Using CPU fallback; performance will be slow.\")\n",
        "\n",
        "import numpy as np\n",
        "import argparse, sys, json\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "import matplotlib.pyplot as plt\n",
        "import hashlib\n",
        "\n",
        "# --- Interval arithmetic emulation: (mid, width) floats --- #\n",
        "def interval(x, w=0.0):\n",
        "    return (float(x), float(w))\n",
        "\n",
        "def ia_add(a, b):\n",
        "    return (a[0] + b[0], a[1] + b[1])\n",
        "\n",
        "def ia_sub(a, b):\n",
        "    return (a[0] - b[0], a[1] + b[1])\n",
        "\n",
        "def ia_mul(a, b):\n",
        "    m = a[0] * b[0]\n",
        "    r = abs(a[0]) * b[1] + abs(b[0]) * a[1] + a[1] * b[1]\n",
        "    return (m, r)\n",
        "\n",
        "def ia_div(a, b):\n",
        "    if b[0] == 0:\n",
        "        return (0, 1e16)\n",
        "    m = a[0]/b[0]\n",
        "    r = abs(m)*(a[1]/abs(a[0] + 1e-20) + b[1]/abs(b[0] + 1e-20))\n",
        "    return (m, r)\n",
        "\n",
        "def ia_pow(a, expo):\n",
        "    m = a[0]**expo\n",
        "    if abs(a[0]) > 1e-10:\n",
        "        r = abs(expo)*abs(a[0])**(expo - 1)*a[1]\n",
        "    else:\n",
        "        r = a[1]\n",
        "    return (m, r)\n",
        "\n",
        "def ia_abs(a):\n",
        "    return (abs(a[0]), a[1])\n",
        "\n",
        "def ia_max(arr):\n",
        "    if len(arr) == 0:\n",
        "        return (0, 0)\n",
        "    m = max([x[0] for x in arr])\n",
        "    r = max([x[1] for x in arr])\n",
        "    return (m, r)\n",
        "\n",
        "def ia_sum(arr):\n",
        "    if len(arr) == 0:\n",
        "        return (0, 0)\n",
        "    m = sum([x[0] for x in arr])\n",
        "    r = sum([x[1] for x in arr])\n",
        "    return (m, r)\n",
        "\n",
        "def ia_mean(arr):\n",
        "    if len(arr) == 0:\n",
        "        return (0, 0)\n",
        "    m = sum([x[0] for x in arr]) / len(arr)\n",
        "    r = sum([x[1] for x in arr]) / len(arr)\n",
        "    return (m, r)\n",
        "\n",
        "def interval_repr(a):\n",
        "    return f\"{a[0]:.6g} ± {a[1]:.2e}\"\n",
        "\n",
        "# --- Dyadic filter FFT tools --- #\n",
        "def fftfreq(N):\n",
        "    return cp.fft.fftfreq(N) * N\n",
        "\n",
        "def dyadic_filter(N, j):\n",
        "    kx, ky, kz = [fftfreq(N)]*3\n",
        "    Kx, Ky, Kz = cp.meshgrid(kx, ky, kz, indexing='ij')\n",
        "    k_mag = cp.sqrt(Kx**2 + Ky**2 + Kz**2)\n",
        "    low, high = 2**j, 2**(j+1)\n",
        "    mask = (k_mag >= low) & (k_mag < high)\n",
        "    return mask.astype(cp.float32)\n",
        "\n",
        "# --- Field generation --- #\n",
        "def make_vortex_tube(N, amplitude=1.0, core_radius=None):\n",
        "    X, Y, Z = cp.meshgrid(cp.arange(N), cp.arange(N), cp.arange(N), indexing='ij')\n",
        "    xc, yc = N/2, N/2\n",
        "    r = cp.sqrt((X - xc)**2 + (Y - yc)**2)\n",
        "    if core_radius is None:\n",
        "        core_radius = N/16\n",
        "    omega = cp.zeros((3, N, N, N), dtype=cp.float32)\n",
        "    tube = amplitude * cp.exp(-r**2 / (2*core_radius**2))\n",
        "    phi = cp.arctan2(Y - yc, X - xc)\n",
        "    # swirl\n",
        "    omega[0] = -tube * cp.sin(phi)\n",
        "    omega[1] = tube * cp.cos(phi)\n",
        "    return omega\n",
        "\n",
        "def make_shell_localized(N, j, amplitude=1.0, seed=0):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    fft_field = cp.zeros((3, N, N, N), dtype=cp.complex64)\n",
        "    mask = dyadic_filter(N, j)\n",
        "    for c in range(3):\n",
        "        random_phase = cp.asarray(np.exp(1j * 2*np.pi * rng.random((N,N,N))))\n",
        "        random_mag = cp.asarray(rng.normal(0,1,(N,N,N)))\n",
        "        fft_field[c] = mask * amplitude * random_phase * random_mag\n",
        "\n",
        "    kx = fftfreq(N)\n",
        "    ky = fftfreq(N)\n",
        "    kz = fftfreq(N)\n",
        "    Kx, Ky, Kz = cp.meshgrid(kx, ky, kz, indexing='ij')\n",
        "    K = cp.array([Kx, Ky, Kz])\n",
        "\n",
        "    # Project out divergence\n",
        "    for idx in cp.ndindex((N, N, N)):\n",
        "        kvec = K[:, idx[0], idx[1], idx[2]]\n",
        "        if cp.linalg.norm(kvec) < 1e-8:\n",
        "            continue\n",
        "        omega_here = fft_field[:, idx[0], idx[1], idx[2]]\n",
        "        proj = cp.dot(omega_here, kvec) / (cp.dot(kvec, kvec) + 1e-15)\n",
        "        fft_field[:, idx[0], idx[1], idx[2]] -= proj * kvec\n",
        "\n",
        "    # channel-by-channel inverse FFT\n",
        "    field = cp.zeros((3, N, N, N), dtype=cp.float32)\n",
        "    for c in range(3):\n",
        "        field[c] = cp.real(ifftn(fft_field[c], axes=(0,1,2)))\n",
        "    return field\n",
        "\n",
        "def make_boundary_layer(N, amplitude=1.0, thickness=None):\n",
        "    if thickness is None:\n",
        "        thickness = N/16\n",
        "    X = cp.arange(N).reshape(N,1,1)\n",
        "    profile = amplitude * cp.exp(-((X - N//8)**2) / (2*thickness**2))\n",
        "    omega = cp.zeros((3,N,N,N), dtype=cp.float32)\n",
        "    omega[2] = cp.tile(profile, (1,N,N))\n",
        "    return omega\n",
        "\n",
        "# --- Chunked / channel-wise transforms to reduce memory usage --- #\n",
        "def chunked_fftn(data_4d):\n",
        "    \"\"\"\n",
        "    Perform an FFT channel by channel to reduce peak memory usage.\n",
        "    data_4d shape: (C, Nx, Nx, Nx)\n",
        "    returns same shape, but complex\n",
        "    \"\"\"\n",
        "    C = data_4d.shape[0]\n",
        "    out = cp.zeros_like(data_4d, dtype=cp.complex64)\n",
        "    for c in range(C):\n",
        "        out[c] = fftn(data_4d[c], axes=(0,1,2))\n",
        "    return out\n",
        "\n",
        "def chunked_ifftn(data_4d):\n",
        "    \"\"\"\n",
        "    Perform an inverse FFT channel by channel to reduce peak memory usage.\n",
        "    data_4d shape: (C, Nx, Nx, Nx)\n",
        "    returns same shape, but real\n",
        "    \"\"\"\n",
        "    C = data_4d.shape[0]\n",
        "    out = cp.zeros((C,) + data_4d.shape[1:], dtype=cp.float32)\n",
        "    for c in range(C):\n",
        "        out[c] = cp.real(ifftn(data_4d[c], axes=(0,1,2)))\n",
        "    return out\n",
        "\n",
        "# --- Biot-Savart and derivatives --- #\n",
        "def biot_savart(omega, verbose=True):\n",
        "    N = omega.shape[1]\n",
        "    omega_hat = chunked_fftn(omega)\n",
        "\n",
        "    kx, ky, kz = [fftfreq(N)]*3\n",
        "    Kx, Ky, Kz = cp.meshgrid(kx, ky, kz, indexing='ij')\n",
        "    k2 = Kx**2 + Ky**2 + Kz**2 + 1e-10\n",
        "    u_hat = cp.zeros_like(omega_hat, dtype=cp.complex64)\n",
        "\n",
        "    # cross-product in freq domain\n",
        "    u_hat[0] = (1j * (Ky*omega_hat[2] - Kz*omega_hat[1])) / k2\n",
        "    u_hat[1] = (1j * (Kz*omega_hat[0] - Kx*omega_hat[2])) / k2\n",
        "    u_hat[2] = (1j * (Kx*omega_hat[1] - Ky*omega_hat[0])) / k2\n",
        "\n",
        "    u = chunked_ifftn(u_hat)\n",
        "\n",
        "    # check divergence\n",
        "    divu_hat = (\n",
        "        1j * Kx * chunked_fftn(u[0:1])[0] +\n",
        "        1j * Ky * chunked_fftn(u[1:2])[0] +\n",
        "        1j * Kz * chunked_fftn(u[2:3])[0]\n",
        "    )\n",
        "    divu = cp.real(ifftn(divu_hat, axes=(0,1,2)))\n",
        "    maxdiv = float(cp.abs(divu).max())\n",
        "    if verbose:\n",
        "        print(f\"[biot_savart] max|div u| = {maxdiv:.2e}\")\n",
        "\n",
        "    return u\n",
        "\n",
        "def compute_gradients(u):\n",
        "    # shape u = (3, N, N, N)\n",
        "    N = u.shape[1]\n",
        "    u_hat = chunked_fftn(u)\n",
        "    kx, ky, kz = [fftfreq(N)]*3\n",
        "    Kx, Ky, Kz = cp.meshgrid(kx, ky, kz, indexing='ij')\n",
        "    K = cp.array([Kx, Ky, Kz])\n",
        "\n",
        "    grad_u = cp.zeros((3,3,N,N,N), dtype=cp.float32)\n",
        "    for alpha in range(3):\n",
        "        for beta in range(3):\n",
        "            tmp = 1j * K[beta] * u_hat[alpha]\n",
        "            grad_comp = cp.real(ifftn(tmp, axes=(0,1,2)))\n",
        "            grad_u[alpha, beta] = grad_comp.astype(cp.float32)\n",
        "    return grad_u\n",
        "\n",
        "def compute_strain(grad_u):\n",
        "    # grad_u shape = (3,3,N,N,N)\n",
        "    return 0.5 * (grad_u + cp.transpose(grad_u, (1,0,2,3,4)))\n",
        "\n",
        "# --- Batched principal strain computation --- #\n",
        "def principal_strain_evectors(S, batch_size=16384):\n",
        "    # S shape = (3,3,N,N,N), symmetrical\n",
        "    N = S.shape[2]\n",
        "    S_batched = S.transpose(2,3,4,0,1).reshape(-1,3,3).astype(cp.float32)\n",
        "    # ensure symmetrical\n",
        "    S_batched = 0.5 * (S_batched + cp.transpose(S_batched, (0,2,1)))\n",
        "    total = S_batched.shape[0]\n",
        "    out = cp.empty((total, 3), dtype=cp.float32)\n",
        "    for start in range(0, total, batch_size):\n",
        "        stop = min(start + batch_size, total)\n",
        "        sb = S_batched[start:stop]\n",
        "        if cp.all(sb == 0):\n",
        "            out[start:stop, :] = 0.\n",
        "            out[start:stop, 0] = 1.\n",
        "            continue\n",
        "        try:\n",
        "            vals, vecs = cp.linalg.eigh(sb)\n",
        "            pv = vecs[:,:,-1]\n",
        "            pv_norm = cp.linalg.norm(pv, axis=1, keepdims=True)\n",
        "            pv = pv / (pv_norm + 1e-30)\n",
        "            out[start:stop, :] = pv\n",
        "        except Exception as e:\n",
        "            print(f\"Eigen failure on batch {start}:{stop}: {e}\")\n",
        "            out[start:stop, :] = 0.\n",
        "            out[start:stop, 0] = 1.\n",
        "    e1 = out.T.reshape(3, N, N, N)\n",
        "    return e1\n",
        "\n",
        "# --- Filter with chunked FFT to reduce memory usage --- #\n",
        "def apply_dyadic_filter(vort, mask):\n",
        "    # vort shape: (3,N,N,N); mask shape: (N,N,N)\n",
        "    out = cp.zeros_like(vort)\n",
        "    for c in range(3):\n",
        "        v_hat = fftn(vort[c], axes=(0,1,2))\n",
        "        out_hat = v_hat * mask\n",
        "        out[c] = cp.real(ifftn(out_hat, axes=(0,1,2)))\n",
        "        del v_hat, out_hat\n",
        "        cp.get_default_memory_pool().free_all_blocks()\n",
        "    return out\n",
        "\n",
        "def linf_norm(arr):\n",
        "    return float(cp.abs(arr).max())\n",
        "\n",
        "def shell_norm_interval(omega_j):\n",
        "    v = cp.abs(omega_j)\n",
        "    maxval = float(v.max())\n",
        "    esterr = 1e-7 * maxval\n",
        "    return (maxval, esterr)\n",
        "\n",
        "def vorticity_rhs(omega, nu):\n",
        "    u = biot_savart(omega, verbose=False)\n",
        "    grad_u = compute_gradients(u)\n",
        "    stretch = cp.zeros_like(omega)\n",
        "    for alpha in range(3):\n",
        "        for beta in range(3):\n",
        "            stretch[alpha] += omega[beta] * grad_u[alpha,beta]\n",
        "\n",
        "    # diffusion\n",
        "    omega_hat = chunked_fftn(omega)\n",
        "    N = omega.shape[1]\n",
        "    kx, ky, kz = [fftfreq(N)]*3\n",
        "    Kx, Ky, Kz = cp.meshgrid(kx, ky, kz, indexing='ij')\n",
        "    k2 = Kx**2 + Ky**2 + Kz**2\n",
        "    laplacian = cp.zeros_like(omega)\n",
        "    for c in range(3):\n",
        "        laplacian_hat = -k2 * omega_hat[c]\n",
        "        laplacian[c] = cp.real(ifftn(laplacian_hat, axes=(0,1,2)))\n",
        "        del laplacian_hat\n",
        "        cp.get_default_memory_pool().free_all_blocks()\n",
        "\n",
        "    return nu*laplacian + stretch\n",
        "\n",
        "def time_evolve(omega, nu, dt):\n",
        "    return omega + dt * vorticity_rhs(omega, nu)\n",
        "\n",
        "# ---- Main compute function --- #\n",
        "def main_compute(omega_t, omega_tpdt, grad_u, alpha, nu,\n",
        "                 j_min, j_max, dt, eps, plot=False, validate=False, context='mainrun'):\n",
        "    N = omega_t.shape[1]\n",
        "    shells = list(range(j_min, j_max + 1))\n",
        "    per_shell = {}\n",
        "    norm_mids, norm_wds, align_mids, align_wds = [], [], [], []\n",
        "\n",
        "    if grad_u is None:\n",
        "        print(\"  (Computing velocity and grad_u from vorticity via Biot-Savart)\")\n",
        "        u = biot_savart(omega_t)\n",
        "        grad_u = compute_gradients(u)\n",
        "\n",
        "    S = compute_strain(grad_u)\n",
        "    e1 = principal_strain_evectors(S)\n",
        "\n",
        "    for j in shells:\n",
        "        mask = dyadic_filter(N, j)\n",
        "        omega_j = apply_dyadic_filter(omega_t, mask)\n",
        "        if cp.all(cp.abs(omega_j) < 1e-12):\n",
        "            norm_j = (0.0, 0.0)\n",
        "            align_j = (0.0, 0.0)\n",
        "        else:\n",
        "            norms = cp.sqrt(cp.sum(omega_j**2, axis=0))\n",
        "            maxval = float(norms.max())\n",
        "            esterr = 1e-7 * maxval\n",
        "            norm_j = (maxval, esterr)\n",
        "            norms_flat = norms.ravel()\n",
        "            w_dot_e_flat = cp.sum(omega_j*e1, axis=0).ravel()\n",
        "            selector = (norms_flat > eps)\n",
        "            if cp.any(selector):\n",
        "                num = w_dot_e_flat[selector]\n",
        "                denom = norms_flat[selector] + 1e-30\n",
        "                ratios = cp.abs(num / denom)\n",
        "                ratios_np = cp.asnumpy(ratios)\n",
        "                aligns = [(float(r), 1e-7*float(r)) for r in ratios_np]\n",
        "                align_j = ia_mean(aligns)\n",
        "            else:\n",
        "                align_j = (0.0, 0.0)\n",
        "        per_shell[j] = {'norm': norm_j, 'align': align_j}\n",
        "        norm_mids.append(norm_j[0])\n",
        "        norm_wds.append(norm_j[1])\n",
        "        align_mids.append(align_j[0])\n",
        "        align_wds.append(align_j[1])\n",
        "\n",
        "    Y = ia_sum([\n",
        "        ia_mul((2**(alpha*j),0), s['norm'])\n",
        "        for j,s in per_shell.items()\n",
        "    ])\n",
        "    align_sup = ia_max([s['align'] for s in per_shell.values()])\n",
        "\n",
        "    if omega_tpdt is not None:\n",
        "        per_shell_p = []\n",
        "        for j in shells:\n",
        "            mask = dyadic_filter(N, j)\n",
        "            omega_j_p = apply_dyadic_filter(omega_tpdt, mask)\n",
        "            if cp.all(cp.abs(omega_j_p) < 1e-12):\n",
        "                norm_j_p = (0.0, 0.0)\n",
        "            else:\n",
        "                norm_j_p = shell_norm_interval(omega_j_p)\n",
        "            per_shell_p.append(ia_mul((2**(alpha*j),0), norm_j_p))\n",
        "        Y_p = ia_sum(per_shell_p)\n",
        "        dYdt = ia_div(ia_sub(Y_p, Y), (dt,0))\n",
        "    else:\n",
        "        dYdt = None\n",
        "\n",
        "    delta = 2.0 / alpha\n",
        "    Lambda = 2.0**alpha\n",
        "    C_B, C_P, C_C, C_R, C_overlap = 32.0, 2.0, 4.0, 1.73205, 3.0\n",
        "    C_nl = C_B * C_P * C_C * C_R * C_overlap\n",
        "\n",
        "    if dYdt is not None:\n",
        "        Ysq = ia_mul(Y, Y)\n",
        "        Ypow = ia_pow(Y, 1 + delta)\n",
        "        rhs1 = ia_mul((C_nl,0), ia_mul(Ysq, align_sup))\n",
        "        rhs2 = ia_mul((nu * Lambda,0), Ypow)\n",
        "        rhs = ia_sub(rhs1, rhs2)\n",
        "        holds = dYdt[0] + dYdt[1] <= rhs[0] - rhs[1]\n",
        "    else:\n",
        "        rhs = None\n",
        "        holds = None\n",
        "\n",
        "    diagnostics = {\n",
        "        'context': context,\n",
        "        'shells': [\n",
        "            {'j': int(j),\n",
        "             'norm': interval_repr(per_shell[j]['norm']),\n",
        "             'align': interval_repr(per_shell[j]['align'])}\n",
        "            for j in shells\n",
        "        ],\n",
        "        'Y': interval_repr(Y),\n",
        "        'align_sup': interval_repr(align_sup),\n",
        "        'delta': delta,\n",
        "        'Lambda': Lambda,\n",
        "        'C_nl': C_nl,\n",
        "        'dYdt': interval_repr(dYdt) if dYdt is not None else \"\",\n",
        "        'RHS': interval_repr(rhs) if rhs is not None else \"\",\n",
        "        'holds': holds,\n",
        "        '_entropic_per_shell': [\n",
        "            dict(j=int(j), norm=per_shell[j]['norm'])\n",
        "            for j in shells\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    print(f\"\\nRecursive norm Y(t):          {diagnostics['Y']}\")\n",
        "    print(f\"sup_j alignment:              {diagnostics['align_sup']}\")\n",
        "    if dYdt is not None:\n",
        "        print(f\"dY/dt:                        {diagnostics['dYdt']}\")\n",
        "        print(f\"RHS:                          {diagnostics['RHS']}\")\n",
        "        if holds:\n",
        "            print(\"[Inequality verified]: This timestep is within bounds.\\n\")\n",
        "        else:\n",
        "            print(\"!!! WARNING: Inequality violated (with certified intervals) !!!\\n\")\n",
        "    else:\n",
        "        print(\"dY/dt not available (only single time). No inequality check.\")\n",
        "\n",
        "    if plot:\n",
        "        fig, axs = plt.subplots(2,1,figsize=(7,6), sharex=True)\n",
        "        axs[0].bar(shells, norm_mids, yerr=norm_wds, capsize=5)\n",
        "        axs[0].set_ylabel(r\"$\\|\\Delta_j\\omega\\|_{L^\\infty}$\")\n",
        "        axs[1].bar(shells, align_mids, yerr=align_wds, capsize=5)\n",
        "        axs[1].set_ylabel(r\"$\\mathcal{A}_j$\")\n",
        "        axs[1].set_xlabel('Shell $j$')\n",
        "        plt.suptitle(\"Per-shell norms and alignments\")\n",
        "        plt.tight_layout()\n",
        "        fig.savefig(f\"/content/output/per_shell_{context}.png\")\n",
        "\n",
        "        if dYdt is not None:\n",
        "            plt.figure()\n",
        "            plt.bar([\"dY/dt\",\"RHS\"], [dYdt[0], rhs[0]], yerr=[dYdt[1], rhs[1]], capsize=8)\n",
        "            plt.title(\"Recursive damping inequality: LHS vs RHS\\n(mid ± width)\")\n",
        "            plt.savefig(f\"/content/output/inequality_{context}.png\")\n",
        "\n",
        "    with open(f\"/content/output/diagnostics_log_{context}.json\",'w', encoding=\"utf-8\") as f:\n",
        "        json.dump(diagnostics, f, indent=2)\n",
        "\n",
        "    return {\n",
        "        'holds': holds,\n",
        "        'dYdt': dYdt,\n",
        "        'rhs': rhs,\n",
        "        'Y': Y,\n",
        "        'align_sup': align_sup,\n",
        "        'delta': delta,\n",
        "        'Lambda': Lambda,\n",
        "        'C_nl': C_nl,\n",
        "        '_entropic_per_shell': [\n",
        "            dict(j=int(j), norm=per_shell[j]['norm'])\n",
        "            for j in shells\n",
        "        ]\n",
        "    }, diagnostics\n",
        "\n",
        "def export_certificate(fname, dYdt, rhs, C_nl, delta, Lambda, Y, align_sup):\n",
        "    lines = []\n",
        "    lines.append(\"-- Certified Clay-Companion Recursive Inequality Certificate --\")\n",
        "    lines.append(f\"-- C_nl = {C_nl}\")\n",
        "    lines.append(f\"-- delta = {delta}\")\n",
        "    lines.append(f\"-- Lambda = {Lambda}\")\n",
        "    lines.append(f\"-- Y = {Y}\")\n",
        "    lines.append(f\"-- align_sup = {align_sup}\")\n",
        "    lines.append(f\"-- Computed (LHS = dY/dt): {dYdt[0]} ± {dYdt[1]}\")\n",
        "    lines.append(f\"-- Computed (RHS):          {rhs[0]} ± {rhs[1]}\")\n",
        "    lines.append(\"theorem verified_t0 : dYdt ≤ RHS := by float_solver\")\n",
        "    # Note: Use encoding=\"utf-8\" to avoid Unicode issues with \"±\".\n",
        "    with open(fname, \"w\", encoding=\"utf-8\") as f:\n",
        "        for L in lines:\n",
        "            f.write(L + '\\n')\n",
        "    print(f\"Wrote Lean-style proof certificate to {fname}\")\n",
        "\n",
        "def validate_damping_terms(Y, dYdt, rhs, align_sup, delta, Lambda, C_nl):\n",
        "    assert isinstance(Y, tuple) and isinstance(dYdt, tuple) and isinstance(rhs, tuple), \\\n",
        "        \"Y, dY/dt, and rhs must be interval tuples\"\n",
        "    assert align_sup[0] <= 1.0 + 1e-6, f\"Alignment factor exceeds 1 (align_sup={align_sup[0]})\"\n",
        "    assert Lambda > 1.0, f\"Lambda must be > 1 (Lambda={Lambda})\"\n",
        "    assert delta > 0.0, f\"delta must be positive (delta={delta})\"\n",
        "    assert C_nl > 0.0, f\"C_nl must be positive (C_nl={C_nl})\"\n",
        "    assert rhs[0] >= 0 or abs(rhs[0]) < 1e-5, f\"RHS is negative ({rhs[0]:.2e}), implies anti-damping\"\n",
        "    # We expect dY/dt to be non-positive in a damping scenario\n",
        "    assert dYdt[0] < 0, f\"dY/dt is positive ({dYdt[0]:.2e}) - unexpected growth\"\n",
        "    return True\n",
        "\n",
        "def compute_entropy(shells):\n",
        "    H = 0.0\n",
        "    for s in shells:\n",
        "        if isinstance(s['norm'], str):\n",
        "            # Convert from \"a ± b\" format if encountered\n",
        "            parts = s['norm'].split('±')\n",
        "            mid = float(parts[0].strip())\n",
        "        else:\n",
        "            mid = s['norm'][0]\n",
        "        if mid > 0:\n",
        "            H += mid * np.log(mid)\n",
        "    return H\n",
        "\n",
        "def save_forensic_failure(timestep, omega, Y, dYdt, rhs, align_sup, folder=\"/content/output\"):\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "    hash_key = hashlib.md5(str((Y, dYdt, rhs, align_sup)).encode()).hexdigest()[:12]\n",
        "    try:\n",
        "        cp.save(f\"{folder}/counterexample_t{timestep:03d}.npy\", omega)\n",
        "    except Exception:\n",
        "        np.save(f\"{folder}/counterexample_t{timestep:03d}.npy\", cp.asnumpy(omega))\n",
        "    with open(f\"{folder}/failure_log_t{timestep:03d}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(f\"FAILURE HASH: {hash_key}\\n\")\n",
        "        f.write(f\"Y(t): {Y}\\n\")\n",
        "        f.write(f\"dY/dt: {dYdt}\\n\")\n",
        "        f.write(f\"RHS: {rhs}\\n\")\n",
        "        f.write(f\"align_sup: {align_sup}\\n\")\n",
        "\n",
        "def float_sanity_check(intervals):\n",
        "    warnings = []\n",
        "    for name, val in intervals.items():\n",
        "        if val is None:\n",
        "            continue\n",
        "        if abs(val[0]) > 1e-12 and val[1]/abs(val[0]) > 1e-2:\n",
        "            warnings.append(f\"⚠️ Interval {name} is unstable: {val[0]:.5g} ± {val[1]:.2e}\")\n",
        "    return warnings\n",
        "\n",
        "# --- Additional test routines --- #\n",
        "def stress_commutator(N=64, alpha=2.5, j_min=2, j_max=6,\n",
        "                      dt=1e-4, timesteps=1, strict=False,\n",
        "                      plot=False, run_validation_checks=False,\n",
        "                      nu=0.01, export_cert=False, eps=1e-10):\n",
        "    \"\"\"\n",
        "    Commutator test: Injects j=2 and j=5 shells to check nonlinear 'leakage' between scales.\n",
        "    Demonstrates a scenario for short-time stepping with multiple shells.\n",
        "    \"\"\"\n",
        "    print(\"[commutator test] j_min={}, j_max={}, timesteps={}\".format(j_min, j_max, timesteps))\n",
        "    omega = make_shell_localized(N, j=2) + make_shell_localized(N, j=5)\n",
        "    for t in range(timesteps):\n",
        "        context = f\"commutator_test_t{t}\"\n",
        "        omega_next = time_evolve(omega, nu, dt)\n",
        "        # Usually we do the same analysis as main_compute:\n",
        "        res, diagnostics = main_compute(\n",
        "            omega, omega_next,\n",
        "            grad_u=None,\n",
        "            alpha=alpha,\n",
        "            nu=nu,\n",
        "            j_min=j_min,\n",
        "            j_max=j_max,\n",
        "            dt=dt,\n",
        "            eps=eps,\n",
        "            plot=plot,\n",
        "            validate=run_validation_checks,\n",
        "            context=context\n",
        "        )\n",
        "\n",
        "        if run_validation_checks:\n",
        "            try:\n",
        "                validate_damping_terms(\n",
        "                    res['Y'], res['dYdt'], res['rhs'],\n",
        "                    res['align_sup'], res['delta'],\n",
        "                    res['Lambda'], res['C_nl']\n",
        "                )\n",
        "            except AssertionError as e:\n",
        "                print(f\"[VALIDATION ERROR] {e}\")\n",
        "                save_forensic_failure(\n",
        "                    timestep=t,\n",
        "                    omega=omega,\n",
        "                    Y=res['Y'],\n",
        "                    dYdt=res['dYdt'],\n",
        "                    rhs=res['rhs'],\n",
        "                    align_sup=res['align_sup']\n",
        "                )\n",
        "                if strict:\n",
        "                    sys.exit(1)\n",
        "\n",
        "            w = float_sanity_check({\n",
        "                'Y': res['Y'],\n",
        "                'dY/dt': res['dYdt'],\n",
        "                'RHS': res['rhs'],\n",
        "                'align_sup': res['align_sup']\n",
        "            })\n",
        "            for ww in w:\n",
        "                print(ww)\n",
        "\n",
        "        if export_cert and (res['dYdt'] is not None) and (res['rhs'] is not None):\n",
        "            export_certificate(\n",
        "                f\"/content/output/certificate_{context}.lean\",\n",
        "                res['dYdt'],\n",
        "                res['rhs'],\n",
        "                res['C_nl'],\n",
        "                res['delta'],\n",
        "                res['Lambda'],\n",
        "                res['Y'],\n",
        "                res['align_sup']\n",
        "            )\n",
        "\n",
        "        if strict and res['holds'] is False:\n",
        "            print(\"FAIL: Damping inequality violated in commutator test at step\", t)\n",
        "            save_forensic_failure(\n",
        "                timestep=t,\n",
        "                omega=omega,\n",
        "                Y=res['Y'],\n",
        "                dYdt=res['dYdt'],\n",
        "                rhs=res['rhs'],\n",
        "                align_sup=res['align_sup']\n",
        "            )\n",
        "            sys.exit(1)\n",
        "\n",
        "        omega = omega_next.copy()\n",
        "\n",
        "    print(\"[commutator test] Completed.\")\n",
        "\n",
        "def simulate_blowup(N=64, alpha=2.5, j_min=1, j_max=5,\n",
        "                    dt=1e-4, timesteps=1, strict=False,\n",
        "                    plot=False, run_validation_checks=False,\n",
        "                    nu=0.01, export_cert=False, eps=1e-10):\n",
        "    \"\"\"\n",
        "    Blowup test: Force alignment near 1 to simulate a worst-case growth scenario.\n",
        "    \"\"\"\n",
        "    print(\"[blowup test] j_min={}, j_max={}, timesteps={}\".format(j_min, j_max, timesteps))\n",
        "    # Make a strong vortex tube, then forcibly align it\n",
        "    omega = make_vortex_tube(N) * 10.0\n",
        "    e1 = cp.ones_like(omega)\n",
        "    # Force full alignment\n",
        "    norms = cp.sqrt(cp.sum(omega**2, axis=0, keepdims=True))\n",
        "    omega = e1 * norms\n",
        "\n",
        "    for t in range(timesteps):\n",
        "        context = f\"blowup_test_t{t}\"\n",
        "        omega_next = time_evolve(omega, nu, dt)\n",
        "        res, diagnostics = main_compute(\n",
        "            omega, omega_next,\n",
        "            grad_u=None,\n",
        "            alpha=alpha,\n",
        "            nu=nu,\n",
        "            j_min=j_min,\n",
        "            j_max=j_max,\n",
        "            dt=dt,\n",
        "            eps=eps,\n",
        "            plot=plot,\n",
        "            validate=run_validation_checks,\n",
        "            context=context\n",
        "        )\n",
        "\n",
        "        if run_validation_checks:\n",
        "            try:\n",
        "                validate_damping_terms(\n",
        "                    res['Y'], res['dYdt'], res['rhs'],\n",
        "                    res['align_sup'], res['delta'],\n",
        "                    res['Lambda'], res['C_nl']\n",
        "                )\n",
        "            except AssertionError as e:\n",
        "                print(f\"[VALIDATION ERROR] {e}\")\n",
        "                save_forensic_failure(\n",
        "                    timestep=t,\n",
        "                    omega=omega,\n",
        "                    Y=res['Y'],\n",
        "                    dYdt=res['dYdt'],\n",
        "                    rhs=res['rhs'],\n",
        "                    align_sup=res['align_sup']\n",
        "                )\n",
        "                if strict:\n",
        "                    sys.exit(1)\n",
        "\n",
        "            w = float_sanity_check({\n",
        "                'Y': res['Y'],\n",
        "                'dY/dt': res['dYdt'],\n",
        "                'RHS': res['rhs'],\n",
        "                'align_sup': res['align_sup']\n",
        "            })\n",
        "            for ww in w:\n",
        "                print(ww)\n",
        "\n",
        "        if export_cert and (res['dYdt'] is not None) and (res['rhs'] is not None):\n",
        "            export_certificate(\n",
        "                f\"/content/output/certificate_{context}.lean\",\n",
        "                res['dYdt'],\n",
        "                res['rhs'],\n",
        "                res['C_nl'],\n",
        "                res['delta'],\n",
        "                res['Lambda'],\n",
        "                res['Y'],\n",
        "                res['align_sup']\n",
        "            )\n",
        "\n",
        "        if strict and res['holds'] is False:\n",
        "            print(\"FAIL: Damping inequality violated in blowup test at step\", t)\n",
        "            save_forensic_failure(\n",
        "                timestep=t,\n",
        "                omega=omega,\n",
        "                Y=res['Y'],\n",
        "                dYdt=res['dYdt'],\n",
        "                rhs=res['rhs'],\n",
        "                align_sup=res['align_sup']\n",
        "            )\n",
        "            sys.exit(1)\n",
        "\n",
        "        omega = omega_next.copy()\n",
        "\n",
        "    print(\"[blowup test] Completed.\")\n",
        "\n",
        "def time_reverse_test(N=64, alpha=2.5, j_min=2, j_max=5,\n",
        "                      dt=1e-4, timesteps=1, strict=False,\n",
        "                      plot=False, run_validation_checks=False,\n",
        "                      nu=0.01, export_cert=False, eps=1e-10):\n",
        "    \"\"\"\n",
        "    Time reversal test: forward and backward time evolution to check\n",
        "    reversibility of the solver.\n",
        "    \"\"\"\n",
        "    print(\"[time reversal test] j_min={}, j_max={}, timesteps={}\".format(j_min, j_max, timesteps))\n",
        "    omega_t = make_vortex_tube(N)\n",
        "    # We only do a single forward/back step to test reversibility (or repeat if timesteps>1).\n",
        "    for t in range(timesteps):\n",
        "        omega_tpdt = time_evolve(omega_t, nu, dt)\n",
        "        omega_back = time_evolve(omega_tpdt, nu, -dt)\n",
        "        err = float(cp.abs(omega_back - omega_t).max())\n",
        "        print(f\"[time reverse] Step={t}, forward->back error = {err:.3e}\")\n",
        "\n",
        "        # We can still run main_compute if we like, but typically this test is about reversibility.\n",
        "        res, diagnostics = main_compute(\n",
        "            omega_t, omega_tpdt,\n",
        "            grad_u=None,\n",
        "            alpha=alpha,\n",
        "            nu=nu,\n",
        "            j_min=j_min,\n",
        "            j_max=j_max,\n",
        "            dt=dt,\n",
        "            eps=eps,\n",
        "            plot=plot,\n",
        "            validate=run_validation_checks,\n",
        "            context=f\"time_reverse_t{t}\"\n",
        "        )\n",
        "\n",
        "        if run_validation_checks:\n",
        "            try:\n",
        "                validate_damping_terms(\n",
        "                    res['Y'], res['dYdt'], res['rhs'],\n",
        "                    res['align_sup'], res['delta'],\n",
        "                    res['Lambda'], res['C_nl']\n",
        "                )\n",
        "            except AssertionError as e:\n",
        "                print(f\"[VALIDATION ERROR] {e}\")\n",
        "                save_forensic_failure(\n",
        "                    timestep=t,\n",
        "                    omega=omega_t,\n",
        "                    Y=res['Y'],\n",
        "                    dYdt=res['dYdt'],\n",
        "                    rhs=res['rhs'],\n",
        "                    align_sup=res['align_sup']\n",
        "                )\n",
        "                if strict:\n",
        "                    sys.exit(1)\n",
        "\n",
        "            w = float_sanity_check({\n",
        "                'Y': res['Y'],\n",
        "                'dY/dt': res['dYdt'],\n",
        "                'RHS': res['rhs'],\n",
        "                'align_sup': res['align_sup']\n",
        "            })\n",
        "            for ww in w:\n",
        "                print(ww)\n",
        "\n",
        "        if export_cert and (res['dYdt'] is not None) and (res['rhs'] is not None):\n",
        "            export_certificate(\n",
        "                f\"/content/output/certificate_time_reverse_t{t}.lean\",\n",
        "                res['dYdt'],\n",
        "                res['rhs'],\n",
        "                res['C_nl'],\n",
        "                res['delta'],\n",
        "                res['Lambda'],\n",
        "                res['Y'],\n",
        "                res['align_sup']\n",
        "            )\n",
        "\n",
        "        if strict and res['holds'] is False:\n",
        "            print(\"FAIL: Damping inequality violated in time_reverse test at step\", t)\n",
        "            save_forensic_failure(\n",
        "                timestep=t,\n",
        "                omega=omega_t,\n",
        "                Y=res['Y'],\n",
        "                dYdt=res['dYdt'],\n",
        "                rhs=res['rhs'],\n",
        "                align_sup=res['align_sup']\n",
        "            )\n",
        "            sys.exit(1)\n",
        "\n",
        "    print(\"[time reverse test] Completed.\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description=\"Recursive damping proof + additional tests.\"\n",
        "    )\n",
        "\n",
        "    # Base / shared arguments\n",
        "    parser.add_argument('--N', type=int, default=512,\n",
        "                        help=\"Grid size (default 512).\")\n",
        "    parser.add_argument('--alpha', type=float, default=2.5,\n",
        "                        help=\"Scaling exponent alpha (default 2.5).\")\n",
        "    parser.add_argument('--nu', type=float, default=0.01,\n",
        "                        help=\"Viscosity coefficient (default 0.01).\")\n",
        "    parser.add_argument('--eps', type=float, default=1e-10,\n",
        "                        help=\"Threshold epsilon for ignoring near-zero shells (default 1e-10).\")\n",
        "    parser.add_argument('--plot', action='store_true',\n",
        "                        help=\"Enable plotting per-shell metrics.\")\n",
        "    parser.add_argument('--export_cert', action='store_true',\n",
        "                        help=\"Export Lean-style proof certificates.\")\n",
        "    parser.add_argument('--run_validation_checks', action='store_true',\n",
        "                        help=\"Perform extra validation checks on intervals.\")\n",
        "    parser.add_argument('--input', type=str,\n",
        "                        help=\"Path to omega_t.npy for the initial vorticity field.\")\n",
        "    parser.add_argument('--input2', type=str,\n",
        "                        help=\"Path to omega_tpdt.npy for the next-timestep vorticity field.\")\n",
        "    parser.add_argument('--grad_u', type=str,\n",
        "                        help=\"Optional path to grad_u.npy if precomputed.\")\n",
        "\n",
        "    # Additional flags for separate tests\n",
        "    parser.add_argument('--run_blowup_test', action='store_true',\n",
        "                        help=\"Run the blowup test scenario after main run.\")\n",
        "    parser.add_argument('--run_commutator_test', action='store_true',\n",
        "                        help=\"Run the commutator test scenario after main run.\")\n",
        "    parser.add_argument('--run_time_reverse_test', action='store_true',\n",
        "                        help=\"Run the time-reverse test scenario after main run.\")\n",
        "\n",
        "    # Test/evolution arguments\n",
        "    parser.add_argument('--j_min', type=int, default=6,\n",
        "                        help=\"Minimum exponent j for the dyadic shell range (default 6).\")\n",
        "    parser.add_argument('--j_max', type=int, default=9,\n",
        "                        help=\"Maximum exponent j for the dyadic shell range (default 9).\")\n",
        "    parser.add_argument('--dt', type=float, default=1e-4,\n",
        "                        help=\"Time step for vorticity evolution (default 1e-4).\")\n",
        "    parser.add_argument('--timesteps', type=int, default=0,\n",
        "                        help=\"Number of time steps to run and certify (default 0).\")\n",
        "    parser.add_argument('--strict', action='store_true',\n",
        "                        help=\"Exit with error if any violation occurs in the inequality check.\")\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # Collect test flags to run later\n",
        "    run_blowup = args.run_blowup_test\n",
        "    run_commutator = args.run_commutator_test\n",
        "    run_time_reverse = args.run_time_reverse_test\n",
        "\n",
        "    # 1) Load or generate initial field\n",
        "    if args.input is not None:\n",
        "        omega_t = cp.load(args.input)\n",
        "        print(f\"Loaded omega_t from {args.input}, shape {omega_t.shape}.\")\n",
        "    else:\n",
        "        print(\"No --input provided. Generating a synthetic 'vortex tube' field.\")\n",
        "        omega_t = make_vortex_tube(args.N)\n",
        "\n",
        "    # 2) Optionally load next-timestep field\n",
        "    omega_tpdt = None\n",
        "    if args.input2 is not None:\n",
        "        omega_tpdt = cp.load(args.input2)\n",
        "        print(f\"Loaded omega_tpdt from {args.input2}, shape {omega_tpdt.shape}.\")\n",
        "\n",
        "    # 3) Optionally load grad_u if provided\n",
        "    grad_u = None\n",
        "    if args.grad_u is not None and os.path.isfile(args.grad_u):\n",
        "        grad_u = cp.load(args.grad_u)\n",
        "        print(f\"Loaded grad_u from {args.grad_u}, shape {grad_u.shape}.\")\n",
        "\n",
        "    # 4) Multi-step evolution if timesteps > 0\n",
        "    if args.timesteps > 0:\n",
        "        print(f\"Running {args.timesteps} time steps with dt={args.dt} and verifying at each step.\")\n",
        "        omega = omega_t.copy()\n",
        "        for t in range(args.timesteps):\n",
        "            context = f\"timestep_{t:03d}\"\n",
        "            omega_next = time_evolve(omega, args.nu, args.dt)\n",
        "            res, diagnostics = main_compute(\n",
        "                omega, omega_next,\n",
        "                grad_u,\n",
        "                args.alpha,\n",
        "                args.nu,\n",
        "                j_min=args.j_min,\n",
        "                j_max=args.j_max,\n",
        "                dt=args.dt,\n",
        "                eps=args.eps,\n",
        "                plot=args.plot,\n",
        "                validate=args.run_validation_checks,\n",
        "                context=context\n",
        "            )\n",
        "\n",
        "            if args.run_validation_checks:\n",
        "                try:\n",
        "                    validate_damping_terms(\n",
        "                        res['Y'], res['dYdt'], res['rhs'],\n",
        "                        res['align_sup'], res['delta'],\n",
        "                        res['Lambda'], res['C_nl']\n",
        "                    )\n",
        "                except AssertionError as e:\n",
        "                    print(f\"[VALIDATION ERROR] {e}\")\n",
        "                    save_forensic_failure(\n",
        "                        timestep=t,\n",
        "                        omega=omega,\n",
        "                        Y=res['Y'],\n",
        "                        dYdt=res['dYdt'],\n",
        "                        rhs=res['rhs'],\n",
        "                        align_sup=res['align_sup']\n",
        "                    )\n",
        "                    if args.strict:\n",
        "                        sys.exit(1)\n",
        "\n",
        "                warnings = float_sanity_check({\n",
        "                    'Y': res['Y'],\n",
        "                    'dY/dt': res['dYdt'],\n",
        "                    'RHS': res['rhs'],\n",
        "                    'align_sup': res['align_sup']\n",
        "                })\n",
        "                for w in warnings:\n",
        "                    print(w)\n",
        "                H = compute_entropy(res['_entropic_per_shell'])\n",
        "                print(f\"[entropy] H(t) = {H:.4f}\")\n",
        "\n",
        "            if args.export_cert and (res['dYdt'] is not None) and (res['rhs'] is not None):\n",
        "                export_certificate(\n",
        "                    f\"/content/output/certificate_{context}.lean\",\n",
        "                    res['dYdt'],\n",
        "                    res['rhs'],\n",
        "                    res['C_nl'],\n",
        "                    res['delta'],\n",
        "                    res['Lambda'],\n",
        "                    res['Y'],\n",
        "                    res['align_sup']\n",
        "                )\n",
        "\n",
        "            if args.strict and res['holds'] is False:\n",
        "                print(f\"FAIL: Damping inequality violated at timestep {t}\")\n",
        "                save_forensic_failure(\n",
        "                    timestep=t,\n",
        "                    omega=omega,\n",
        "                    Y=res['Y'],\n",
        "                    dYdt=res['dYdt'],\n",
        "                    rhs=res['rhs'],\n",
        "                    align_sup=res['align_sup']\n",
        "                )\n",
        "                sys.exit(1)\n",
        "\n",
        "            omega = omega_next.copy()\n",
        "\n",
        "        print(f\"Timestep evolution complete for {args.timesteps} steps.\")\n",
        "\n",
        "    else:\n",
        "        # 5) Single-step certification if timesteps == 0\n",
        "        res, diagnostics = main_compute(\n",
        "            omega_t, omega_tpdt,\n",
        "            grad_u,\n",
        "            args.alpha,\n",
        "            args.nu,\n",
        "            j_min=args.j_min,\n",
        "            j_max=args.j_max,\n",
        "            dt=args.dt,\n",
        "            eps=args.eps,\n",
        "            plot=args.plot,\n",
        "            validate=args.run_validation_checks,\n",
        "            context='mainrun'\n",
        "        )\n",
        "\n",
        "        if args.export_cert and (res['dYdt'] is not None) and (res['rhs'] is not None):\n",
        "            export_certificate(\n",
        "                \"/content/output/certificate.lean\",\n",
        "                res['dYdt'],\n",
        "                res['rhs'],\n",
        "                res['C_nl'],\n",
        "                res['delta'],\n",
        "                res['Lambda'],\n",
        "                res['Y'],\n",
        "                res['align_sup']\n",
        "            )\n",
        "\n",
        "        if args.strict and res['holds'] is False:\n",
        "            print(\"FAIL: Damping inequality violated for the single-step scenario.\")\n",
        "            save_forensic_failure(\n",
        "                timestep=0,\n",
        "                omega=omega_t,\n",
        "                Y=res['Y'],\n",
        "                dYdt=res['dYdt'],\n",
        "                rhs=res['rhs'],\n",
        "                align_sup=res['align_sup']\n",
        "            )\n",
        "            sys.exit(1)\n",
        "\n",
        "        if args.run_validation_checks:\n",
        "            try:\n",
        "                validate_damping_terms(\n",
        "                    res['Y'], res['dYdt'], res['rhs'],\n",
        "                    res['align_sup'], res['delta'],\n",
        "                    res['Lambda'], res['C_nl']\n",
        "                )\n",
        "            except AssertionError as e:\n",
        "                print(f\"[VALIDATION ERROR] {e}\")\n",
        "                save_forensic_failure(\n",
        "                    timestep=0,\n",
        "                    omega=omega_t,\n",
        "                    Y=res['Y'],\n",
        "                    dYdt=res['dYdt'],\n",
        "                    rhs=res['rhs'],\n",
        "                    align_sup=res['align_sup']\n",
        "                )\n",
        "                if args.strict:\n",
        "                    sys.exit(1)\n",
        "\n",
        "            warnings = float_sanity_check({\n",
        "                'Y': res['Y'],\n",
        "                'dY/dt': res['dYdt'],\n",
        "                'RHS': res['rhs'],\n",
        "                'align_sup': res['align_sup']\n",
        "            })\n",
        "            for w in warnings:\n",
        "                print(w)\n",
        "            H = compute_entropy(res['_entropic_per_shell'])\n",
        "            print(f\"[entropy] H(t) = {H:.4f}\")\n",
        "\n",
        "        print(\"Default evolution + certification completed successfully.\")\n",
        "        print(\"See /content/output/diagnostics_log_mainrun.json for details.\")\n",
        "\n",
        "    # Now run additional diagnostic tests (after the main run)\n",
        "    if run_blowup:\n",
        "        simulate_blowup(\n",
        "            N=args.N, alpha=args.alpha, j_min=args.j_min, j_max=args.j_max,\n",
        "            dt=args.dt, timesteps=1, strict=args.strict, plot=args.plot,\n",
        "            run_validation_checks=args.run_validation_checks, nu=args.nu,\n",
        "            export_cert=args.export_cert, eps=args.eps\n",
        "        )\n",
        "\n",
        "    if run_commutator:\n",
        "        stress_commutator(\n",
        "            N=args.N, alpha=args.alpha, j_min=args.j_min, j_max=args.j_max,\n",
        "            dt=args.dt, timesteps=1, strict=args.strict, plot=args.plot,\n",
        "            run_validation_checks=args.run_validation_checks, nu=args.nu,\n",
        "            export_cert=args.export_cert, eps=args.eps\n",
        "        )\n",
        "\n",
        "    if run_time_reverse:\n",
        "        time_reverse_test(\n",
        "            N=args.N, alpha=args.alpha, j_min=args.j_min, j_max=args.j_max,\n",
        "            dt=args.dt, timesteps=1, strict=args.strict, plot=args.plot,\n",
        "            run_validation_checks=args.run_validation_checks, nu=args.nu,\n",
        "            export_cert=args.export_cert, eps=args.eps\n",
        "        )\n",
        "\n",
        "    print(\"All requested runs/tests are complete. Exiting.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5bd0xKL9CkO",
        "outputId": "6013bfef-b75b-4624-efcd-b1900d99f55b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting proof_colab.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile recursive_ode_falsifier.py\n",
        "import glob, json, numpy as np, matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "import matplotlib.pyplot as plt\n",
        "import csv, re, warnings, argparse, sys, os\n",
        "\n",
        "FALSIFIER_LOG = \"/content/output/falsifier_log.txt\"\n",
        "\n",
        "def parse_interval_tuple(s):\n",
        "    # Accepts: float/int, \"X ± Y\", [X, Y], (X, Y), or {\"mid\":X,\"width\":Y}\n",
        "    if isinstance(s, (int, float)):\n",
        "        return (float(s), 0.0)\n",
        "    if isinstance(s, (list, tuple)) and len(s) == 2 and all(isinstance(x, (int, float)) for x in s):\n",
        "        return (float(s[0]), float(s[1]))\n",
        "    if isinstance(s, dict):\n",
        "        if \"mid\" in s and \"width\" in s:\n",
        "            return (float(s[\"mid\"]), float(s[\"width\"]))\n",
        "        if \"val\" in s and \"err\" in s:\n",
        "            return (float(s[\"val\"]), float(s[\"err\"]))\n",
        "        # add more keys as needed\n",
        "    if isinstance(s, str):\n",
        "        m = re.match(r\"^\\s*([-+0-9.eE]+)\\s*±\\s*([-+0-9.eE]+)\\s*$\", s)\n",
        "        if m:\n",
        "            return (float(m.group(1)), float(m.group(2)))\n",
        "        try:\n",
        "            return (float(s), 0.0)\n",
        "        except:\n",
        "            pass\n",
        "    raise ValueError(f\"Cannot parse interval from: {s}\")\n",
        "\n",
        "\n",
        "def falsify(reason, strict=False, do_lean_cert=False):\n",
        "    with open(FALSIFIER_LOG, \"a\") as f:\n",
        "        f.write(reason.strip() + \"\\n\")\n",
        "    print(\"FALSIFIER:\", reason.strip())\n",
        "    if do_lean_cert:\n",
        "        export_falsifier_certificate(reason)\n",
        "    if strict:\n",
        "        sys.exit(1)\n",
        "\n",
        "def export_falsifier_certificate(reason, fname=\"/content/output/falsifier_certificate.lean\"):\n",
        "    with open(fname, \"w\") as f:\n",
        "        f.write(f\"-- Falsifier certificate: Antagonist claim\\n\")\n",
        "        f.write(f\"theorem proof_invalid : false := by\\n  -- {reason.strip()}\\n  contradiction\\n\")\n",
        "\n",
        "def compute_entropy(per_shell):\n",
        "    H = 0.0\n",
        "    for s in per_shell:\n",
        "        m, _ = parse_interval_tuple(s['norm'])\n",
        "        if m > 0:\n",
        "            H += m * np.log(m)\n",
        "    return H\n",
        "\n",
        "def load_logs():\n",
        "    diagnostics = []\n",
        "    shell_per_t = []\n",
        "    files = sorted(glob.glob(\"/content/output/diagnostics_log_timestep_*.json\"),\n",
        "                  key=lambda f: int(re.search(r'_(\\d+)\\.json$', f).group(1)))\n",
        "    if not files:\n",
        "        raise RuntimeError(\"No log files found in /content/output/\")\n",
        "    prev_idx = -1\n",
        "    for f in files:\n",
        "        with open(f) as j:\n",
        "            d = json.load(j)\n",
        "        t_idx = int(re.search(r'_(\\d+)\\.json$', f).group(1))\n",
        "        if t_idx <= prev_idx:\n",
        "            falsify(f\"Non-monotonic timestep index in {f}.\", strict=False)\n",
        "        prev_idx = t_idx\n",
        "        diagnostics.append(d)\n",
        "        if '_entropic_per_shell' in d:\n",
        "            shell_per_t.append(d['_entropic_per_shell'])\n",
        "        else:\n",
        "            shell_per_t.append([])\n",
        "    # Guess dt:\n",
        "    if len(files)>1:\n",
        "        idxs = [int(re.search(r'_(\\d+)\\.json$', f).group(1)) for f in files]\n",
        "        dts = np.diff(idxs)\n",
        "        dt = float(dts[0]) if np.all(dts==dts[0]) else np.median(dts)\n",
        "    else:\n",
        "        dt = 1.0\n",
        "    return diagnostics, shell_per_t, dt\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--strict\", action=\"store_true\", help=\"Fail hard on any ODE falsification.\")\n",
        "    parser.add_argument(\"--lean_cert\", action=\"store_true\", help=\"Export Lean-style falsifier certificate.\")\n",
        "    # PATCH: Allow notebook/Colab to pass extraneous args\n",
        "    args, unknown = parser.parse_known_args()\n",
        "    diagnostics, shell_per_t, dt = load_logs()\n",
        "    steps = len(diagnostics)\n",
        "    t_arr = np.arange(steps) * dt\n",
        "    # Extract constants and interval data\n",
        "    Y_tuples  = [parse_interval_tuple(d['Y']) for d in diagnostics]\n",
        "    Y_mids = [y[0] for y in Y_tuples]\n",
        "    Y_wids = [y[1] for y in Y_tuples]\n",
        "    dYdt_vals = [parse_interval_tuple(d['dYdt'])[0] if d['dYdt'] else np.nan for d in diagnostics]\n",
        "    A_tuples  = [parse_interval_tuple(d['align_sup']) for d in diagnostics]\n",
        "    A_mids = [a[0] for a in A_tuples]\n",
        "    A_wids = [a[1] for a in A_tuples]\n",
        "    C_nl  = float(diagnostics[0]['C_nl'])\n",
        "    nu    = float(diagnostics[0].get('nu', 0.01))\n",
        "    delta = float(diagnostics[0]['delta'])\n",
        "    Lam   = float(diagnostics[0]['Lambda'])\n",
        "    A_lowers = [max(a[0]-a[1], 0.0) for a in A_tuples]\n",
        "    A_uppers = [a[0]+a[1] for a in A_tuples]\n",
        "    Y0_mid = Y_mids[0]; Y0_wid = Y_wids[0]\n",
        "    # Prepare ODE sim\n",
        "    def ode_step(Y, A):\n",
        "        return C_nl * Y**2 * A - nu * Lam * (Y**(1+delta))\n",
        "    def sim_trajectory(Y0, A_series):\n",
        "        Ys = [Y0]\n",
        "        rhses = []\n",
        "        for i in range(steps-1):\n",
        "            Y = Ys[-1]\n",
        "            A = A_series[i]\n",
        "            rhs = ode_step(Y, A)\n",
        "            rhses.append(rhs)\n",
        "            Y_next = Y + dt * rhs\n",
        "            if Y_next < 0 or np.isnan(Y_next) or np.isinf(Y_next):\n",
        "                falsify(f\"Ode trajectory blew up at t={i*dt:.4g}, Y={Y_next}\", strict=args.strict, do_lean_cert=args.lean_cert)\n",
        "                Y_next = 0.0\n",
        "            Ys.append(Y_next)\n",
        "        # Final point for rhs (for completeness)\n",
        "        rhses.append(ode_step(Ys[-1], A_series[-1]))\n",
        "        return np.array(Ys), np.array(rhses)\n",
        "    Ys_sim_nom, rhs_vals_nom = sim_trajectory(Y0_mid, A_mids)\n",
        "    Ys_sim_lo,  _            = sim_trajectory(max(Y0_mid-Y0_wid,0), A_lowers)\n",
        "    Ys_sim_hi,  _            = sim_trajectory(Y0_mid+Y0_wid, A_uppers)\n",
        "    # RHS sign stability check\n",
        "    if any(r > 0 for r in rhs_vals_nom):\n",
        "        falsify(\"RHS > 0 detected: net stretching over damping!\", strict=args.strict, do_lean_cert=args.lean_cert)\n",
        "    # Entropy\n",
        "    entropies = [compute_entropy(shell) if shell else np.nan for shell in shell_per_t]\n",
        "    ent_deltas = np.diff(entropies)\n",
        "    if np.any(ent_deltas > 0.5 * np.abs(entropies[:-1])):\n",
        "        falsify(\"Entropy surged >50% between steps — possible intermittent burst\", strict=args.strict, do_lean_cert=args.lean_cert)\n",
        "    # Relative error\n",
        "    rel_errs = np.abs(Ys_sim_nom - np.array(Y_mids)) / np.maximum(np.abs(Y_mids), 1e-14)\n",
        "    max_rel_err = np.max(rel_errs)\n",
        "    trend_measured = Y_mids[-1] < Y_mids[0]\n",
        "    trend_sim = Ys_sim_nom[-1] < Ys_sim_nom[0]\n",
        "    trend_match = (trend_measured == trend_sim)\n",
        "    falsified = False\n",
        "    violations = []\n",
        "    for i in range(steps):\n",
        "        if rel_errs[i] > 0.02:\n",
        "            msg = f\"Step {i}: rel_err={rel_errs[i]:.3%} exceeds Clay threshold (2%)\"\n",
        "            violations.append(msg)\n",
        "            falsify(f\"FALSIFICATION: {msg}\", strict=args.strict, do_lean_cert=args.lean_cert)\n",
        "            falsified = True\n",
        "        if Ys_sim_nom[i]<0 or np.isnan(Ys_sim_nom[i]):\n",
        "            msg = f\"Step {i}: Simulated Y negative or NaN!\"\n",
        "            violations.append(msg)\n",
        "            falsify(f\"FALSIFICATION: {msg}\", strict=args.strict, do_lean_cert=args.lean_cert)\n",
        "            falsified = True\n",
        "    if not trend_match:\n",
        "        falsify(\"Decay trend between proof logs and ODE simulation does not match (monotonicity fail)\", strict=args.strict, do_lean_cert=args.lean_cert)\n",
        "        falsified = True\n",
        "    # Derivative check (finite diff)\n",
        "    dY_log = (np.array(Y_mids[1:]) - np.array(Y_mids[:-1]))/dt\n",
        "    dY_log_full = np.concatenate([ [dYdt_vals[0]], dY_log ])\n",
        "    dYdt_agree = np.max(np.abs(dY_log_full-np.array(dYdt_vals))) < 0.01*np.max(np.abs(Y_mids))\n",
        "    if not dYdt_agree:\n",
        "        falsify(\"Log-differs of measured Y(t) and provided dY/dt do not match (inconsistency)\", strict=args.strict, do_lean_cert=args.lean_cert)\n",
        "    # Slope bound check\n",
        "    if np.any(np.abs(dY_log_full) > 1e3):\n",
        "        falsify(\"dY/dt slope magnitude exceeds 1000 — possibly unstable timestep\", strict=args.strict, do_lean_cert=args.lean_cert)\n",
        "    # Plot Y(t)\n",
        "    plt.figure(figsize=(7,6))\n",
        "    plt.plot(t_arr, Y_mids, 'o-', label='Measured Y(t)', zorder=3)\n",
        "    plt.plot(t_arr, Ys_sim_nom, 's-', label='Simulated Y(t) [Nominal]', zorder=2)\n",
        "    plt.fill_between(t_arr, Ys_sim_lo, Ys_sim_hi, color='lightblue', alpha=0.3, label='Sim interval')\n",
        "    plt.xlabel('t')\n",
        "    plt.ylabel('Y(t)')\n",
        "    plt.title('Recursive ODE (with Antagonist Intervals)')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"/content/output/recursive_ode_validation.png\")\n",
        "    # Plot A(t)\n",
        "    plt.figure(figsize=(7,2))\n",
        "    plt.plot(t_arr, A_mids, label='A(t) midpoint')\n",
        "    plt.fill_between(t_arr, A_lowers, A_uppers, color='orange', alpha=0.2, label='A(t) interval')\n",
        "    plt.ylabel('Alignment A')\n",
        "    plt.xlabel('t')\n",
        "    plt.title('Alignment factor interval')\n",
        "    plt.legend()\n",
        "    plt.savefig(\"/content/output/recursive_ode_A.png\")\n",
        "    # Plot entropy\n",
        "    plt.figure(figsize=(7,2))\n",
        "    plt.plot(t_arr, entropies, label='Entropy')\n",
        "    plt.xlabel('t')\n",
        "    plt.ylabel('H(t)')\n",
        "    plt.title('Shellwise Entropy')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"/content/output/recursive_ode_entropy.png\")\n",
        "    # CSV\n",
        "    with open(\"/content/output/recursive_ode_trace.csv\", \"w\", newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(['t', 'Y_measured', 'Y_measured_width', 'Y_sim_nom', 'Y_sim_lo', 'Y_sim_hi',\n",
        "                        'dYdt_measured', 'A_align_mid', 'A_lo', 'A_hi', 'entropy', 'rel_error'])\n",
        "        for i in range(steps):\n",
        "            writer.writerow([t_arr[i], Y_mids[i], Y_wids[i], Ys_sim_nom[i],\n",
        "                            Ys_sim_lo[i], Ys_sim_hi[i], dYdt_vals[i],\n",
        "                            A_mids[i], A_lowers[i], A_uppers[i], entropies[i], rel_errs[i]])\n",
        "    print(f\"Max relative error: {max_rel_err:.4%}\")\n",
        "    print(\"Decay trend matches: \" if trend_match else \"DECAY TREND MISMATCH!\")\n",
        "    print(f\"Strict falsified: {falsified}\")\n",
        "    print(f\"CSV and plots in /content/output/\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FE-qIRUeOUZj",
        "outputId": "0f54e626-9ddf-4ef0-9d1d-f96408ddd810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting recursive_ode_falsifier.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile proof_falsifier_engine.py\n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import subprocess\n",
        "import time\n",
        "import hashlib\n",
        "import json\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "try:\n",
        "    import cupy as cp\n",
        "except ImportError:\n",
        "    cp = None\n",
        "\n",
        "####### --- Synthetic Field Generators --- #######\n",
        "\n",
        "def make_shell_localized(j=3, N=32, seed=42):\n",
        "    # Shell-localized vorticity (Fourier bump at shell j)\n",
        "    np.random.seed(seed)\n",
        "    if cp: cp.random.seed(seed)\n",
        "    omega = np.zeros((3, N, N, N), dtype=np.float64)\n",
        "    grid = np.fft.fftfreq(N) * N\n",
        "    Kx, Ky, Kz = np.meshgrid(grid, grid, grid, indexing='ij')\n",
        "    K2 = Kx**2 + Ky**2 + Kz**2\n",
        "    mask = (K2 >= 2**(2*j)) & (K2 < 2**(2*(j+1)))\n",
        "    for c in range(3):\n",
        "        noise = np.random.randn(N,N,N)\n",
        "        fft = np.fft.fftn(noise)\n",
        "        fft *= mask\n",
        "        loc = np.fft.ifftn(fft).real\n",
        "        omega[c] = loc / np.sqrt(np.mean(loc**2)+1e-12)\n",
        "    return omega\n",
        "\n",
        "def make_vortex_tube(N=32, amp=1.0):\n",
        "    # Simple vortex tube along e1\n",
        "    omega = np.zeros((3, N, N, N), dtype=np.float64)\n",
        "    x = np.linspace(-1,1,N,endpoint=False)\n",
        "    X,Y,Z = np.meshgrid(x,x,x,indexing='ij')\n",
        "    r = np.sqrt(Y**2+Z**2)\n",
        "    profile = amp * np.exp(-20*r**2)\n",
        "    omega[0] = profile  # Aligned with e1\n",
        "    return omega\n",
        "\n",
        "def align_to_e1(omega):\n",
        "    # Rotate max-energy direction to e1\n",
        "    v = omega.reshape(3,-1).mean(axis=1)\n",
        "    if np.linalg.norm(v) < 1e-8:\n",
        "        return omega\n",
        "    e1 = np.array([1,0,0.])\n",
        "    axis = np.cross(v, e1)\n",
        "    if np.linalg.norm(axis) < 1e-8:\n",
        "        return omega\n",
        "    axis = axis / np.linalg.norm(axis)\n",
        "    theta = np.arccos(np.dot(v, e1)/(np.linalg.norm(v)*np.linalg.norm(e1)))\n",
        "    from scipy.spatial.transform import Rotation as R\n",
        "    Rmat = R.from_rotvec(axis*theta).as_matrix()\n",
        "    return np.tensordot(Rmat, omega, axes=([1],[0]))\n",
        "\n",
        "def combine_shells(j1=2, j2=6, N=32):\n",
        "    # Blend two shell-localized fields\n",
        "    w1 = make_shell_localized(j=j1,N=N,seed=10*j1)\n",
        "    w2 = make_shell_localized(j=j2,N=N,seed=10*j2+1)\n",
        "    return 0.5*w1 + 1.5*w2\n",
        "\n",
        "def random_gaussian(scale=1e-2, N=32, seed=123):\n",
        "    np.random.seed(seed)\n",
        "    omega = scale * np.random.randn(3,N,N,N)\n",
        "    return omega\n",
        "\n",
        "def proof_evolve(omega_t, dt=1e-4):\n",
        "    # Very simple Euler step for demonstration (add some noise)\n",
        "    omega_tpdt = omega_t + dt * np.random.randn(*omega_t.shape) * 0.01\n",
        "    return omega_tpdt\n",
        "\n",
        "######## ---- Field Registry ---- ########\n",
        "\n",
        "fields = [\n",
        "  {\"name\": \"shell_j3\", \"generator\": make_shell_localized, \"params\": {\"j\":3, \"seed\":42}},\n",
        "  {\"name\": \"shell_j5\", \"generator\": make_shell_localized, \"params\": {\"j\":5, \"seed\":43}},\n",
        "  {\"name\": \"aligned_blowup\", \"generator\": make_vortex_tube, \"post\": \"align_to_e1\"},\n",
        "  {\"name\": \"adversarial_combo\", \"generator\": combine_shells, \"params\": {\"j1\":2, \"j2\":6}},\n",
        "  {\"name\": \"random_noise\", \"generator\": random_gaussian, \"params\": {\"scale\":1e-2, \"seed\":99}},\n",
        "]\n",
        "\n",
        "gen_post_map = {\n",
        "    \"align_to_e1\": align_to_e1,\n",
        "}\n",
        "\n",
        "######## ---- Utility Functions ---- ########\n",
        "def get_hash(arr):\n",
        "    return hashlib.md5(arr.astype(np.float32).tobytes()).hexdigest()[:10]\n",
        "\n",
        "def save_field(arr, fname):\n",
        "    np.save(fname, arr)\n",
        "\n",
        "def load_field(fname):\n",
        "    return np.load(fname)\n",
        "\n",
        "def get_git_hash():\n",
        "    try:\n",
        "        import subprocess\n",
        "        git_hash = subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"], cwd=\"/content/\", text=True).strip()\n",
        "        return git_hash\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def copy_if_exists(src, dst):\n",
        "    try:\n",
        "        if os.path.exists(src):\n",
        "            shutil.copy(src, dst)\n",
        "            return True\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to copy {src} to {dst}: {e}\")\n",
        "    return False\n",
        "\n",
        "def safe_makedirs(path):\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "def bundle_counterexamples(counterexample_paths, zip_out=\"/content/output/counterexample_bundle.zip\"):\n",
        "    with zipfile.ZipFile(zip_out, 'w', compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "        for cdir in counterexample_paths:\n",
        "            for fname in Path(cdir).glob('*'):\n",
        "                zf.write(fname, arcname=f\"{Path(cdir).name}/{fname.name}\")\n",
        "\n",
        "######## ---- Metrics & Report ---- ########\n",
        "\n",
        "summary = {\n",
        "    \"total_runs\": 0,\n",
        "    \"proof_colab_failures\": 0,\n",
        "    \"ode_falsifier_failures\": 0,\n",
        "    \"field_failure_types\": [],\n",
        "    \"counterexample_paths\": [],\n",
        "    \"entropy_curves\": [],\n",
        "    \"run_details\": [],\n",
        "}\n",
        "\n",
        "######## ---- Main Adversarial Loop ---- ########\n",
        "\n",
        "def main():\n",
        "    N = 512\n",
        "    output_dir = \"/content/output/\"\n",
        "    cx_dir = os.path.join(output_dir, \"counterexamples/\")\n",
        "    safe_makedirs(output_dir)\n",
        "    safe_makedirs(cx_dir)\n",
        "    git_hash = get_git_hash()\n",
        "    timestamp = datetime.datetime.utcnow().isoformat() + \"Z\"\n",
        "    global_run = 1\n",
        "\n",
        "    for run_idx, field in enumerate(fields, 1):\n",
        "        name = field['name']\n",
        "        params = field.get('params', {})\n",
        "        gen = field['generator']\n",
        "        context = f\"test_{name}_run{run_idx}\"\n",
        "        seed = params.get('seed', 1000+run_idx) if 'seed' in params else 1000+run_idx\n",
        "        np.random.seed(seed)\n",
        "        if cp: cp.random.seed(seed)\n",
        "        run_info = {\n",
        "            \"index\": run_idx,\n",
        "            \"context\": context,\n",
        "            \"name\": name,\n",
        "            \"params\": params,\n",
        "            \"timestamp\": timestamp,\n",
        "            \"git_hash\": git_hash,\n",
        "            \"seed\": seed,\n",
        "        }\n",
        "        # --- Generate vorticity field ---\n",
        "        if 'params' in field:\n",
        "            omega = gen(**params, N=N) if 'N' in gen.__code__.co_varnames else gen(**params)\n",
        "        else:\n",
        "            omega = gen(N=N)\n",
        "        # Apply any postproc:\n",
        "        if field.get('post'):\n",
        "            omega = gen_post_map[field['post']](omega)\n",
        "        omega_t = omega.astype(np.float32)\n",
        "        save_field(omega_t, '/content/omega_t.npy')\n",
        "        omega_tpdt = proof_evolve(omega_t)\n",
        "        save_field(omega_tpdt, '/content/omega_tpdt.npy')\n",
        "        cx_hash = get_hash(omega_t)\n",
        "        context_full = f\"{context}_{cx_hash}\"\n",
        "        run_info[\"context_full\"] = context_full\n",
        "        run_info[\"cx_hash\"] = cx_hash\n",
        "        # Save config:\n",
        "        config_json = f\"/content/output/{context_full}_config.json\"\n",
        "        with open(config_json,\"w\") as f:\n",
        "            json.dump(run_info, f, indent=2)\n",
        "        proof_log = os.path.join(output_dir, 'diagnostics_log.json')\n",
        "        proof_cert = os.path.join(output_dir, 'proof_certificate.lean')\n",
        "        falsifier_log = os.path.join(output_dir, 'falsifier_log.txt')\n",
        "        falsifier_cert = os.path.join(output_dir, 'falsifier_certificate.lean')\n",
        "        # --- RUN proof_colab.py ---\n",
        "        proof_args = [\n",
        "            sys.executable, \"proof_colab.py\",\n",
        "            \"--input\", \"omega_t.npy\",\n",
        "            \"--input2\", \"omega_tpdt.npy\",\n",
        "            \"--alpha\", \"2.5\", \"--plot\", \"--export_cert\",\n",
        "            \"--run_validation_checks\", \"--strict\",\n",
        "            \"--context\", context_full\n",
        "        ]\n",
        "        summary[\"total_runs\"] += 1\n",
        "        proc1 = subprocess.run(proof_args, capture_output=True, cwd=\"/content/\")\n",
        "        proof_failed = proc1.returncode != 0\n",
        "        ode_failed = False\n",
        "        # --- RUN recursive_ode_falsifier.py ---\n",
        "        if not proof_failed:\n",
        "            ode_args = [sys.executable, \"recursive_ode_falsifier.py\", \"--strict\", \"--lean_cert\"]\n",
        "            proc2 = subprocess.run(ode_args, capture_output=True, cwd=\"/content/\")\n",
        "            ode_failed = proc2.returncode != 0\n",
        "        # --- Handle any failures ---\n",
        "        failed = False\n",
        "        cx_this_run_dir = \"\"\n",
        "        if proof_failed or ode_failed:\n",
        "            failed = True\n",
        "            fail_reason = []\n",
        "            cxdir = os.path.join(cx_dir, context_full)\n",
        "            safe_makedirs(cxdir)\n",
        "            cx_this_run_dir = cxdir\n",
        "            safe_makedirs(cxdir)\n",
        "            shutil.copy('/content/omega_t.npy', os.path.join(cxdir, f\"{context_full}_omega_t.npy\"))\n",
        "            shutil.copy('/content/omega_tpdt.npy', os.path.join(cxdir, f\"{context_full}_omega_tpdt.npy\"))\n",
        "            copy_if_exists(proof_log, os.path.join(cxdir, f\"{context_full}_diagnostics_log.json\"))\n",
        "            copy_if_exists(proof_cert, os.path.join(cxdir, f\"{context_full}_proof_certificate.lean\"))\n",
        "            copy_if_exists(falsifier_log, os.path.join(cxdir, f\"{context_full}_falsifier_log.txt\"))\n",
        "            copy_if_exists(falsifier_cert, os.path.join(cxdir, f\"{context_full}_falsifier_certificate.lean\"))\n",
        "            shutil.copy(config_json, os.path.join(cxdir, f\"{context_full}_config.json\"))\n",
        "            with open(os.path.join(cxdir, f\"{context_full}_proof_stdout.txt\"),\"w\") as f: f.write(proc1.stdout.decode(errors='ignore'))\n",
        "            with open(os.path.join(cxdir, f\"{context_full}_proof_stderr.txt\"),\"w\") as f: f.write(proc1.stderr.decode(errors='ignore'))\n",
        "            if not proof_failed:\n",
        "                with open(os.path.join(cxdir, f\"{context_full}_ode_stdout.txt\"),\"w\") as f: f.write(proc2.stdout.decode(errors='ignore'))\n",
        "                with open(os.path.join(cxdir, f\"{context_full}_ode_stderr.txt\"),\"w\") as f: f.write(proc2.stderr.decode(errors='ignore'))\n",
        "            summary[\"counterexample_paths\"].append(cxdir)\n",
        "            if proof_failed:\n",
        "                summary[\"proof_colab_failures\"] += 1\n",
        "                fail_reason.append('proof_colab')\n",
        "            if ode_failed:\n",
        "                summary[\"ode_falsifier_failures\"] += 1\n",
        "                fail_reason.append('recursive_ode_falsifier')\n",
        "            summary[\"field_failure_types\"].append(f\"{name} ({'/'.join(fail_reason)})\")\n",
        "        # Optionally collect entropy curve:\n",
        "        try:\n",
        "            diag_path = os.path.join(output_dir, 'diagnostics_log_timestep_000.json')\n",
        "            if os.path.exists(diag_path):\n",
        "                with open(diag_path) as f:\n",
        "                    diag = json.load(f)\n",
        "                if '_entropic_per_shell' in diag:\n",
        "                    ent_arr = [float(s.get('norm',0)) for s in diag['_entropic_per_shell']]\n",
        "                    summary[\"entropy_curves\"].append({\"context\":context, \"entropy\": ent_arr})\n",
        "        except Exception: pass\n",
        "        # Save run details\n",
        "        run_info.update({\n",
        "            \"proof_failed\": proof_failed,\n",
        "            \"ode_failed\": ode_failed,\n",
        "            \"counterexample_dir\": cx_this_run_dir\n",
        "        })\n",
        "        summary[\"run_details\"].append(run_info)\n",
        "        result_tag = \"[FAIL]\" if failed else \"[PASS]\"\n",
        "        print(f\"{result_tag} {context_full} | proof_colab: {proc1.returncode} | ode: {('n/a' if proof_failed else proc2.returncode)}\")\n",
        "        sys.stdout.flush()\n",
        "\n",
        "    # Final bundle zip\n",
        "    if summary[\"counterexample_paths\"]:\n",
        "        bundle_counterexamples(summary[\"counterexample_paths\"])\n",
        "\n",
        "    # Print report\n",
        "    print(\"------ Adversarial Falsification Test Report ------\")\n",
        "    print(f\"Total runs: {summary['total_runs']}\")\n",
        "    print(f\"proof_colab.py failures: {summary['proof_colab_failures']}\")\n",
        "    print(f\"recursive_ode_falsifier.py failures: {summary['ode_falsifier_failures']}\")\n",
        "    print(f\"Field types causing failure:\\n  \" + \"\\n  \".join(sorted(set(summary['field_failure_types']))))\n",
        "    if summary[\"entropy_curves\"]:\n",
        "        print(\"Entropy curves available for analysis (first context shown):\")\n",
        "        print(summary[\"entropy_curves\"][0])\n",
        "    print(f\"Counterexamples saved in: {cx_dir}\")\n",
        "    print(f\"Bundle zip (if any): /content/output/counterexample_bundle.zip\")\n",
        "    print(\"--------------------------------------------------\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wc8Fkg3hF6Fy",
        "outputId": "fcc0c19d-702a-4d09-b2d7-45f1539ef72c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting proof_falsifier_engine.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile certificate_packager.py\n",
        "#!/usr/bin/env python3\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import glob\n",
        "import shutil\n",
        "import hashlib\n",
        "import argparse\n",
        "from pathlib import Path\n",
        "import zipfile\n",
        "import datetime\n",
        "\n",
        "############# Utility Functions ################\n",
        "\n",
        "def sha256file(fn):\n",
        "    h = hashlib.sha256()\n",
        "    with open(fn, \"rb\") as f:\n",
        "        while True:\n",
        "            blk = f.read(65536)\n",
        "            if not blk: break\n",
        "            h.update(blk)\n",
        "    return h.hexdigest()\n",
        "\n",
        "def sha256_bytes(b):\n",
        "    return hashlib.sha256(b).hexdigest()\n",
        "\n",
        "def load_json(fn):\n",
        "    with open(fn,\"r\") as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def fail(msg):\n",
        "    print(f\"[certificate_packager.py] ERROR: {msg}\", file=sys.stderr)\n",
        "    sys.exit(2)\n",
        "\n",
        "def lean_valid_certificate(lean_path):\n",
        "    try:\n",
        "        with open(lean_path,\"r\") as f:\n",
        "            data = f.read()\n",
        "        return \"theorem proof_invalid\" in data\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def find_file(prefix, exts, context, extra_match=None):\n",
        "    \"\"\"Find file with basename prefix, extension in list, containing context.\"\"\"\n",
        "    for e in exts:\n",
        "        for match in glob.glob(f\"**/*{prefix}*{context}*{e}\", recursive=True):\n",
        "            if extra_match and extra_match not in match: continue\n",
        "            return match\n",
        "    return None\n",
        "\n",
        "def find_field_file(ref_dir, hashval, suffix=\"omega_t.npy\"):\n",
        "    cands = glob.glob(os.path.join(ref_dir, f\"**/*{suffix}\"), recursive=True)\n",
        "    for fn in cands:\n",
        "        try:\n",
        "            if sha256file(fn) == hashval:\n",
        "                return fn\n",
        "        except: pass\n",
        "    return None\n",
        "\n",
        "def get_source_hash(path):\n",
        "    # Take SHA1 of this script as generator source hash\n",
        "    try:\n",
        "        with open(path, \"rb\") as f:\n",
        "            return hashlib.sha1(f.read()).hexdigest()\n",
        "    except Exception:\n",
        "        return \"unknown\"\n",
        "\n",
        "def monotonic_decay(yt):\n",
        "    if not yt or len(yt)<2: return False\n",
        "    return all((a>=b) for a,b in zip(yt,yt[1:]))\n",
        "\n",
        "############# Main Capsule Logic ###############\n",
        "\n",
        "def package_capsules(\n",
        "    proof_summary_json=\"/content/output/proof_summary.json\",\n",
        "    output_dir=\"/content/output/capsules/\",\n",
        "    verify_only=False,\n",
        "    min_ris=3,\n",
        "    sign_gpg=False,\n",
        "):\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # Step 1: Load summary, enumerate valid runs\n",
        "    # -------------------------------------------------\n",
        "    if not os.path.exists(proof_summary_json):\n",
        "        fail(f\"proof_summary.json not found at {proof_summary_json}\")\n",
        "    with open(proof_summary_json,\"r\") as f:\n",
        "        summary = json.load(f)[\"summary\"] if \"summary\" in json.load(f) else json.load(f)\n",
        "\n",
        "    runlist = []\n",
        "    for run in summary:\n",
        "        # Must be PASS, have config, lean cert present & valid, relerr ≤2%, monotonic, RIS ≥ min_ris\n",
        "        if run.get(\"pass_fail\") != \"PASS\": continue\n",
        "        if not run.get(\"lean_cert_present\"): continue\n",
        "        if not run.get(\"lean_cert_valid\"): continue\n",
        "        if run.get(\"relerr_max\") is None or float(run.get(\"relerr_max\",9e9)) > 0.02: continue\n",
        "        if not monotonic_decay(run.get(\"Y_t\",[])): continue\n",
        "        if int(run.get(\"RIS\",0)) < min_ris: continue\n",
        "        runlist.append(run)\n",
        "    if not runlist:\n",
        "        fail(\"No valid runs found for packaging.\")\n",
        "\n",
        "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
        "    generator_src_hash = get_source_hash(__file__)\n",
        "    capsules = []\n",
        "    now = datetime.datetime.utcnow().isoformat()+\"Z\"\n",
        "\n",
        "    for run in runlist:\n",
        "        context = run['context']\n",
        "        field_type = run.get(\"type\")\n",
        "        params = run.get(\"params\",{})\n",
        "        seed = params.get(\"seed\",\"\")\n",
        "        git_commit = run.get(\"git_commit\",\"\")\n",
        "        sha_reported = run.get(\"sha256\") or run.get(\"hash_sha256\")\n",
        "        capsule_data = {\n",
        "            \"context\": context,\n",
        "            \"field_type\": field_type,\n",
        "            \"seed\": seed,\n",
        "            \"params\": params,\n",
        "            \"timestamp\": now,\n",
        "            \"git_commit\": git_commit,\n",
        "            \"sha256\": sha_reported,\n",
        "            \"generator_source_hash\": generator_src_hash,\n",
        "            \"files\": {},\n",
        "        }\n",
        "        # ------- Locate and validate all relevant files -------\n",
        "        # -- omega_t.npy (must match hash from config)\n",
        "        omega_t_fn = find_field_file(\"/content/output/\", sha_reported, suffix=\"omega_t.npy\")\n",
        "        if not omega_t_fn:\n",
        "            fail(f\"Run {context}: omega_t.npy with matching hash not found.\")\n",
        "        if sha256file(omega_t_fn) != sha_reported:\n",
        "            fail(f\"Run {context}: hash mismatch for omega_t.npy.\")\n",
        "\n",
        "        # -- omega_tpdt.npy (optional, but must exist if claimed)\n",
        "        omega_tpdt_fn = None\n",
        "        for cand in glob.glob(os.path.join(os.path.dirname(omega_t_fn),\"*omega_tpdt.npy\")):\n",
        "            if os.path.exists(cand): omega_tpdt_fn = cand\n",
        "\n",
        "        # -- Config JSON\n",
        "        config_fn = find_file(prefix=\"\", exts=[\"_config.json\"], context=context)\n",
        "        if not config_fn:\n",
        "            fail(f\"Run {context}: config json missing.\")\n",
        "\n",
        "        # -- Lean certificate (proof or falsifier), must validate\n",
        "        lean_fn = find_file(prefix=\"\", exts=[\".lean\"], context=context)\n",
        "        if not lean_fn or not lean_valid_certificate(lean_fn):\n",
        "            fail(f\"Run {context}: valid .lean certificate not found or invalid.\")\n",
        "\n",
        "        # -- Diagnostics, logs, preview images, CSVs\n",
        "        diag_log = find_file(prefix=\"diagnostics_log\", exts=[\".json\"], context=context)\n",
        "        csv_fn   = find_file(prefix=\"\", exts=[\".csv\"], context=context)\n",
        "        falsifier_log = find_file(prefix=\"falsifier_log\", exts=[\".txt\"], context=context)\n",
        "        preview_png = find_file(prefix=\"\", exts=[\".png\"], context=context)\n",
        "        # ---- Gather all files to package\n",
        "        fileset = {\n",
        "            \"omega_t.npy\": omega_t_fn,\n",
        "            \"config.json\": config_fn,\n",
        "            \"certificate.lean\": lean_fn\n",
        "        }\n",
        "        if omega_tpdt_fn: fileset[\"omega_tpdt.npy\"] = omega_tpdt_fn\n",
        "        if diag_log: fileset[\"diagnostics.json\"] = diag_log\n",
        "        if csv_fn: fileset[\"summary.csv\"] = csv_fn\n",
        "        if falsifier_log: fileset[\"falsifier_log.txt\"] = falsifier_log\n",
        "        if preview_png: fileset[\"preview.png\"] = preview_png\n",
        "\n",
        "        # -- Compute all file hashes\n",
        "        file_hashes = {name: sha256file(path) for name, path in fileset.items()}\n",
        "        capsule_data[\"files\"] = file_hashes\n",
        "        # -- Capsule SHA: hash of (all .npy/.json/.lean data in sorted order)\n",
        "        cap_bytes = b''\n",
        "        for k in sorted(fileset.keys()):\n",
        "            with open(fileset[k],\"rb\") as f:\n",
        "                cap_bytes += f.read()\n",
        "        capsule_sha = sha256_bytes(cap_bytes)\n",
        "        capsule_data[\"capsule_sha256\"] = capsule_sha\n",
        "\n",
        "        # -- Archive into ZIP\n",
        "        capsule_name = f\"{context}_capsule.zip\"\n",
        "        capsule_fn = os.path.join(output_dir, capsule_name)\n",
        "        with zipfile.ZipFile(capsule_fn,\"w\",compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "            for fname, src in fileset.items():\n",
        "                zf.write(src, arcname=fname)\n",
        "            # manifest will be added after below\n",
        "        # Save manifest\n",
        "        manifest_fn = os.path.join(output_dir, f\"{context}_capsule_manifest.json\")\n",
        "        with open(manifest_fn, \"w\") as mf:\n",
        "            json.dump(capsule_data, mf, indent=2)\n",
        "        # Add manifest into zip\n",
        "        with zipfile.ZipFile(capsule_fn,\"a\",compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "            zf.write(manifest_fn,\"capsule_manifest.json\")\n",
        "        # Optionally: GPG-sign zip (placeholder)\n",
        "        if sign_gpg:\n",
        "            # For actual signing, replace this block\n",
        "            sigtxt = f\"signed-by-certificate-packager:{now}\"\n",
        "            sigfile = os.path.join(output_dir, f\"{context}_capsule_signature.txt\")\n",
        "            with open(sigfile, \"w\") as f:\n",
        "                f.write(sigtxt)\n",
        "            with zipfile.ZipFile(capsule_fn,\"a\",compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "                zf.write(sigfile, \"capsule_signature.txt\")\n",
        "        print(f\"[OK] Capsule created: {capsule_fn}\")\n",
        "        capsules.append({\n",
        "            \"context\": context,\n",
        "            \"capsule_zip\": capsule_fn,\n",
        "            \"capsule_manifest\": manifest_fn,\n",
        "            \"capsule_sha256\": capsule_sha\n",
        "        })\n",
        "\n",
        "    # ----------- Summarize ---------------\n",
        "    print(f\"Packaged {len(capsules)} archive capsules into {output_dir}.\")\n",
        "    # Master manifest\n",
        "    mani = {\n",
        "        \"capsules\": capsules,\n",
        "        \"timestamp\": now,\n",
        "        \"generator_source_hash\": generator_src_hash\n",
        "    }\n",
        "    with open(os.path.join(output_dir,\"capsule_manifest_master.json\"),\"w\") as f:\n",
        "        json.dump(mani, f, indent=2)\n",
        "    print(\"Master manifest written.\")\n",
        "\n",
        "##########################################\n",
        "\n",
        "def verify_capsules(capsule_dir=\"/content/output/capsules/\"):\n",
        "    print(f\"Verifying capsules in {capsule_dir} ...\")\n",
        "    manifests = glob.glob(os.path.join(capsule_dir,\"*_capsule_manifest.json\"))\n",
        "    zips = glob.glob(os.path.join(capsule_dir,\"*_capsule.zip\"))\n",
        "    for mani in manifests:\n",
        "        with open(mani,\"r\") as f:\n",
        "            cap = json.load(f)\n",
        "        capsule_sha = cap.get(\"capsule_sha256\")\n",
        "        # find ZIP\n",
        "        context = cap.get(\"context\")\n",
        "        zipfile_path = os.path.join(capsule_dir, f\"{context}_capsule.zip\")\n",
        "        if not os.path.exists(zipfile_path): fail(f\"Capsule zip missing: {zipfile_path}\")\n",
        "        # Check file hashes inside\n",
        "        with zipfile.ZipFile(zipfile_path,\"r\") as zf:\n",
        "            for fname, file_sha in cap[\"files\"].items():\n",
        "                try:\n",
        "                    data = zf.read(fname)\n",
        "                    if sha256_bytes(data) != file_sha:\n",
        "                        fail(f\"[{context}] Hash mismatch for {fname} inside {zipfile_path}\")\n",
        "                except KeyError:\n",
        "                    fail(f\"[{context}] File missing in archive: {fname}\")\n",
        "            # Manifest file:\n",
        "            mani_data = zf.read(\"capsule_manifest.json\")\n",
        "            if sha256_bytes(mani_data) != sha256_bytes(json.dumps(cap,sort_keys=True,indent=2).encode()):\n",
        "                print(f\"[WARN] Capsule manifest hash mismatch for {context}\")\n",
        "        # Check Lean cert\n",
        "        cert_fname = None\n",
        "        for fname in cap[\"files\"]:\n",
        "            if fname.endswith(\".lean\"):\n",
        "                cert_fname = fname\n",
        "        if cert_fname:\n",
        "            with zipfile.ZipFile(zipfile_path,\"r\") as zf:\n",
        "                cert_data = zf.read(cert_fname).decode(errors='ignore')\n",
        "                if \"theorem proof_invalid\" not in cert_data:\n",
        "                    fail(f\"[{context}] Lean certificate invalid in archive.\")\n",
        "    print(\"All capsules verified OK.\")\n",
        "\n",
        "##########################################\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(description=\"Pack and validate proof certificate capsules.\")\n",
        "    parser.add_argument(\"--summary\", type=str, default=\"/content/output/proof_summary.json\")\n",
        "    parser.add_argument(\"--output_dir\", type=str, default=\"/content/output/capsules/\")\n",
        "    parser.add_argument(\"--verify-only\", action=\"store_true\")\n",
        "    parser.add_argument(\"--sign-gpg\", action=\"store_true\")\n",
        "    parser.add_argument(\"--min_ris\", type=int, default=3)\n",
        "    args = parser.parse_args()\n",
        "    if args.verify_only:\n",
        "        verify_capsules(args.output_dir)\n",
        "    else:\n",
        "        package_capsules(\n",
        "            proof_summary_json=args.summary,\n",
        "            output_dir=args.output_dir,\n",
        "            verify_only=False,\n",
        "            min_ris=args.min_ris,\n",
        "            sign_gpg=args.sign_gpg\n",
        "        )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "-PVTnhQHVPaJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "442cc2d2-9101-4ed5-93c0-795c777a4f7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting certificate_packager.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile lean_validator.py\n",
        "#!/usr/bin/env python3\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import re\n",
        "import csv\n",
        "import json\n",
        "import glob\n",
        "import hashlib\n",
        "import argparse\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "from datetime import datetime\n",
        "\n",
        "# =================== Helper Functions ===================\n",
        "\n",
        "def sha256file(fn):\n",
        "    h = hashlib.sha256()\n",
        "    with open(fn, \"rb\") as f:\n",
        "        for chunk in iter(lambda: f.read(65536), b''):\n",
        "            h.update(chunk)\n",
        "    return h.hexdigest()\n",
        "\n",
        "def md5file(fn):\n",
        "    h = hashlib.md5()\n",
        "    with open(fn, \"rb\") as f:\n",
        "        for chunk in iter(lambda: f.read(65536), b''):\n",
        "            h.update(chunk)\n",
        "    return h.hexdigest()\n",
        "\n",
        "def get_lean_version():\n",
        "    try:\n",
        "        lean_version = subprocess.getoutput(\"lean --version\").strip()\n",
        "        if lean_version:\n",
        "            return lean_version\n",
        "    except Exception:\n",
        "        pass\n",
        "    return \"Lean unavailable (syntax-only mode)\"\n",
        "\n",
        "def run_lean_check(lean_path):\n",
        "    try:\n",
        "        completed = subprocess.run(['lean', '--check', lean_path], capture_output=True, text=True, timeout=15)\n",
        "        return completed.returncode, completed.stdout, completed.stderr\n",
        "    except Exception as ex:\n",
        "        return -99, \"\", f\"EXCEPTION: {ex}\"\n",
        "\n",
        "def parse_theorem_header(contents):\n",
        "    \"\"\"\n",
        "    Extract theorem name, type (\"false\" or \"true\"), and statement location.\n",
        "    \"\"\"\n",
        "    header_pattern = re.compile(r'theorem\\s+([A-Za-z0-9_]+)\\s*:\\s*([^:]+):=\\s*by', re.S)\n",
        "    m = header_pattern.search(contents)\n",
        "    if not m:\n",
        "        # fallback: more flexible for Lean 4 theorem syntax\n",
        "        header_pattern2 = re.compile(r'theorem\\s+([A-Za-z0-9_]+)\\s*:\\s*(.*?)\\s*:=\\s*by', re.S)\n",
        "        m = header_pattern2.search(contents)\n",
        "    if m:\n",
        "        name = m.group(1).strip()\n",
        "        thm_type = m.group(2).strip()\n",
        "        is_false = \"false\" in thm_type\n",
        "        is_true = \"true\" in thm_type\n",
        "        start = m.end()\n",
        "        return name, (is_false, is_true), start\n",
        "    return None, (None, None), -1\n",
        "\n",
        "def extract_proof_body(contents):\n",
        "    \"\"\"\n",
        "    Everything after ':= by'\n",
        "    \"\"\"\n",
        "    sp = contents.split(\":= by\",1)\n",
        "    if len(sp)<2:\n",
        "        return \"\"\n",
        "    return sp[1].strip()\n",
        "\n",
        "def count_proof_steps(body):\n",
        "    return len([line for line in body.splitlines() if line.strip() and not line.strip().startswith(\"--\")])\n",
        "\n",
        "def classify_lean_error(stderr):\n",
        "    if not stderr:\n",
        "        return None\n",
        "    if \"unknown identifier\" in stderr.lower():\n",
        "        return \"Unknown Identifier\"\n",
        "    if \"syntax error\" in stderr.lower():\n",
        "        return \"Syntax Error\"\n",
        "    if \"contradiction\" in stderr.lower():\n",
        "        return \"Contradiction\"\n",
        "    if \"timeout\" in stderr.lower():\n",
        "        return \"Timeout/Tactic Fail\"\n",
        "    if \"error\" in stderr.lower():\n",
        "        return \"General Error\"\n",
        "    return \"Unknown\"\n",
        "\n",
        "def load_json_if_exists(path):\n",
        "    if not os.path.exists(path): return None\n",
        "    with open(path,\"r\") as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def smart_str(x):\n",
        "    if isinstance(x, str): return x\n",
        "    if isinstance(x, (list, dict)): return json.dumps(x)\n",
        "    return str(x)\n",
        "\n",
        "# =================== Main Validation ====================\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(description=\"Lean certificate validator and proof auditor\")\n",
        "    parser.add_argument(\"--dir\", type=str, required=True, help=\"Directory with .lean files\")\n",
        "    parser.add_argument(\"--strict\", action=\"store_true\", default=False)\n",
        "    parser.add_argument(\"--check_duplicate_ast\", action=\"store_true\", default=False)\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    root = args.dir\n",
        "    lean_files = sorted(glob.glob(os.path.join(root, \"**/*.lean\"), recursive=True))\n",
        "\n",
        "    lean_version = get_lean_version()\n",
        "    print(f\"Lean version: {lean_version}\")\n",
        "\n",
        "    results = []\n",
        "    context_proofbody_map = dict()\n",
        "    ast_hash_map = defaultdict(list)\n",
        "    duplicates = []\n",
        "    vacuous = []\n",
        "    config_mismatches = []\n",
        "    fail_compiles = []\n",
        "    lean_hash_set = set()\n",
        "\n",
        "    for lf in lean_files:\n",
        "        d = {}\n",
        "        d['lean_path'] = lf\n",
        "        d['lean_sha256'] = sha256file(lf)\n",
        "        d['lean_md5'] = md5file(lf)\n",
        "        lean_hash_set.add(d['lean_sha256'])\n",
        "        with open(lf,\"r\") as f:\n",
        "            contents = f.read()\n",
        "        d['lean_size_bytes'] = len(contents.encode())\n",
        "        theorem_name, (is_false, is_true), thmbody_start = parse_theorem_header(contents)\n",
        "        d['theorem_name'] = theorem_name\n",
        "        d['proves_false'] = bool(is_false)\n",
        "        d['proves_true'] = bool(is_true)\n",
        "        proof_body = extract_proof_body(contents)\n",
        "        d['proof_lines'] = count_proof_steps(proof_body)\n",
        "        d['proof_body_ast_hash'] = hashlib.sha256(proof_body.encode()).hexdigest()\n",
        "        if args.check_duplicate_ast:\n",
        "            ast_hash_map[d['proof_body_ast_hash']].append((lf,theorem_name))\n",
        "        d['lean_version'] = lean_version\n",
        "        # Trivial/vacuous proof check:\n",
        "        tauto_match = re.match(r'^\\s*(contradiction|trivial)\\s*$', proof_body,re.I)\n",
        "        d['is_trivial'] = bool(tauto_match) or \\\n",
        "            (d['proves_true'] and d['proof_lines']<=1)\n",
        "        # Associated config\n",
        "        cfg_path = lf.replace(\".lean\", \"_config.json\")\n",
        "        config = load_json_if_exists(cfg_path)\n",
        "        d['config_path'] = cfg_path if config else None\n",
        "        d['has_config'] = bool(config)\n",
        "        context_hash = config.get(\"context_full\") or config.get(\"context\") if config else None\n",
        "        d[\"context_config\"] = context_hash\n",
        "        d['config_field_type'] = config.get(\"type\") if config else \"unknown\"\n",
        "        d['config_seed'] = smart_str(config.get(\"params\",{}).get(\"seed\")) if config else \"\"\n",
        "        d['config_hash'] = config.get(\"hash_sha256\") or config.get(\"cx_hash\") if config else None\n",
        "        # RIS scoring\n",
        "        RIS = 0\n",
        "        # 1. Compiles under Lean\n",
        "        rc, out, err = run_lean_check(lf)\n",
        "        d['lean_compile_returncode'] = rc\n",
        "        d['lean_stdout'] = out\n",
        "        d['lean_stderr'] = err\n",
        "        d['lean_stderr_hash'] = hashlib.sha256((err or \"\").encode()).hexdigest()\n",
        "        d['lean_check_status'] = (\"PASS\" if rc==0 else \"FAIL\")\n",
        "        if rc==0:\n",
        "            RIS += 1\n",
        "        else:\n",
        "            fail_compiles.append(lf)\n",
        "        # 2. Config exists and matches SHA (if possible)\n",
        "        if config and (\n",
        "            d['lean_sha256'] == d['config_hash'] or not d['config_hash']\n",
        "        ):\n",
        "            RIS += 1\n",
        "        else:\n",
        "            config_mismatches.append(lf)\n",
        "        # 3. Theorem name includes context hash\n",
        "        if theorem_name and context_hash and context_hash in theorem_name:\n",
        "            RIS += 1\n",
        "        else:\n",
        "            config_mismatches.append(lf)\n",
        "        # 4. Proof is not trivial/vacuous\n",
        "        if not d['is_trivial'] and d['proves_false']:\n",
        "            RIS += 1\n",
        "        else:\n",
        "            vacuous.append(lf)\n",
        "        # 5. Unique proof body\n",
        "        is_unique = (ast_hash_map[d['proof_body_ast_hash']]==[(lf, theorem_name)]) if args.check_duplicate_ast else True\n",
        "        if is_unique:\n",
        "            RIS += 1\n",
        "        else:\n",
        "            duplicates.append(lf)\n",
        "        d['RIS'] = RIS\n",
        "\n",
        "        # Redundancy check (populate later)\n",
        "        context_proofbody_map[(context_hash or theorem_name)] = d['proof_body_ast_hash']\n",
        "        # Collect theorem duplication\n",
        "        results.append(d)\n",
        "\n",
        "    # After scan: detect duplicate ASTs (ignore self)\n",
        "    if args.check_duplicate_ast:\n",
        "        for proof_hash, lst in ast_hash_map.items():\n",
        "            if len(lst)>1:\n",
        "                for lf, thm in lst:\n",
        "                    for d in results:\n",
        "                        if d['lean_path']==lf:\n",
        "                            d['is_duplicate_ast'] = True\n",
        "                duplicates.extend([x[0] for x in lst if x[0] not in duplicates])\n",
        "\n",
        "    # ==== Export .csv ====\n",
        "    summary_csv = os.path.join(root, \"lean_validation_summary.csv\")\n",
        "    fieldnames = [\n",
        "        \"lean_path\",\"lean_sha256\",\"lean_md5\",\"theorem_name\",\n",
        "        \"proves_false\",\"proves_true\",\"proof_lines\",\"proof_body_ast_hash\",\n",
        "        \"lean_version\",\"has_config\",\"context_config\",\"config_field_type\",\n",
        "        \"config_seed\",\"config_hash\",\"lean_check_status\",\"RIS\"\n",
        "    ]\n",
        "    with open(summary_csv,\"w\",newline=\"\") as f:\n",
        "        w = csv.DictWriter(f,fieldnames=fieldnames)\n",
        "        w.writeheader()\n",
        "        for d in results:\n",
        "            w.writerow({k:smart_str(d.get(k,\"\")) for k in fieldnames})\n",
        "\n",
        "    # ==== Export .md report ====\n",
        "    summary_md = os.path.join(root, \"lean_validation_report.md\")\n",
        "    with open(summary_md,\"w\") as f:\n",
        "        f.write(f\"# Lean Certificate Validation Report\\n\")\n",
        "        f.write(f\"Audit time: {datetime.utcnow().isoformat()}Z\\n\")\n",
        "        f.write(f\"Target directory: `{root}`\\n\")\n",
        "        f.write(f\"Lean version: {lean_version}\\n\\n\")\n",
        "        f.write(f\"Total certificates: {len(results)}\\n\\n\")\n",
        "        f.write(\"## Failures to compile:\\n\")\n",
        "        for fn in fail_compiles:\n",
        "            f.write(f\"- {fn}\\n\")\n",
        "        f.write(\"\\n## Config mismatches or theorem/context inconsistency:\\n\")\n",
        "        for fn in config_mismatches:\n",
        "            f.write(f\"- {fn}\\n\")\n",
        "        f.write(\"\\n## Vacuous/trivial certificates:\\n\")\n",
        "        for fn in vacuous:\n",
        "            f.write(f\"- {fn}\\n\")\n",
        "        if args.check_duplicate_ast:\n",
        "            f.write(\"\\n## Duplicate AST bodies detected (possible redundancy):\\n\")\n",
        "            for fn in duplicates:\n",
        "                f.write(f\"- {fn}\\n\")\n",
        "        f.write(\"\\n## RIS Score Histogram\\n\")\n",
        "        ris_hist = defaultdict(int)\n",
        "        for d in results:\n",
        "            ris_hist[d['RIS']] += 1\n",
        "        for k in sorted(ris_hist):\n",
        "            f.write(f\"- RIS={k}: {ris_hist[k]}\\n\")\n",
        "        f.write(\"\\n## Certificates with RIS < 5\\n\")\n",
        "        for d in results:\n",
        "            if d['RIS']<5:\n",
        "                f.write(f\"- {d['lean_path']} (RIS={d['RIS']})\\n\")\n",
        "        f.write(\"\\n\\nDetail per certificate is available in the CSV.\")\n",
        "\n",
        "    # ==== Export .json metadata ====\n",
        "    summary_json = os.path.join(root, \"lean_validator_metadata.json\")\n",
        "    for d in results:\n",
        "        # Truncate large keys to keep JSON readable\n",
        "        if 'lean_stdout' in d and len(d['lean_stdout'])>500: d['lean_stdout'] = d['lean_stdout'][:500] + \"···\"\n",
        "        if 'lean_stderr' in d and len(d['lean_stderr'])>500: d['lean_stderr'] = d['lean_stderr'][:500] + \"···\"\n",
        "    with open(summary_json, \"w\") as f:\n",
        "        json.dump({\"certificates\": results, \"lean_version\": lean_version, \"timestamp\": datetime.utcnow().isoformat()}, f, indent=2)\n",
        "\n",
        "    print(f\"\\nSummary:\")\n",
        "    print(f\"- CSV: {summary_csv}\")\n",
        "    print(f\"- Markdown report: {summary_md}\")\n",
        "    print(f\"- Metadata: {summary_json}\")\n",
        "    if args.strict and (fail_compiles or duplicates or vacuous or config_mismatches):\n",
        "        print(\"Strict mode: at least one error detected. Failing.\")\n",
        "        sys.exit(99)\n",
        "    print(\"Done.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "PT9kGguyiebI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d0c24ee-6be2-470d-d05b-ba53175e424c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting lean_validator.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile generate_random_fields.py\n",
        "#!/usr/bin/env python3\n",
        "import os\n",
        "import sys\n",
        "import hashlib\n",
        "import json\n",
        "import time\n",
        "import socket\n",
        "import argparse\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from functools import wraps\n",
        "try:\n",
        "    import matplotlib.pyplot as plt\n",
        "except ImportError:\n",
        "    plt = None\n",
        "\n",
        "# ================= Registry & Decorators ====================\n",
        "\n",
        "class FieldRegistry:\n",
        "    def __init__(self):\n",
        "        self.generators = {}\n",
        "    def register(self, name):\n",
        "        def wrapper(func):\n",
        "            self.generators[name] = func\n",
        "            return func\n",
        "        return wrapper\n",
        "    def generate(self, name, **params):\n",
        "        if name not in self.generators:\n",
        "            raise ValueError(f\"Unknown field type: {name}\")\n",
        "        return self.generators[name](**params)\n",
        "\n",
        "field_registry = FieldRegistry()\n",
        "\n",
        "def validate_field(fn):\n",
        "    \"\"\"Decorator for generator functions to check output shape, finiteness, divergence.\"\"\"\n",
        "    @wraps(fn)\n",
        "    def wrapper(*args, **kwargs):\n",
        "        omega = fn(*args, **kwargs)\n",
        "        if omega.shape[0] != 3 or len(omega.shape) != 4:\n",
        "            raise ValueError(f\"Field shape invalid: expected (3,N,N,N), got {omega.shape}\")\n",
        "        if not np.isfinite(omega).all():\n",
        "            raise ValueError(\"Field contains inf/nan values\")\n",
        "        if np.linalg.norm(omega) < 1e-8:\n",
        "            raise ValueError(\"Field norm too small\")\n",
        "        # Divergence-free test (optional unless forced)\n",
        "        if kwargs.get('enforce_divergence', True):\n",
        "            N = omega.shape[1]\n",
        "            dx = 1.0/N\n",
        "            div = (\n",
        "                np.gradient(omega[0], dx, axis=0) +\n",
        "                np.gradient(omega[1], dx, axis=1) +\n",
        "                np.gradient(omega[2], dx, axis=2)\n",
        "            )\n",
        "            if np.abs(div).mean() >= 1e-3:\n",
        "                raise ValueError(\"Field failed divergence test: mean(abs(div)) >= 1e-3\")\n",
        "        return omega\n",
        "    return wrapper\n",
        "\n",
        "# ============= Field Generators =========================\n",
        "\n",
        "@field_registry.register(\"shell_random\")\n",
        "@validate_field\n",
        "def shell_random(j=8, N=512, seed=42, amplitude=1.0, **_):\n",
        "    \"\"\"Divergence-free field with energy in shell |k| ~ 2^j.\"\"\"\n",
        "    np.random.seed(seed)\n",
        "    F = np.zeros((3, N, N, N), dtype=np.complex64)\n",
        "    freq = np.fft.fftfreq(N)*N\n",
        "    Kx, Ky, Kz = np.meshgrid(freq, freq, freq, indexing='ij')\n",
        "    K2 = Kx**2 + Ky**2 + Kz**2\n",
        "    mask = (K2 >= 2**(2*j)) & (K2 < 2**(2*(j+1)))\n",
        "    if not np.any(mask):\n",
        "        max_freq = np.max(np.abs(freq))\n",
        "        j_adj = int(np.floor(np.log2(max_freq)))\n",
        "        mask = (K2 >= 2**(2*j_adj)) & (K2 < 2**(2*(j_adj+1)))\n",
        "    idx = np.nonzero(mask)\n",
        "    if idx[0].size > 0:\n",
        "        kvec = np.vstack([Kx[idx], Ky[idx], Kz[idx]])  # shape (3, M)\n",
        "        norm_k = np.linalg.norm(kvec, axis=0)\n",
        "        valid = norm_k >= 1e-7\n",
        "        if np.any(valid):\n",
        "            kvec_valid = kvec[:, valid]\n",
        "            norm_k_valid = norm_k[valid]\n",
        "            k_unit = kvec_valid / norm_k_valid  # shape (3, M_valid)\n",
        "            M_valid = k_unit.shape[1]\n",
        "            u = np.random.randn(3, M_valid) + 1j * np.random.randn(3, M_valid)\n",
        "            dot = np.sum(u * k_unit, axis=0)\n",
        "            u = u - k_unit * dot\n",
        "            indices = np.array(np.nonzero(mask)).T  # shape (M, 3)\n",
        "            indices_valid = indices[valid]\n",
        "            F[:, indices_valid[:,0], indices_valid[:,1], indices_valid[:,2]] = u\n",
        "    norm_F = np.sqrt((np.abs(F)**2).sum())\n",
        "    if norm_F == 0:\n",
        "        raise ValueError(\"No energy in selected Fourier modes; adjust 'j' or 'N'.\")\n",
        "    F /= norm_F\n",
        "    F *= amplitude\n",
        "    omega = np.fft.ifftn(F, axes=(1,2,3)).real.astype(np.float32)\n",
        "    return omega\n",
        "\n",
        "@field_registry.register(\"multi_shell\")\n",
        "@validate_field\n",
        "def multi_shell(j1=6, j2=9, N=512, seed=888, amplitude=1.0, **_):\n",
        "    \"\"\"Superpose two shells.\"\"\"\n",
        "    a = shell_random(j=j1, N=N, seed=seed, amplitude=amplitude/2, enforce_divergence=False)\n",
        "    b = shell_random(j=j2, N=N, seed=seed+1, amplitude=amplitude/2, enforce_divergence=False)\n",
        "    omega = a + b\n",
        "    return omega\n",
        "\n",
        "@field_registry.register(\"aligned_noise\")\n",
        "@validate_field\n",
        "def aligned_noise(N=512, seed=123, amplitude=1.0, **_):\n",
        "    np.random.seed(seed)\n",
        "    omega = np.random.randn(3, N, N, N)\n",
        "    v = omega.reshape(3,-1).mean(axis=1)\n",
        "    if np.linalg.norm(v) > 1e-8:\n",
        "        theta = np.arccos(np.dot(v, [1,0,0])/np.linalg.norm(v))\n",
        "        if theta > 1e-5:\n",
        "            axis = np.cross(v, [1,0,0])\n",
        "            axis = axis/np.linalg.norm(axis)\n",
        "            from scipy.spatial.transform import Rotation as R\n",
        "            rot = R.from_rotvec(axis*theta)\n",
        "            omega = np.tensordot(rot.as_matrix(), omega, axes=([1],[0]))\n",
        "    omega *= amplitude / np.sqrt(np.mean(omega**2)+1e-12)\n",
        "    return omega.astype(np.float32)\n",
        "\n",
        "@field_registry.register(\"white_noise\")\n",
        "@validate_field\n",
        "def white_noise(N=512, seed=77, amplitude=1.0, **_):\n",
        "    np.random.seed(seed)\n",
        "    omega = amplitude * np.random.randn(3, N, N, N).astype(np.float32)\n",
        "    return omega\n",
        "\n",
        "@field_registry.register(\"vortex_tube\")\n",
        "@validate_field\n",
        "def vortex_tube(N=512, amplitude=1.0, **_):\n",
        "    x = np.linspace(-1,1,N,endpoint=False)\n",
        "    X,Y,Z = np.meshgrid(x,x,x,indexing='ij')\n",
        "    r = np.sqrt(Y**2+Z**2)\n",
        "    tube = amplitude * np.exp(-30*r**2)\n",
        "    omega = np.zeros((3,N,N,N), dtype=np.float32)\n",
        "    omega[0] = tube\n",
        "    return omega\n",
        "\n",
        "@field_registry.register(\"boundary_layer\")\n",
        "@validate_field\n",
        "def boundary_layer(N=512, amplitude=1.0, **_):\n",
        "    x = np.linspace(-1,1,N,endpoint=False)\n",
        "    Z = np.meshgrid(x,x,x,indexing='ij')[2]\n",
        "    layer = amplitude * np.exp(-200*Z**2)\n",
        "    omega = np.zeros((3,N,N,N), dtype=np.float32)\n",
        "    omega[1] = layer\n",
        "    return omega\n",
        "\n",
        "@field_registry.register(\"adversarial_mix\")\n",
        "@validate_field\n",
        "def adversarial_mix(N=512, j=3, j2=6, seed=444, amplitude=1.0, **_):\n",
        "    field1 = shell_random(j=j, N=N, seed=seed, amplitude=amplitude/2, enforce_divergence=False)\n",
        "    field2 = white_noise(N=N, seed=seed+993, amplitude=amplitude/4, enforce_divergence=False)\n",
        "    field3 = vortex_tube(N=N, amplitude=amplitude/4, enforce_divergence=False)\n",
        "    omega = field1 + field2 + field3\n",
        "    return omega\n",
        "\n",
        "# ============ Evolution Stepper =======================\n",
        "\n",
        "def proof_evolve(omega_t, dt=1e-4, magnitude=0.01, seed=2023):\n",
        "    np.random.seed(hash(float(np.sum(omega_t))+dt+seed) % (2**32-1))\n",
        "    noise = magnitude * np.random.randn(*omega_t.shape)\n",
        "    return omega_t + dt*noise\n",
        "\n",
        "# ========== Hashing & Metadata ========================\n",
        "\n",
        "def get_sha256(arr):\n",
        "    m = hashlib.sha256()\n",
        "    m.update(arr.tobytes())\n",
        "    return m.hexdigest()\n",
        "\n",
        "def get_md5(arr):\n",
        "    m = hashlib.md5()\n",
        "    m.update(arr.astype(np.float32).tobytes())\n",
        "    return m.hexdigest()\n",
        "\n",
        "def get_src_hash(fn):\n",
        "    co = fn.__code__\n",
        "    code_bytes = co.co_code\n",
        "    h = hashlib.sha1(code_bytes).hexdigest()\n",
        "    return h\n",
        "\n",
        "def get_git_commit():\n",
        "    try:\n",
        "        import subprocess\n",
        "        commit = subprocess.check_output(['git', 'rev-parse', 'HEAD'], text=True).strip()\n",
        "        return commit\n",
        "    except Exception:\n",
        "        return \"unknown\"\n",
        "\n",
        "# ========== CLI & Main ===============================\n",
        "\n",
        "def visualize_field(omega, out_fn=\"preview_slice.png\"):\n",
        "    import matplotlib.pyplot as plt\n",
        "    N = omega.shape[1]\n",
        "    mid = N//2\n",
        "    fig, axs = plt.subplots(1, 3, figsize=(10, 3))\n",
        "    for i, comp in enumerate(['x', 'y', 'z']):\n",
        "        im = axs[i].imshow(omega[i, mid], cmap='RdBu', vmax=np.abs(omega[i, mid]).max())\n",
        "        axs[i].set_title(f\"$\\\\omega_{comp}$ (z={mid})\")\n",
        "        plt.colorbar(im, ax=axs[i])\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out_fn)\n",
        "    plt.close(fig)\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(description=\"Generate reproducible random vorticity fields for proof engine.\")\n",
        "    parser.add_argument('--type', type=str, required=True, help=\"Field type\")\n",
        "    parser.add_argument('--j', type=int, help=\"Shell/Multi\")\n",
        "    parser.add_argument('--j1', type=int)\n",
        "    parser.add_argument('--j2', type=int)\n",
        "    parser.add_argument('--seed', type=int, default=42)\n",
        "    parser.add_argument('--amplitude', type=float, default=1.0)\n",
        "    parser.add_argument('--N', type=int, default=512)\n",
        "    parser.add_argument('--out', type=str, default=\"/content/omega_t.npy\")\n",
        "    parser.add_argument('--visualize', action='store_true')\n",
        "    parser.add_argument('--evolve', action='store_true')\n",
        "    parser.add_argument('--export_config', action='store_true')\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    params = {}\n",
        "    argsvars = vars(args)\n",
        "    for k in argsvars:\n",
        "        v = argsvars[k]\n",
        "        if k in {'visualize', 'evolve', 'out', 'export_config', 'type'} or v is None:\n",
        "            continue\n",
        "        params[k] = v\n",
        "\n",
        "    ftype = args.type\n",
        "    if ftype not in field_registry.generators:\n",
        "        raise ValueError(f'Field type not recognized: {ftype}')\n",
        "    fn = field_registry.generators[ftype]\n",
        "    import inspect\n",
        "    valid_args = inspect.getfullargspec(fn).args\n",
        "    fn_params = {k: params[k] for k in params if k in valid_args}\n",
        "\n",
        "    omega = field_registry.generate(ftype, **fn_params)\n",
        "    assert omega.shape == (3, args.N, args.N, args.N)\n",
        "    save_path = args.out\n",
        "    np.save(save_path, omega)\n",
        "\n",
        "    sha256 = get_sha256(omega)\n",
        "    md5 = get_md5(omega)\n",
        "    src_hash = get_src_hash(fn)\n",
        "    git_commit = get_git_commit()\n",
        "    ts = datetime.utcnow().replace(microsecond=0).isoformat() + \"Z\"\n",
        "    hostname = socket.gethostname()\n",
        "\n",
        "    if args.visualize and plt is not None:\n",
        "        out_img = os.path.splitext(save_path)[0] + \"_preview.png\"\n",
        "        visualize_field(omega, out_img)\n",
        "\n",
        "    if args.evolve:\n",
        "        omega_tpdt = proof_evolve(omega)\n",
        "        out_tpdt = os.path.splitext(save_path)[0] + \"_tpdt.npy\"\n",
        "        np.save(out_tpdt, omega_tpdt)\n",
        "\n",
        "    if args.export_config:\n",
        "        config = {\n",
        "            \"type\": ftype,\n",
        "            \"params\": fn_params,\n",
        "            \"shape\": list(omega.shape),\n",
        "            \"hash_sha256\": sha256,\n",
        "            \"float_hash_md5\": md5,\n",
        "            \"generator_source_hash\": src_hash,\n",
        "            \"timestamp\": ts,\n",
        "            \"git_commit\": git_commit,\n",
        "            \"hostname\": hostname\n",
        "        }\n",
        "        config_path = os.path.splitext(save_path)[0] + \"_config.json\"\n",
        "        with open(config_path, \"w\") as f:\n",
        "            json.dump(config, f, indent=2)\n",
        "        print(f\"Config saved to {config_path}\")\n",
        "\n",
        "    print(f\"Field '{ftype}' written to {save_path}\")\n",
        "    print(f\"SHA256: {sha256}\")\n",
        "    print(f\"MD5(float32): {md5}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dm0Q9Nqjmf9x",
        "outputId": "d934ffb9-acdf-4b85-e898-b19e6281b65a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting generate_random_fields.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Generate a field with real energy in j=8 shell\n",
        "!python3 generate_random_fields.py --type multi_shell --j1 6 --j2 9 --N 512 --seed 123 --evolve --visualize --export_config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cql16U5aQILp",
        "outputId": "492abcae-e25f-4d6a-c87d-38758edff03c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "Config saved to /content/omega_t_config.json\n",
            "Field 'multi_shell' written to /content/omega_t.npy\n",
            "SHA256: 7d09439c791610e3f39c3b6ebac02e1880f15f22aeabffb315916be8980dc4f4\n",
            "MD5(float32): 635653f02ace9faa614018ead6c5b45a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python proof_colab.py --input omega_t.npy --input2 omega_t_tpdt.npy --alpha 2.5 --j_min 6 --j_max 9 --timesteps 100 --strict --export_cert --plot --run_validation_checks\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tN4CrEPPBnKB",
        "outputId": "4cabf7d0-8569-416d-b84e-ce1eb5d176d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using CuPy (GPU) for arrays and FFTs\n",
            "Loaded omega_t from omega_t.npy, shape (3, 512, 512, 512).\n",
            "Loaded omega_tpdt from omega_t_tpdt.npy, shape (3, 512, 512, 512).\n",
            "Running 100 time steps with dt=0.0001 and verifying at each step.\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 5.02e-15\n",
            "\n",
            "Recursive norm Y(t):          0.0103605 ± 1.04e-09\n",
            "sup_j alignment:              0.500082 ± 5.00e-08\n",
            "dY/dt:                        -11.7085 ± 1.96e-05\n",
            "RHS:                          0.0713894 ± 2.14e-08\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_000.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 4.57e-15\n",
            "\n",
            "Recursive norm Y(t):          0.00939181 ± 9.39e-10\n",
            "sup_j alignment:              0.500079 ± 5.00e-08\n",
            "dY/dt:                        -10.1023 ± 1.78e-05\n",
            "RHS:                          0.0586632 ± 1.76e-08\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_001.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 4.67e-15\n",
            "\n",
            "Recursive norm Y(t):          0.00853534 ± 8.54e-10\n",
            "sup_j alignment:              0.500078 ± 5.00e-08\n",
            "dY/dt:                        -8.86468 ± 1.62e-05\n",
            "RHS:                          0.0484513 ± 1.45e-08\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_002.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 4.71e-15\n",
            "\n",
            "Recursive norm Y(t):          0.00780917 ± 7.81e-10\n",
            "sup_j alignment:              0.500076 ± 5.00e-08\n",
            "dY/dt:                        -8.24931 ± 1.48e-05\n",
            "RHS:                          0.0405574 ± 1.22e-08\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_003.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 4.56e-15\n",
            "\n",
            "Recursive norm Y(t):          0.00717118 ± 7.17e-10\n",
            "sup_j alignment:              0.500077 ± 5.00e-08\n",
            "dY/dt:                        -7.90071 ± 1.36e-05\n",
            "RHS:                          0.0342012 ± 1.03e-08\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_004.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 4.63e-15\n",
            "\n",
            "Recursive norm Y(t):          0.00659029 ± 6.59e-10\n",
            "sup_j alignment:              0.500076 ± 5.00e-08\n",
            "dY/dt:                        -7.56713 ± 1.24e-05\n",
            "RHS:                          0.0288846 ± 8.67e-09\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_005.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 4.18e-15\n",
            "\n",
            "Recursive norm Y(t):          0.00606097 ± 6.06e-10\n",
            "sup_j alignment:              0.500076 ± 5.00e-08\n",
            "dY/dt:                        -7.24661 ± 1.14e-05\n",
            "RHS:                          0.0244309 ± 7.33e-09\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_006.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 4.32e-15\n",
            "\n",
            "Recursive norm Y(t):          0.00557829 ± 5.58e-10\n",
            "sup_j alignment:              0.500075 ± 5.00e-08\n",
            "dY/dt:                        -6.9377 ± 1.05e-05\n",
            "RHS:                          0.0206945 ± 6.21e-09\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_007.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 4.23e-15\n",
            "\n",
            "Recursive norm Y(t):          0.00513782 ± 5.14e-10\n",
            "sup_j alignment:              0.500074 ± 5.00e-08\n",
            "dY/dt:                        -6.63939 ± 9.61e-06\n",
            "RHS:                          0.0175553 ± 5.27e-09\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_008.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 4.35e-15\n",
            "\n",
            "Recursive norm Y(t):          0.0047356 ± 4.74e-10\n",
            "sup_j alignment:              0.500072 ± 5.00e-08\n",
            "dY/dt:                        -6.35097 ± 8.84e-06\n",
            "RHS:                          0.014914 ± 4.48e-09\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_009.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 4.07e-15\n",
            "\n",
            "Recursive norm Y(t):          0.00436805 ± 4.37e-10\n",
            "sup_j alignment:              0.50007 ± 5.00e-08\n",
            "dY/dt:                        -6.07197 ± 8.13e-06\n",
            "RHS:                          0.0126887 ± 3.81e-09\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "/content/proof_colab.py:411: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
            "  fig, axs = plt.subplots(2,1,figsize=(7,6), sharex=True)\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_010.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 4.03e-15\n",
            "\n",
            "Recursive norm Y(t):          0.00403199 ± 4.03e-10\n",
            "sup_j alignment:              0.500069 ± 5.00e-08\n",
            "dY/dt:                        -5.80208 ± 7.48e-06\n",
            "RHS:                          0.0108113 ± 3.24e-09\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_011.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 3.93e-15\n",
            "\n",
            "Recursive norm Y(t):          0.00372452 ± 3.72e-10\n",
            "sup_j alignment:              0.500069 ± 5.00e-08\n",
            "dY/dt:                        -5.54108 ± 6.89e-06\n",
            "RHS:                          0.00922528 ± 2.77e-09\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_012.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 4.27e-15\n",
            "\n",
            "Recursive norm Y(t):          0.00344305 ± 3.44e-10\n",
            "sup_j alignment:              0.500068 ± 5.00e-08\n",
            "dY/dt:                        -5.28888 ± 6.36e-06\n",
            "RHS:                          0.00788358 ± 2.37e-09\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_013.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 3.96e-15\n",
            "\n",
            "Recursive norm Y(t):          0.00318524 ± 3.19e-10\n",
            "sup_j alignment:              0.500067 ± 5.00e-08\n",
            "dY/dt:                        -5.04539 ± 5.87e-06\n",
            "RHS:                          0.00674712 ± 2.03e-09\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_014.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 3.85e-15\n",
            "\n",
            "Recursive norm Y(t):          0.00294897 ± 2.95e-10\n",
            "sup_j alignment:              0.500066 ± 5.00e-08\n",
            "dY/dt:                        -4.81055 ± 5.42e-06\n",
            "RHS:                          0.00578324 ± 1.74e-09\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_015.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 4.36e-15\n",
            "\n",
            "Recursive norm Y(t):          0.00273233 ± 2.73e-10\n",
            "sup_j alignment:              0.500066 ± 5.00e-08\n",
            "dY/dt:                        -4.58431 ± 5.01e-06\n",
            "RHS:                          0.00496472 ± 1.49e-09\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_016.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 4.10e-15\n",
            "\n",
            "Recursive norm Y(t):          0.00253358 ± 2.53e-10\n",
            "sup_j alignment:              0.500066 ± 5.00e-08\n",
            "dY/dt:                        -4.36664 ± 4.63e-06\n",
            "RHS:                          0.00426871 ± 1.28e-09\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_017.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 3.73e-15\n",
            "\n",
            "Recursive norm Y(t):          0.00235116 ± 2.35e-10\n",
            "sup_j alignment:              0.500066 ± 5.00e-08\n",
            "dY/dt:                        -4.15746 ± 4.29e-06\n",
            "RHS:                          0.00367612 ± 1.10e-09\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_018.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 3.85e-15\n",
            "\n",
            "Recursive norm Y(t):          0.00218365 ± 2.18e-10\n",
            "sup_j alignment:              0.500065 ± 5.00e-08\n",
            "dY/dt:                        -3.9567 ± 3.97e-06\n",
            "RHS:                          0.00317094 ± 9.52e-10\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_019.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 3.93e-15\n",
            "\n",
            "Recursive norm Y(t):          0.00202976 ± 2.03e-10\n",
            "sup_j alignment:              0.500063 ± 5.00e-08\n",
            "dY/dt:                        -3.68185 ± 3.69e-06\n",
            "RHS:                          0.00273972 ± 8.22e-10\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_020.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 3.89e-15\n",
            "\n",
            "Recursive norm Y(t):          0.00188831 ± 1.89e-10\n",
            "sup_j alignment:              0.500062 ± 5.00e-08\n",
            "dY/dt:                        -3.39922 ± 3.44e-06\n",
            "RHS:                          0.00237116 ± 7.12e-10\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_021.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 3.58e-15\n",
            "\n",
            "Recursive norm Y(t):          0.00175824 ± 1.76e-10\n",
            "sup_j alignment:              0.500062 ± 5.00e-08\n",
            "dY/dt:                        -3.14093 ± 3.20e-06\n",
            "RHS:                          0.00205575 ± 6.17e-10\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_022.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 3.64e-15\n",
            "\n",
            "Recursive norm Y(t):          0.00163859 ± 1.64e-10\n",
            "sup_j alignment:              0.500061 ± 5.00e-08\n",
            "dY/dt:                        -2.90487 ± 2.99e-06\n",
            "RHS:                          0.00178546 ± 5.36e-10\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_023.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 3.71e-15\n",
            "\n",
            "Recursive norm Y(t):          0.00152847 ± 1.53e-10\n",
            "sup_j alignment:              0.50006 ± 5.00e-08\n",
            "dY/dt:                        -2.68911 ± 2.79e-06\n",
            "RHS:                          0.00155353 ± 4.66e-10\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_024.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 3.53e-15\n",
            "\n",
            "Recursive norm Y(t):          0.00142708 ± 1.43e-10\n",
            "sup_j alignment:              0.50006 ± 5.00e-08\n",
            "dY/dt:                        -2.49187 ± 2.60e-06\n",
            "RHS:                          0.00135426 ± 4.06e-10\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_025.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 3.37e-15\n",
            "\n",
            "Recursive norm Y(t):          0.00133369 ± 1.33e-10\n",
            "sup_j alignment:              0.50006 ± 5.00e-08\n",
            "dY/dt:                        -2.31155 ± 2.44e-06\n",
            "RHS:                          0.00118281 ± 3.55e-10\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_026.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 3.67e-15\n",
            "\n",
            "Recursive norm Y(t):          0.00124763 ± 1.25e-10\n",
            "sup_j alignment:              0.50006 ± 5.00e-08\n",
            "dY/dt:                        -2.14666 ± 2.28e-06\n",
            "RHS:                          0.00103508 ± 3.11e-10\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_027.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 3.38e-15\n",
            "\n",
            "Recursive norm Y(t):          0.0011683 ± 1.17e-10\n",
            "sup_j alignment:              0.50006 ± 5.00e-08\n",
            "dY/dt:                        -1.99589 ± 2.14e-06\n",
            "RHS:                          0.000907628 ± 2.72e-10\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_028.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 3.38e-15\n",
            "\n",
            "Recursive norm Y(t):          0.00109513 ± 1.10e-10\n",
            "sup_j alignment:              0.50006 ± 5.00e-08\n",
            "dY/dt:                        -1.858 ± 2.00e-06\n",
            "RHS:                          0.000797503 ± 2.39e-10\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_029.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 3.52e-15\n",
            "\n",
            "Recursive norm Y(t):          0.00102763 ± 1.03e-10\n",
            "sup_j alignment:              0.50006 ± 5.00e-08\n",
            "dY/dt:                        -1.73187 ± 1.88e-06\n",
            "RHS:                          0.000702213 ± 2.11e-10\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_030.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 3.58e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000965322 ± 9.65e-11\n",
            "sup_j alignment:              0.500059 ± 5.00e-08\n",
            "dY/dt:                        -1.61649 ± 1.77e-06\n",
            "RHS:                          0.000619639 ± 1.86e-10\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_031.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 3.66e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000907789 ± 9.08e-11\n",
            "sup_j alignment:              0.500058 ± 5.00e-08\n",
            "dY/dt:                        -1.51093 ± 1.66e-06\n",
            "RHS:                          0.000547976 ± 1.64e-10\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_032.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 3.38e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000854641 ± 8.55e-11\n",
            "sup_j alignment:              0.500057 ± 5.00e-08\n",
            "dY/dt:                        -1.41434 ± 1.57e-06\n",
            "RHS:                          0.000485688 ± 1.46e-10\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_033.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 3.27e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000805524 ± 8.06e-11\n",
            "sup_j alignment:              0.500056 ± 5.00e-08\n",
            "dY/dt:                        -1.32494 ± 1.48e-06\n",
            "RHS:                          0.000431463 ± 1.30e-10\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_034.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 3.29e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000760112 ± 7.60e-11\n",
            "sup_j alignment:              0.500056 ± 5.00e-08\n",
            "dY/dt:                        -1.24241 ± 1.40e-06\n",
            "RHS:                          0.000384184 ± 1.15e-10\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_035.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 3.60e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000718107 ± 7.18e-11\n",
            "sup_j alignment:              0.500056 ± 5.00e-08\n",
            "dY/dt:                        -1.16675 ± 1.32e-06\n",
            "RHS:                          0.000342895 ± 1.03e-10\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_036.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 3.39e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000679237 ± 6.79e-11\n",
            "sup_j alignment:              0.500056 ± 5.00e-08\n",
            "dY/dt:                        -1.09738 ± 1.25e-06\n",
            "RHS:                          0.000306778 ± 9.21e-11\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_037.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 3.14e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000643251 ± 6.43e-11\n",
            "sup_j alignment:              0.500056 ± 5.00e-08\n",
            "dY/dt:                        -1.03376 ± 1.18e-06\n",
            "RHS:                          0.000275132 ± 8.26e-11\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_038.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 3.22e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000609921 ± 6.10e-11\n",
            "sup_j alignment:              0.500056 ± 5.00e-08\n",
            "dY/dt:                        -0.975392 ± 1.12e-06\n",
            "RHS:                          0.000247357 ± 7.43e-11\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_039.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 3.08e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000579035 ± 5.79e-11\n",
            "sup_j alignment:              0.500056 ± 5.00e-08\n",
            "dY/dt:                        -0.92183 ± 1.07e-06\n",
            "RHS:                          0.000222939 ± 6.69e-11\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_040.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.98e-15\n",
            "\n",
            "Recursive norm Y(t):          0.0005504 ± 5.50e-11\n",
            "sup_j alignment:              0.500056 ± 5.00e-08\n",
            "dY/dt:                        -0.872663 ± 1.01e-06\n",
            "RHS:                          0.000201433 ± 6.05e-11\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_041.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 3.22e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000523839 ± 5.24e-11\n",
            "sup_j alignment:              0.500055 ± 5.00e-08\n",
            "dY/dt:                        -0.827516 ± 9.65e-07\n",
            "RHS:                          0.00018246 ± 5.48e-11\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_042.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 3.08e-15\n",
            "\n",
            "Recursive norm Y(t):          0.00049919 ± 4.99e-11\n",
            "sup_j alignment:              0.500055 ± 5.00e-08\n",
            "dY/dt:                        -0.786043 ± 9.20e-07\n",
            "RHS:                          0.000165692 ± 4.97e-11\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_043.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.99e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000476302 ± 4.76e-11\n",
            "sup_j alignment:              0.500055 ± 5.00e-08\n",
            "dY/dt:                        -0.747931 ± 8.78e-07\n",
            "RHS:                          0.000150846 ± 4.53e-11\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_044.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 3.11e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000455038 ± 4.55e-11\n",
            "sup_j alignment:              0.500055 ± 5.00e-08\n",
            "dY/dt:                        -0.712893 ± 8.39e-07\n",
            "RHS:                          0.000137677 ± 4.13e-11\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_045.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.93e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000435272 ± 4.35e-11\n",
            "sup_j alignment:              0.500054 ± 5.00e-08\n",
            "dY/dt:                        -0.680666 ± 8.02e-07\n",
            "RHS:                          0.000125976 ± 3.78e-11\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_046.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 3.01e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000416889 ± 4.17e-11\n",
            "sup_j alignment:              0.500054 ± 5.00e-08\n",
            "dY/dt:                        -0.651017 ± 7.69e-07\n",
            "RHS:                          0.000115559 ± 3.47e-11\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_047.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.88e-15\n",
            "\n",
            "Recursive norm Y(t):          0.00039978 ± 4.00e-11\n",
            "sup_j alignment:              0.500054 ± 5.00e-08\n",
            "dY/dt:                        -0.623717 ± 7.37e-07\n",
            "RHS:                          0.000106268 ± 3.19e-11\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_048.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.78e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000383848 ± 3.84e-11\n",
            "sup_j alignment:              0.500054 ± 5.00e-08\n",
            "dY/dt:                        -0.59857 ± 7.08e-07\n",
            "RHS:                          9.79667e-05 ± 2.94e-11\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_049.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.85e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000369003 ± 3.69e-11\n",
            "sup_j alignment:              0.500054 ± 5.00e-08\n",
            "dY/dt:                        -0.575398 ± 6.80e-07\n",
            "RHS:                          9.05352e-05 ± 2.72e-11\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_050.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.77e-15\n",
            "\n",
            "Recursive norm Y(t):          0.00035516 ± 3.55e-11\n",
            "sup_j alignment:              0.500053 ± 5.00e-08\n",
            "dY/dt:                        -0.554026 ± 6.55e-07\n",
            "RHS:                          8.38698e-05 ± 2.52e-11\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_051.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.94e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000342245 ± 3.42e-11\n",
            "sup_j alignment:              0.500053 ± 5.00e-08\n",
            "dY/dt:                        -0.534306 ± 6.31e-07\n",
            "RHS:                          7.78805e-05 ± 2.34e-11\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_052.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.81e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000330185 ± 3.30e-11\n",
            "sup_j alignment:              0.500393 ± 5.00e-08\n",
            "dY/dt:                        -0.516095 ± 6.09e-07\n",
            "RHS:                          7.2538e-05 ± 2.18e-11\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_053.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.87e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000318918 ± 3.19e-11\n",
            "sup_j alignment:              0.546783 ± 5.47e-08\n",
            "dY/dt:                        -0.499267 ± 5.88e-07\n",
            "RHS:                          7.39477e-05 ± 2.22e-11\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_054.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.95e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000308381 ± 3.08e-11\n",
            "sup_j alignment:              0.500051 ± 5.00e-08\n",
            "dY/dt:                        -0.483706 ± 5.68e-07\n",
            "RHS:                          6.32304e-05 ± 1.90e-11\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_055.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.72e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000298521 ± 2.99e-11\n",
            "sup_j alignment:              0.50005 ± 5.00e-08\n",
            "dY/dt:                        -0.469302 ± 5.50e-07\n",
            "RHS:                          5.92514e-05 ± 1.78e-11\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_056.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.75e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000289287 ± 2.89e-11\n",
            "sup_j alignment:              0.50005 ± 5.00e-08\n",
            "dY/dt:                        -0.455962 ± 5.33e-07\n",
            "RHS:                          5.56422e-05 ± 1.67e-11\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_057.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.55e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000280631 ± 2.81e-11\n",
            "sup_j alignment:              0.500049 ± 5.00e-08\n",
            "dY/dt:                        -0.443591 ± 5.17e-07\n",
            "RHS:                          5.23621e-05 ± 1.57e-11\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_058.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.70e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000272512 ± 2.73e-11\n",
            "sup_j alignment:              0.500048 ± 5.00e-08\n",
            "dY/dt:                        -0.432111 ± 5.02e-07\n",
            "RHS:                          4.93757e-05 ± 1.48e-11\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_059.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.77e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000264888 ± 2.65e-11\n",
            "sup_j alignment:              0.500048 ± 5.00e-08\n",
            "dY/dt:                        -0.421444 ± 4.88e-07\n",
            "RHS:                          4.66514e-05 ± 1.40e-11\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_060.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.74e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000257723 ± 2.58e-11\n",
            "sup_j alignment:              0.500048 ± 5.00e-08\n",
            "dY/dt:                        -0.411527 ± 4.74e-07\n",
            "RHS:                          4.41618e-05 ± 1.33e-11\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_061.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.65e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000250984 ± 2.51e-11\n",
            "sup_j alignment:              0.500047 ± 5.00e-08\n",
            "dY/dt:                        -0.402294 ± 4.62e-07\n",
            "RHS:                          4.18822e-05 ± 1.26e-11\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_062.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.82e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000244639 ± 2.45e-11\n",
            "sup_j alignment:              0.500047 ± 5.00e-08\n",
            "dY/dt:                        -0.393684 ± 4.50e-07\n",
            "RHS:                          3.97912e-05 ± 1.19e-11\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_063.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.51e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000238659 ± 2.39e-11\n",
            "sup_j alignment:              0.500046 ± 5.00e-08\n",
            "dY/dt:                        -0.385651 ± 4.39e-07\n",
            "RHS:                          3.78696e-05 ± 1.14e-11\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_064.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.58e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000233018 ± 2.33e-11\n",
            "sup_j alignment:              0.500046 ± 5.00e-08\n",
            "dY/dt:                        -0.378146 ± 4.28e-07\n",
            "RHS:                          3.61004e-05 ± 1.08e-11\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_065.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.51e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000227691 ± 2.28e-11\n",
            "sup_j alignment:              0.500045 ± 5.00e-08\n",
            "dY/dt:                        -0.371123 ± 4.18e-07\n",
            "RHS:                          3.44686e-05 ± 1.03e-11\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_066.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.42e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000222655 ± 2.23e-11\n",
            "sup_j alignment:              0.500045 ± 5.00e-08\n",
            "dY/dt:                        -0.36454 ± 4.09e-07\n",
            "RHS:                          3.29607e-05 ± 9.90e-12\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_067.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.64e-15\n",
            "\n",
            "Recursive norm Y(t):          0.00021789 ± 2.18e-11\n",
            "sup_j alignment:              0.500044 ± 5.00e-08\n",
            "dY/dt:                        -0.358366 ± 4.00e-07\n",
            "RHS:                          3.1565e-05 ± 9.48e-12\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_068.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.59e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000213376 ± 2.13e-11\n",
            "sup_j alignment:              0.500044 ± 5.00e-08\n",
            "dY/dt:                        -0.352566 ± 3.91e-07\n",
            "RHS:                          3.02706e-05 ± 9.09e-12\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_069.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.43e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000209096 ± 2.09e-11\n",
            "sup_j alignment:              0.500043 ± 5.00e-08\n",
            "dY/dt:                        -0.347106 ± 3.83e-07\n",
            "RHS:                          2.90682e-05 ± 8.73e-12\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_070.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.67e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000205032 ± 2.05e-11\n",
            "sup_j alignment:              0.500043 ± 5.00e-08\n",
            "dY/dt:                        -0.34196 ± 3.76e-07\n",
            "RHS:                          2.79493e-05 ± 8.39e-12\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_071.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.47e-15\n",
            "\n",
            "Recursive norm Y(t):          0.00020117 ± 2.01e-11\n",
            "sup_j alignment:              0.500042 ± 5.00e-08\n",
            "dY/dt:                        -0.337104 ± 3.69e-07\n",
            "RHS:                          2.69061e-05 ± 8.08e-12\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_072.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.53e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000197495 ± 1.97e-11\n",
            "sup_j alignment:              0.500042 ± 5.00e-08\n",
            "dY/dt:                        -0.332511 ± 3.62e-07\n",
            "RHS:                          2.5932e-05 ± 7.79e-12\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_073.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.27e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000193995 ± 1.94e-11\n",
            "sup_j alignment:              0.500042 ± 5.00e-08\n",
            "dY/dt:                        -0.328162 ± 3.55e-07\n",
            "RHS:                          2.50209e-05 ± 7.51e-12\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_074.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.33e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000190656 ± 1.91e-11\n",
            "sup_j alignment:              0.500041 ± 5.00e-08\n",
            "dY/dt:                        -0.324037 ± 3.49e-07\n",
            "RHS:                          2.41672e-05 ± 7.26e-12\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_075.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.28e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000187469 ± 1.87e-11\n",
            "sup_j alignment:              0.500041 ± 5.00e-08\n",
            "dY/dt:                        -0.320116 ± 3.43e-07\n",
            "RHS:                          2.33659e-05 ± 7.02e-12\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_076.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.19e-15\n",
            "\n",
            "Recursive norm Y(t):          0.00018444 ± 1.84e-11\n",
            "sup_j alignment:              0.500041 ± 5.00e-08\n",
            "dY/dt:                        -0.316557 ± 3.37e-07\n",
            "RHS:                          2.26169e-05 ± 6.79e-12\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_077.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.27e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000181572 ± 1.82e-11\n",
            "sup_j alignment:              0.50004 ± 5.00e-08\n",
            "dY/dt:                        -0.313471 ± 3.32e-07\n",
            "RHS:                          2.1919e-05 ± 6.58e-12\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_078.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.31e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000178819 ± 1.79e-11\n",
            "sup_j alignment:              0.50004 ± 5.00e-08\n",
            "dY/dt:                        -0.310469 ± 3.27e-07\n",
            "RHS:                          2.12593e-05 ± 6.38e-12\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_079.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.32e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000176174 ± 1.76e-11\n",
            "sup_j alignment:              0.50004 ± 5.00e-08\n",
            "dY/dt:                        -0.307547 ± 3.22e-07\n",
            "RHS:                          2.06349e-05 ± 6.20e-12\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_080.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.36e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000173629 ± 1.74e-11\n",
            "sup_j alignment:              0.50004 ± 5.00e-08\n",
            "dY/dt:                        -0.304703 ± 3.17e-07\n",
            "RHS:                          2.00431e-05 ± 6.02e-12\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_081.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.27e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000171179 ± 1.71e-11\n",
            "sup_j alignment:              0.50004 ± 5.00e-08\n",
            "dY/dt:                        -0.301934 ± 3.12e-07\n",
            "RHS:                          1.94814e-05 ± 5.85e-12\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_082.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.30e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000168818 ± 1.69e-11\n",
            "sup_j alignment:              0.500039 ± 5.00e-08\n",
            "dY/dt:                        -0.299235 ± 3.08e-07\n",
            "RHS:                          1.89475e-05 ± 5.69e-12\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_083.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.13e-15\n",
            "\n",
            "Recursive norm Y(t):          0.00016654 ± 1.67e-11\n",
            "sup_j alignment:              0.500039 ± 5.00e-08\n",
            "dY/dt:                        -0.296605 ± 3.03e-07\n",
            "RHS:                          1.84396e-05 ± 5.54e-12\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_084.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.36e-15\n",
            "\n",
            "Recursive norm Y(t):          0.00016434 ± 1.64e-11\n",
            "sup_j alignment:              0.500039 ± 5.00e-08\n",
            "dY/dt:                        -0.294038 ± 2.99e-07\n",
            "RHS:                          1.79556e-05 ± 5.39e-12\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_085.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.29e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000162213 ± 1.62e-11\n",
            "sup_j alignment:              0.500039 ± 5.00e-08\n",
            "dY/dt:                        -0.291535 ± 2.95e-07\n",
            "RHS:                          1.74939e-05 ± 5.25e-12\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_086.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.14e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000160156 ± 1.60e-11\n",
            "sup_j alignment:              0.500039 ± 5.00e-08\n",
            "dY/dt:                        -0.289091 ± 2.91e-07\n",
            "RHS:                          1.7053e-05 ± 5.12e-12\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_087.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.14e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000158164 ± 1.58e-11\n",
            "sup_j alignment:              0.500038 ± 5.00e-08\n",
            "dY/dt:                        -0.286701 ± 2.88e-07\n",
            "RHS:                          1.66313e-05 ± 4.99e-12\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_088.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.18e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000156233 ± 1.56e-11\n",
            "sup_j alignment:              0.500038 ± 5.00e-08\n",
            "dY/dt:                        -0.284368 ± 2.84e-07\n",
            "RHS:                          1.62276e-05 ± 4.87e-12\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_089.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.17e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000154359 ± 1.54e-11\n",
            "sup_j alignment:              0.500038 ± 5.00e-08\n",
            "dY/dt:                        -0.282085 ± 2.81e-07\n",
            "RHS:                          1.58407e-05 ± 4.76e-12\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_090.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.01e-15\n",
            "\n",
            "Recursive norm Y(t):          0.00015254 ± 1.53e-11\n",
            "sup_j alignment:              0.500038 ± 5.00e-08\n",
            "dY/dt:                        -0.279724 ± 2.77e-07\n",
            "RHS:                          1.54695e-05 ± 4.64e-12\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_091.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.03e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000150772 ± 1.51e-11\n",
            "sup_j alignment:              0.500038 ± 5.00e-08\n",
            "dY/dt:                        -0.277161 ± 2.74e-07\n",
            "RHS:                          1.5113e-05 ± 4.54e-12\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_092.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.01e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000149053 ± 1.49e-11\n",
            "sup_j alignment:              0.500038 ± 5.00e-08\n",
            "dY/dt:                        -0.274653 ± 2.71e-07\n",
            "RHS:                          1.47703e-05 ± 4.43e-12\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_093.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.32e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000147379 ± 1.47e-11\n",
            "sup_j alignment:              0.500038 ± 5.00e-08\n",
            "dY/dt:                        -0.272191 ± 2.68e-07\n",
            "RHS:                          1.44404e-05 ± 4.34e-12\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_094.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 1.99e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000145749 ± 1.46e-11\n",
            "sup_j alignment:              0.500038 ± 5.00e-08\n",
            "dY/dt:                        -0.269614 ± 2.65e-07\n",
            "RHS:                          1.41227e-05 ± 4.24e-12\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_095.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.02e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000144159 ± 1.44e-11\n",
            "sup_j alignment:              0.500037 ± 5.00e-08\n",
            "dY/dt:                        -0.266276 ± 2.62e-07\n",
            "RHS:                          1.38163e-05 ± 4.15e-12\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_096.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 2.06e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000142608 ± 1.43e-11\n",
            "sup_j alignment:              0.500037 ± 5.00e-08\n",
            "dY/dt:                        -0.262995 ± 2.59e-07\n",
            "RHS:                          1.35206e-05 ± 4.06e-12\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_097.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 1.97e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000141094 ± 1.41e-11\n",
            "sup_j alignment:              0.500037 ± 5.00e-08\n",
            "dY/dt:                        -0.259769 ± 2.56e-07\n",
            "RHS:                          1.32351e-05 ± 3.97e-12\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_098.lean\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 1.94e-15\n",
            "\n",
            "Recursive norm Y(t):          0.000139615 ± 1.40e-11\n",
            "sup_j alignment:              0.500038 ± 5.00e-08\n",
            "dY/dt:                        -0.256597 ± 2.54e-07\n",
            "RHS:                          1.2959e-05 ± 3.89e-12\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[entropy] H(t) = -0.0000\n",
            "Wrote Lean-style proof certificate to /content/output/certificate_timestep_099.lean\n",
            "Timestep evolution complete for 100 steps.\n",
            "All requested runs/tests are complete. Exiting.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 proof_colab.py --run_blowup_test --strict\n",
        "!python3 proof_colab.py --run_commutator_test --strict\n",
        "!python3 proof_colab.py --run_time_reverse_test --strict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6TsX4n9nYmb",
        "outputId": "c47c4df8-44b1-48a1-a7e8-813967588480"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using CuPy (GPU) for arrays and FFTs\n",
            "No --input provided. Generating a synthetic 'vortex tube' field.\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 0.00e+00\n",
            "\n",
            "Recursive norm Y(t):          347872 ± 3.48e-02\n",
            "sup_j alignment:              0.411426 ± 4.11e-08\n",
            "dY/dt not available (only single time). No inequality check.\n",
            "Default evolution + certification completed successfully.\n",
            "See /content/output/diagnostics_log_mainrun.json for details.\n",
            "[blowup test] j_min=6, j_max=9, timesteps=1\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 9.26e-05\n",
            "\n",
            "Recursive norm Y(t):          2.48765 ± 2.49e-07\n",
            "sup_j alignment:              0.329752 ± 3.30e-08\n",
            "dY/dt:                        -4629.68 ± 4.51e-03\n",
            "RHS:                          2714.19 ± 8.14e-04\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[blowup test] Completed.\n",
            "All requested runs/tests are complete. Exiting.\n",
            "Using CuPy (GPU) for arrays and FFTs\n",
            "No --input provided. Generating a synthetic 'vortex tube' field.\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 0.00e+00\n",
            "\n",
            "Recursive norm Y(t):          347872 ± 3.48e-02\n",
            "sup_j alignment:              0.411426 ± 4.11e-08\n",
            "dY/dt not available (only single time). No inequality check.\n",
            "Default evolution + certification completed successfully.\n",
            "See /content/output/diagnostics_log_mainrun.json for details.\n",
            "[commutator test] j_min=6, j_max=9, timesteps=1\n",
            "object address  : 0x79a94b819660\n",
            "object refcount : 2\n",
            "object type     : 0x9d5ea0\n",
            "object type name: KeyboardInterrupt\n",
            "object repr     : KeyboardInterrupt()\n",
            "lost sys.stderr\n",
            "^C\n",
            "Using CuPy (GPU) for arrays and FFTs\n",
            "No --input provided. Generating a synthetic 'vortex tube' field.\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 0.00e+00\n",
            "\n",
            "Recursive norm Y(t):          347872 ± 3.48e-02\n",
            "sup_j alignment:              0.411426 ± 4.11e-08\n",
            "dY/dt not available (only single time). No inequality check.\n",
            "Default evolution + certification completed successfully.\n",
            "See /content/output/diagnostics_log_mainrun.json for details.\n",
            "[time reversal test] j_min=6, j_max=9, timesteps=1\n",
            "[time reverse] Step=0, forward->back error = 2.672e-03\n",
            "  (Computing velocity and grad_u from vorticity via Biot-Savart)\n",
            "[biot_savart] max|div u| = 0.00e+00\n",
            "\n",
            "Recursive norm Y(t):          347872 ± 3.48e-02\n",
            "sup_j alignment:              0.411426 ± 4.11e-08\n",
            "dY/dt:                        -2.34328e+08 ± 6.72e+02\n",
            "RHS:                          6.62291e+13 ± 1.99e+07\n",
            "[Inequality verified]: This timestep is within bounds.\n",
            "\n",
            "[time reverse test] Completed.\n",
            "All requested runs/tests are complete. Exiting.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 recursive_ode_falsifier.py --strict --lean_cert"
      ],
      "metadata": {
        "id": "La6-lI1anaIR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa2cc0e9-ecd7-41ce-dcc3-a43e2b266598"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/recursive_ode_falsifier.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/recursive_ode_falsifier.py\", line 125, in main\n",
            "    Ys_sim_nom, rhs_vals_nom = sim_trajectory(Y0_mid, A_mids)\n",
            "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/recursive_ode_falsifier.py\", line 115, in sim_trajectory\n",
            "    rhs = ode_step(Y, A)\n",
            "          ^^^^^^^^^^^^^^\n",
            "  File \"/content/recursive_ode_falsifier.py\", line 108, in ode_step\n",
            "    return C_nl * Y**2 * A - nu * Lam * (Y**(1+delta))\n",
            "                  ~^^~\n",
            "OverflowError: (34, 'Numerical result out of range')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 proof_falsifier_engine.py"
      ],
      "metadata": {
        "id": "qSKFybRpwxil",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0593b9f-9254-4e0f-b731-77839f69f3b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "[FAIL] test_shell_j3_run1_ec23a7ff2c | proof_colab: 2 | ode: n/a\n",
            "[FAIL] test_shell_j5_run2_47a2d52362 | proof_colab: 2 | ode: n/a\n",
            "[FAIL] test_aligned_blowup_run3_296c65368f | proof_colab: 2 | ode: n/a\n",
            "[FAIL] test_adversarial_combo_run4_4fae59cf96 | proof_colab: 2 | ode: n/a\n",
            "[FAIL] test_random_noise_run5_cda5c21d99 | proof_colab: 2 | ode: n/a\n",
            "------ Adversarial Falsification Test Report ------\n",
            "Total runs: 5\n",
            "proof_colab.py failures: 5\n",
            "recursive_ode_falsifier.py failures: 0\n",
            "Field types causing failure:\n",
            "  adversarial_combo (proof_colab)\n",
            "  aligned_blowup (proof_colab)\n",
            "  random_noise (proof_colab)\n",
            "  shell_j3 (proof_colab)\n",
            "  shell_j5 (proof_colab)\n",
            "Counterexamples saved in: /content/output/counterexamples/\n",
            "Bundle zip (if any): /content/output/counterexample_bundle.zip\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 certificate_packager.py"
      ],
      "metadata": {
        "id": "ZwtZbhX-w3dQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a06de0bd-ff71-4db7-f420-293804902f56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[certificate_packager.py] ERROR: proof_summary.json not found at /content/output/proof_summary.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 lean_validator.py --dir /content/output/counterexamples/ --strict --check_duplicate_ast"
      ],
      "metadata": {
        "id": "sTgBKhhuw5BX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47891347-fe8e-40ed-fc8d-587da05cfe8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lean version: /bin/sh: 1: lean: not found\n",
            "\n",
            "Summary:\n",
            "- CSV: /content/output/counterexamples/lean_validation_summary.csv\n",
            "- Markdown report: /content/output/counterexamples/lean_validation_report.md\n",
            "- Metadata: /content/output/counterexamples/lean_validator_metadata.json\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 lean_validator.py --dir /content/output/ --strict --check_duplicate_ast"
      ],
      "metadata": {
        "id": "FB_-MnY4zOgZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e067d4e-7b23-4c76-8910-80c964287cb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lean version: /bin/sh: 1: lean: not found\n",
            "\n",
            "Summary:\n",
            "- CSV: /content/output/lean_validation_summary.csv\n",
            "- Markdown report: /content/output/lean_validation_report.md\n",
            "- Metadata: /content/output/lean_validator_metadata.json\n",
            "Strict mode: at least one error detected. Failing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r navier_stokes_proof_output.zip /content/output/"
      ],
      "metadata": {
        "id": "QTHrT0cVzP1B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cab2f4d-767c-4222-fe32-ea77e266c9b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/output/ (stored 0%)\n",
            "  adding: content/output/inequality_timestep_081.png (deflated 20%)\n",
            "  adding: content/output/diagnostics_log_timestep_094.json (deflated 67%)\n",
            "  adding: content/output/certificate_timestep_051.lean (deflated 31%)\n",
            "  adding: content/output/inequality_timestep_093.png (deflated 20%)\n",
            "  adding: content/output/certificate_timestep_099.lean (deflated 31%)\n",
            "  adding: content/output/inequality_timestep_008.png (deflated 20%)\n",
            "  adding: content/output/per_shell_timestep_028.png (deflated 23%)\n",
            "  adding: content/output/diagnostics_log_timestep_081.json (deflated 67%)\n",
            "  adding: content/output/diagnostics_log_timestep_044.json (deflated 67%)\n",
            "  adding: content/output/certificate_timestep_048.lean (deflated 32%)\n",
            "  adding: content/output/diagnostics_log_timestep_051.json (deflated 67%)\n",
            "  adding: content/output/diagnostics_log_timestep_033.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_015.png (deflated 21%)\n",
            "  adding: content/output/certificate_timestep_072.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_063.json (deflated 67%)\n",
            "  adding: content/output/certificate_timestep_073.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_041.json (deflated 68%)\n",
            "  adding: content/output/inequality_timestep_076.png (deflated 21%)\n",
            "  adding: content/output/certificate_timestep_017.lean (deflated 31%)\n",
            "  adding: content/output/per_shell_timestep_039.png (deflated 22%)\n",
            "  adding: content/output/certificate_timestep_064.lean (deflated 31%)\n",
            "  adding: content/output/inequality_timestep_024.png (deflated 20%)\n",
            "  adding: content/output/inequality_timestep_052.png (deflated 21%)\n",
            "  adding: content/output/diagnostics_log_timestep_043.json (deflated 67%)\n",
            "  adding: content/output/certificate_timestep_030.lean (deflated 31%)\n",
            "  adding: content/output/per_shell_timestep_069.png (deflated 22%)\n",
            "  adding: content/output/inequality_timestep_073.png (deflated 21%)\n",
            "  adding: content/output/inequality_timestep_070.png (deflated 20%)\n",
            "  adding: content/output/certificate_timestep_045.lean (deflated 31%)\n",
            "  adding: content/output/inequality_timestep_000.png (deflated 20%)\n",
            "  adding: content/output/per_shell_timestep_074.png (deflated 23%)\n",
            "  adding: content/output/test_shell_j5_run2_47a2d52362_config.json (deflated 40%)\n",
            "  adding: content/output/inequality_timestep_038.png (deflated 21%)\n",
            "  adding: content/output/per_shell_timestep_097.png (deflated 22%)\n",
            "  adding: content/output/diagnostics_log_timestep_008.json (deflated 68%)\n",
            "  adding: content/output/per_shell_timestep_085.png (deflated 23%)\n",
            "  adding: content/output/per_shell_timestep_062.png (deflated 22%)\n",
            "  adding: content/output/diagnostics_log_timestep_053.json (deflated 67%)\n",
            "  adding: content/output/diagnostics_log_timestep_083.json (deflated 67%)\n",
            "  adding: content/output/per_shell_timestep_084.png (deflated 22%)\n",
            "  adding: content/output/diagnostics_log_timestep_022.json (deflated 68%)\n",
            "  adding: content/output/inequality_timestep_098.png (deflated 21%)\n",
            "  adding: content/output/per_shell_timestep_035.png (deflated 22%)\n",
            "  adding: content/output/diagnostics_log_timestep_048.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_092.png (deflated 22%)\n",
            "  adding: content/output/inequality_timestep_096.png (deflated 20%)\n",
            "  adding: content/output/inequality_timestep_097.png (deflated 21%)\n",
            "  adding: content/output/per_shell_timestep_054.png (deflated 21%)\n",
            "  adding: content/output/per_shell_timestep_008.png (deflated 24%)\n",
            "  adding: content/output/certificate_timestep_005.lean (deflated 31%)\n",
            "  adding: content/output/per_shell_timestep_005.png (deflated 24%)\n",
            "  adding: content/output/diagnostics_log_timestep_040.json (deflated 67%)\n",
            "  adding: content/output/diagnostics_log_timestep_019.json (deflated 67%)\n",
            "  adding: content/output/per_shell_timestep_066.png (deflated 23%)\n",
            "  adding: content/output/per_shell_timestep_015.png (deflated 23%)\n",
            "  adding: content/output/inequality_timestep_075.png (deflated 21%)\n",
            "  adding: content/output/diagnostics_log_timestep_060.json (deflated 67%)\n",
            "  adding: content/output/certificate_timestep_026.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_050.json (deflated 67%)\n",
            "  adding: content/output/per_shell_timestep_026.png (deflated 23%)\n",
            "  adding: content/output/certificate_timestep_061.lean (deflated 32%)\n",
            "  adding: content/output/certificate_timestep_047.lean (deflated 32%)\n",
            "  adding: content/output/counterexamples/ (stored 0%)\n",
            "  adding: content/output/counterexamples/test_shell_j3_run1_ec23a7ff2c/ (stored 0%)\n",
            "  adding: content/output/counterexamples/test_shell_j3_run1_ec23a7ff2c/test_shell_j3_run1_ec23a7ff2c_omega_tpdt.npy (deflated 4%)\n",
            "  adding: content/output/counterexamples/test_shell_j3_run1_ec23a7ff2c/test_shell_j3_run1_ec23a7ff2c_omega_t.npy (deflated 8%)\n",
            "  adding: content/output/counterexamples/test_shell_j3_run1_ec23a7ff2c/test_shell_j3_run1_ec23a7ff2c_proof_stdout.txt (stored 0%)\n",
            "  adding: content/output/counterexamples/test_shell_j3_run1_ec23a7ff2c/test_shell_j3_run1_ec23a7ff2c_config.json (deflated 40%)\n",
            "  adding: content/output/counterexamples/test_shell_j3_run1_ec23a7ff2c/test_shell_j3_run1_ec23a7ff2c_proof_stderr.txt (deflated 46%)\n",
            "  adding: content/output/counterexamples/lean_validator_metadata.json (deflated 9%)\n",
            "  adding: content/output/counterexamples/test_random_noise_run5_cda5c21d99/ (stored 0%)\n",
            "  adding: content/output/counterexamples/test_random_noise_run5_cda5c21d99/test_random_noise_run5_cda5c21d99_omega_t.npy (deflated 7%)\n",
            "  adding: content/output/counterexamples/test_random_noise_run5_cda5c21d99/test_random_noise_run5_cda5c21d99_proof_stderr.txt (deflated 46%)\n",
            "  adding: content/output/counterexamples/test_random_noise_run5_cda5c21d99/test_random_noise_run5_cda5c21d99_config.json (deflated 42%)\n",
            "  adding: content/output/counterexamples/test_random_noise_run5_cda5c21d99/test_random_noise_run5_cda5c21d99_omega_tpdt.npy (deflated 4%)\n",
            "  adding: content/output/counterexamples/test_random_noise_run5_cda5c21d99/test_random_noise_run5_cda5c21d99_proof_stdout.txt (stored 0%)\n",
            "  adding: content/output/counterexamples/test_shell_j5_run2_47a2d52362/ (stored 0%)\n",
            "  adding: content/output/counterexamples/test_shell_j5_run2_47a2d52362/test_shell_j5_run2_47a2d52362_config.json (deflated 40%)\n",
            "  adding: content/output/counterexamples/test_shell_j5_run2_47a2d52362/test_shell_j5_run2_47a2d52362_proof_stdout.txt (stored 0%)\n",
            "  adding: content/output/counterexamples/test_shell_j5_run2_47a2d52362/test_shell_j5_run2_47a2d52362_omega_tpdt.npy (deflated 4%)\n",
            "  adding: content/output/counterexamples/test_shell_j5_run2_47a2d52362/test_shell_j5_run2_47a2d52362_omega_t.npy (deflated 7%)\n",
            "  adding: content/output/counterexamples/test_shell_j5_run2_47a2d52362/test_shell_j5_run2_47a2d52362_proof_stderr.txt (deflated 45%)\n",
            "  adding: content/output/counterexamples/test_aligned_blowup_run3_296c65368f/ (stored 0%)\n",
            "  adding: content/output/counterexamples/test_aligned_blowup_run3_296c65368f/test_aligned_blowup_run3_296c65368f_omega_t.npy (deflated 78%)\n",
            "  adding: content/output/counterexamples/test_aligned_blowup_run3_296c65368f/test_aligned_blowup_run3_296c65368f_proof_stdout.txt (stored 0%)\n",
            "  adding: content/output/counterexamples/test_aligned_blowup_run3_296c65368f/test_aligned_blowup_run3_296c65368f_proof_stderr.txt (deflated 46%)\n",
            "  adding: content/output/counterexamples/test_aligned_blowup_run3_296c65368f/test_aligned_blowup_run3_296c65368f_config.json (deflated 40%)\n",
            "  adding: content/output/counterexamples/test_aligned_blowup_run3_296c65368f/test_aligned_blowup_run3_296c65368f_omega_tpdt.npy (deflated 4%)\n",
            "  adding: content/output/counterexamples/lean_validation_report.md (deflated 34%)\n",
            "  adding: content/output/counterexamples/test_adversarial_combo_run4_4fae59cf96/ (stored 0%)\n",
            "  adding: content/output/counterexamples/test_adversarial_combo_run4_4fae59cf96/test_adversarial_combo_run4_4fae59cf96_proof_stderr.txt (deflated 46%)\n",
            "  adding: content/output/counterexamples/test_adversarial_combo_run4_4fae59cf96/test_adversarial_combo_run4_4fae59cf96_omega_tpdt.npy (deflated 3%)\n",
            "  adding: content/output/counterexamples/test_adversarial_combo_run4_4fae59cf96/test_adversarial_combo_run4_4fae59cf96_proof_stdout.txt (stored 0%)\n",
            "  adding: content/output/counterexamples/test_adversarial_combo_run4_4fae59cf96/test_adversarial_combo_run4_4fae59cf96_omega_t.npy (deflated 7%)\n",
            "  adding: content/output/counterexamples/test_adversarial_combo_run4_4fae59cf96/test_adversarial_combo_run4_4fae59cf96_config.json (deflated 42%)\n",
            "  adding: content/output/counterexamples/lean_validation_summary.csv (deflated 38%)\n",
            "  adding: content/output/per_shell_timestep_088.png (deflated 23%)\n",
            "  adding: content/output/diagnostics_log_timestep_088.json (deflated 67%)\n",
            "  adding: content/output/per_shell_timestep_073.png (deflated 22%)\n",
            "  adding: content/output/inequality_timestep_091.png (deflated 20%)\n",
            "  adding: content/output/diagnostics_log_timestep_096.json (deflated 67%)\n",
            "  adding: content/output/diagnostics_log_timestep_002.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_084.png (deflated 21%)\n",
            "  adding: content/output/inequality_timestep_035.png (deflated 20%)\n",
            "  adding: content/output/diagnostics_log_timestep_072.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_074.png (deflated 21%)\n",
            "  adding: content/output/per_shell_timestep_080.png (deflated 23%)\n",
            "  adding: content/output/per_shell_timestep_044.png (deflated 22%)\n",
            "  adding: content/output/certificate_timestep_029.lean (deflated 32%)\n",
            "  adding: content/output/diagnostics_log_timestep_080.json (deflated 67%)\n",
            "  adding: content/output/per_shell_timestep_037.png (deflated 21%)\n",
            "  adding: content/output/diagnostics_log_timestep_055.json (deflated 67%)\n",
            "  adding: content/output/certificate_timestep_079.lean (deflated 31%)\n",
            "  adding: content/output/per_shell_timestep_040.png (deflated 22%)\n",
            "  adding: content/output/per_shell_timestep_071.png (deflated 23%)\n",
            "  adding: content/output/certificate_timestep_007.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_mainrun.json (deflated 66%)\n",
            "  adding: content/output/diagnostics_log_timestep_021.json (deflated 68%)\n",
            "  adding: content/output/inequality_timestep_065.png (deflated 21%)\n",
            "  adding: content/output/diagnostics_log_timestep_054.json (deflated 67%)\n",
            "  adding: content/output/per_shell_timestep_095.png (deflated 22%)\n",
            "  adding: content/output/inequality_timestep_014.png (deflated 21%)\n",
            "  adding: content/output/certificate_timestep_039.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_time_reverse_t0.json (deflated 65%)\n",
            "  adding: content/output/per_shell_timestep_076.png (deflated 23%)\n",
            "  adding: content/output/certificate_timestep_016.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_073.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_044.png (deflated 21%)\n",
            "  adding: content/output/per_shell_timestep_079.png (deflated 22%)\n",
            "  adding: content/output/per_shell_timestep_055.png (deflated 22%)\n",
            "  adding: content/output/per_shell_timestep_061.png (deflated 22%)\n",
            "  adding: content/output/diagnostics_log_timestep_093.json (deflated 67%)\n",
            "  adding: content/output/certificate_timestep_078.lean (deflated 31%)\n",
            "  adding: content/output/per_shell_timestep_082.png (deflated 22%)\n",
            "  adding: content/output/diagnostics_log_timestep_024.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_059.png (deflated 22%)\n",
            "  adding: content/output/diagnostics_log_timestep_034.json (deflated 67%)\n",
            "  adding: content/output/diagnostics_log_timestep_058.json (deflated 67%)\n",
            "  adding: content/output/certificate_timestep_065.lean (deflated 31%)\n",
            "  adding: content/output/per_shell_timestep_010.png (deflated 24%)\n",
            "  adding: content/output/inequality_timestep_087.png (deflated 21%)\n",
            "  adding: content/output/certificate_timestep_034.lean (deflated 31%)\n",
            "  adding: content/output/certificate_timestep_098.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_046.json (deflated 67%)\n",
            "  adding: content/output/certificate_timestep_085.lean (deflated 31%)\n",
            "  adding: content/output/per_shell_timestep_056.png (deflated 22%)\n",
            "  adding: content/output/certificate_timestep_025.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_070.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_099.png (deflated 21%)\n",
            "  adding: content/output/inequality_timestep_050.png (deflated 20%)\n",
            "  adding: content/output/certificate_timestep_001.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_091.json (deflated 67%)\n",
            "  adding: content/output/per_shell_timestep_072.png (deflated 22%)\n",
            "  adding: content/output/certificate_timestep_036.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_005.json (deflated 68%)\n",
            "  adding: content/output/diagnostics_log_timestep_052.json (deflated 67%)\n",
            "  adding: content/output/diagnostics_log_timestep_086.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_054.png (deflated 21%)\n",
            "  adding: content/output/certificate_timestep_014.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_011.json (deflated 68%)\n",
            "  adding: content/output/diagnostics_log_timestep_026.json (deflated 68%)\n",
            "  adding: content/output/certificate_timestep_037.lean (deflated 32%)\n",
            "  adding: content/output/inequality_timestep_034.png (deflated 20%)\n",
            "  adding: content/output/diagnostics_log_timestep_077.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_042.png (deflated 22%)\n",
            "  adding: content/output/per_shell_timestep_021.png (deflated 23%)\n",
            "  adding: content/output/diagnostics_log_timestep_015.json (deflated 67%)\n",
            "  adding: content/output/diagnostics_log_timestep_031.json (deflated 67%)\n",
            "  adding: content/output/per_shell_timestep_016.png (deflated 23%)\n",
            "  adding: content/output/inequality_timestep_023.png (deflated 19%)\n",
            "  adding: content/output/diagnostics_log_timestep_030.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_061.png (deflated 21%)\n",
            "  adding: content/output/diagnostics_log_timestep_035.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_003.png (deflated 21%)\n",
            "  adding: content/output/inequality_timestep_071.png (deflated 20%)\n",
            "  adding: content/output/certificate_timestep_075.lean (deflated 31%)\n",
            "  adding: content/output/per_shell_timestep_007.png (deflated 26%)\n",
            "  adding: content/output/inequality_timestep_022.png (deflated 20%)\n",
            "  adding: content/output/inequality_timestep_062.png (deflated 21%)\n",
            "  adding: content/output/diagnostics_log_timestep_032.json (deflated 67%)\n",
            "  adding: content/output/diagnostics_log_timestep_036.json (deflated 67%)\n",
            "  adding: content/output/diagnostics_log_timestep_025.json (deflated 68%)\n",
            "  adding: content/output/certificate_timestep_032.lean (deflated 32%)\n",
            "  adding: content/output/diagnostics_log_timestep_066.json (deflated 67%)\n",
            "  adding: content/output/per_shell_timestep_043.png (deflated 23%)\n",
            "  adding: content/output/inequality_timestep_080.png (deflated 21%)\n",
            "  adding: content/output/certificate_timestep_089.lean (deflated 31%)\n",
            "  adding: content/output/per_shell_timestep_048.png (deflated 22%)\n",
            "  adding: content/output/diagnostics_log_timestep_084.json (deflated 67%)\n",
            "  adding: content/output/certificate_timestep_022.lean (deflated 31%)\n",
            "  adding: content/output/per_shell_timestep_089.png (deflated 23%)\n",
            "  adding: content/output/certificate_timestep_069.lean (deflated 31%)\n",
            "  adding: content/output/certificate_timestep_060.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_003.json (deflated 68%)\n",
            "  adding: content/output/certificate_timestep_027.lean (deflated 31%)\n",
            "  adding: content/output/per_shell_timestep_003.png (deflated 25%)\n",
            "  adding: content/output/certificate_timestep_056.lean (deflated 31%)\n",
            "  adding: content/output/per_shell_timestep_094.png (deflated 23%)\n",
            "  adding: content/output/per_shell_timestep_011.png (deflated 23%)\n",
            "  adding: content/output/diagnostics_log_timestep_059.json (deflated 67%)\n",
            "  adding: content/output/per_shell_timestep_083.png (deflated 23%)\n",
            "  adding: content/output/inequality_timestep_079.png (deflated 20%)\n",
            "  adding: content/output/inequality_timestep_068.png (deflated 21%)\n",
            "  adding: content/output/inequality_timestep_083.png (deflated 21%)\n",
            "  adding: content/output/certificate_timestep_006.lean (deflated 31%)\n",
            "  adding: content/output/certificate_timestep_081.lean (deflated 31%)\n",
            "  adding: content/output/inequality_timestep_066.png (deflated 20%)\n",
            "  adding: content/output/per_shell_timestep_070.png (deflated 22%)\n",
            "  adding: content/output/lean_validator_metadata.json (deflated 92%)\n",
            "  adding: content/output/certificate_timestep_084.lean (deflated 31%)\n",
            "  adding: content/output/certificate_timestep_053.lean (deflated 32%)\n",
            "  adding: content/output/per_shell_timestep_057.png (deflated 22%)\n",
            "  adding: content/output/inequality_timestep_006.png (deflated 20%)\n",
            "  adding: content/output/diagnostics_log_timestep_004.json (deflated 68%)\n",
            "  adding: content/output/inequality_timestep_040.png (deflated 21%)\n",
            "  adding: content/output/certificate_timestep_086.lean (deflated 31%)\n",
            "  adding: content/output/per_shell_timestep_059.png (deflated 22%)\n",
            "  adding: content/output/diagnostics_log_timestep_085.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_085.png (deflated 20%)\n",
            "  adding: content/output/diagnostics_log_timestep_016.json (deflated 68%)\n",
            "  adding: content/output/diagnostics_log_timestep_014.json (deflated 67%)\n",
            "  adding: content/output/certificate_timestep_093.lean (deflated 31%)\n",
            "  adding: content/output/certificate_timestep_054.lean (deflated 32%)\n",
            "  adding: content/output/per_shell_timestep_027.png (deflated 22%)\n",
            "  adding: content/output/inequality_timestep_012.png (deflated 21%)\n",
            "  adding: content/output/certificate_timestep_082.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_087.json (deflated 67%)\n",
            "  adding: content/output/per_shell_timestep_064.png (deflated 23%)\n",
            "  adding: content/output/certificate_timestep_018.lean (deflated 31%)\n",
            "  adding: content/output/certificate_timestep_092.lean (deflated 31%)\n",
            "  adding: content/output/certificate_timestep_095.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_023.json (deflated 68%)\n",
            "  adding: content/output/certificate_timestep_049.lean (deflated 31%)\n",
            "  adding: content/output/per_shell_timestep_001.png (deflated 24%)\n",
            "  adding: content/output/diagnostics_log_timestep_095.json (deflated 67%)\n",
            "  adding: content/output/diagnostics_log_timestep_097.json (deflated 67%)\n",
            "  adding: content/output/diagnostics_log_timestep_068.json (deflated 67%)\n",
            "  adding: content/output/diagnostics_log_timestep_027.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_001.png (deflated 21%)\n",
            "  adding: content/output/per_shell_timestep_042.png (deflated 22%)\n",
            "  adding: content/output/diagnostics_log_timestep_007.json (deflated 68%)\n",
            "  adding: content/output/certificate_timestep_042.lean (deflated 32%)\n",
            "  adding: content/output/certificate_timestep_087.lean (deflated 31%)\n",
            "  adding: content/output/per_shell_timestep_099.png (deflated 22%)\n",
            "  adding: content/output/per_shell_timestep_086.png (deflated 22%)\n",
            "  adding: content/output/certificate_timestep_028.lean (deflated 31%)\n",
            "  adding: content/output/per_shell_timestep_000.png (deflated 23%)\n",
            "  adding: content/output/inequality_timestep_041.png (deflated 21%)\n",
            "  adding: content/output/certificate_timestep_040.lean (deflated 32%)\n",
            "  adding: content/output/inequality_timestep_016.png (deflated 21%)\n",
            "  adding: content/output/diagnostics_log_blowup_test_t0.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_045.png (deflated 21%)\n",
            "  adding: content/output/inequality_timestep_063.png (deflated 21%)\n",
            "  adding: content/output/inequality_timestep_007.png (deflated 20%)\n",
            "  adding: content/output/certificate_timestep_050.lean (deflated 31%)\n",
            "  adding: content/output/test_aligned_blowup_run3_296c65368f_config.json (deflated 40%)\n",
            "  adding: content/output/diagnostics_log_timestep_028.json (deflated 67%)\n",
            "  adding: content/output/per_shell_timestep_090.png (deflated 23%)\n",
            "  adding: content/output/certificate_timestep_000.lean (deflated 31%)\n",
            "  adding: content/output/inequality_timestep_089.png (deflated 21%)\n",
            "  adding: content/output/inequality_timestep_019.png (deflated 20%)\n",
            "  adding: content/output/certificate_timestep_013.lean (deflated 31%)\n",
            "  adding: content/output/certificate_timestep_057.lean (deflated 31%)\n",
            "  adding: content/output/inequality_timestep_057.png (deflated 22%)\n",
            "  adding: content/output/per_shell_timestep_045.png (deflated 21%)\n",
            "  adding: content/output/per_shell_timestep_019.png (deflated 22%)\n",
            "  adding: content/output/certificate_timestep_055.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_065.json (deflated 67%)\n",
            "  adding: content/output/diagnostics_log_timestep_057.json (deflated 67%)\n",
            "  adding: content/output/certificate_timestep_074.lean (deflated 31%)\n",
            "  adding: content/output/inequality_timestep_029.png (deflated 19%)\n",
            "  adding: content/output/diagnostics_log_timestep_045.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_017.png (deflated 22%)\n",
            "  adding: content/output/per_shell_timestep_029.png (deflated 24%)\n",
            "  adding: content/output/inequality_timestep_064.png (deflated 21%)\n",
            "  adding: content/output/inequality_timestep_020.png (deflated 19%)\n",
            "  adding: content/output/diagnostics_log_timestep_082.json (deflated 67%)\n",
            "  adding: content/output/certificate_timestep_035.lean (deflated 31%)\n",
            "  adding: content/output/inequality_timestep_039.png (deflated 21%)\n",
            "  adding: content/output/certificate_timestep_066.lean (deflated 31%)\n",
            "  adding: content/output/per_shell_timestep_091.png (deflated 23%)\n",
            "  adding: content/output/per_shell_timestep_060.png (deflated 22%)\n",
            "  adding: content/output/inequality_timestep_090.png (deflated 21%)\n",
            "  adding: content/output/inequality_timestep_049.png (deflated 21%)\n",
            "  adding: content/output/diagnostics_log_timestep_078.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_055.png (deflated 21%)\n",
            "  adding: content/output/per_shell_timestep_009.png (deflated 23%)\n",
            "  adding: content/output/inequality_timestep_033.png (deflated 19%)\n",
            "  adding: content/output/diagnostics_log_timestep_020.json (deflated 68%)\n",
            "  adding: content/output/inequality_timestep_011.png (deflated 20%)\n",
            "  adding: content/output/inequality_timestep_060.png (deflated 22%)\n",
            "  adding: content/output/certificate_timestep_010.lean (deflated 31%)\n",
            "  adding: content/output/per_shell_timestep_030.png (deflated 23%)\n",
            "  adding: content/output/diagnostics_log_timestep_017.json (deflated 68%)\n",
            "  adding: content/output/certificate_timestep_091.lean (deflated 31%)\n",
            "  adding: content/output/per_shell_timestep_047.png (deflated 22%)\n",
            "  adding: content/output/diagnostics_log_timestep_062.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_051.png (deflated 20%)\n",
            "  adding: content/output/per_shell_timestep_033.png (deflated 22%)\n",
            "  adding: content/output/diagnostics_log_timestep_064.json (deflated 67%)\n",
            "  adding: content/output/per_shell_timestep_022.png (deflated 23%)\n",
            "  adding: content/output/diagnostics_log_timestep_000.json (deflated 68%)\n",
            "  adding: content/output/per_shell_timestep_075.png (deflated 23%)\n",
            "  adding: content/output/per_shell_timestep_067.png (deflated 23%)\n",
            "  adding: content/output/diagnostics_log_timestep_092.json (deflated 67%)\n",
            "  adding: content/output/lean_validation_report.md (deflated 95%)\n",
            "  adding: content/output/certificate_timestep_059.lean (deflated 32%)\n",
            "  adding: content/output/per_shell_timestep_078.png (deflated 23%)\n",
            "  adding: content/output/inequality_timestep_030.png (deflated 19%)\n",
            "  adding: content/output/diagnostics_log_timestep_067.json (deflated 67%)\n",
            "  adding: content/output/diagnostics_log_timestep_089.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_005.png (deflated 20%)\n",
            "  adding: content/output/per_shell_timestep_038.png (deflated 22%)\n",
            "  adding: content/output/certificate_timestep_063.lean (deflated 31%)\n",
            "  adding: content/output/certificate_timestep_077.lean (deflated 31%)\n",
            "  adding: content/output/per_shell_timestep_014.png (deflated 23%)\n",
            "  adding: content/output/per_shell_timestep_017.png (deflated 23%)\n",
            "  adding: content/output/test_random_noise_run5_cda5c21d99_config.json (deflated 42%)\n",
            "  adding: content/output/test_shell_j3_run1_ec23a7ff2c_config.json (deflated 40%)\n",
            "  adding: content/output/certificate_timestep_090.lean (deflated 31%)\n",
            "  adding: content/output/inequality_timestep_036.png (deflated 20%)\n",
            "  adding: content/output/inequality_timestep_047.png (deflated 21%)\n",
            "  adding: content/output/inequality_timestep_013.png (deflated 21%)\n",
            "  adding: content/output/inequality_timestep_077.png (deflated 21%)\n",
            "  adding: content/output/certificate_timestep_046.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_098.json (deflated 67%)\n",
            "  adding: content/output/certificate_timestep_062.lean (deflated 31%)\n",
            "  adding: content/output/inequality_timestep_009.png (deflated 20%)\n",
            "  adding: content/output/per_shell_timestep_049.png (deflated 22%)\n",
            "  adding: content/output/inequality_timestep_078.png (deflated 21%)\n",
            "  adding: content/output/per_shell_timestep_041.png (deflated 22%)\n",
            "  adding: content/output/per_shell_timestep_046.png (deflated 22%)\n",
            "  adding: content/output/diagnostics_log_timestep_056.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_082.png (deflated 20%)\n",
            "  adding: content/output/per_shell_timestep_053.png (deflated 22%)\n",
            "  adding: content/output/diagnostics_log_timestep_013.json (deflated 68%)\n",
            "  adding: content/output/per_shell_timestep_087.png (deflated 23%)\n",
            "  adding: content/output/per_shell_timestep_023.png (deflated 23%)\n",
            "  adding: content/output/certificate_timestep_058.lean (deflated 31%)\n",
            "  adding: content/output/certificate_timestep_008.lean (deflated 31%)\n",
            "  adding: content/output/certificate_timestep_076.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_049.json (deflated 67%)\n",
            "  adding: content/output/diagnostics_log_timestep_009.json (deflated 68%)\n",
            "  adding: content/output/certificate_timestep_052.lean (deflated 31%)\n",
            "  adding: content/output/certificate_timestep_041.lean (deflated 32%)\n",
            "  adding: content/output/diagnostics_log_timestep_090.json (deflated 67%)\n",
            "  adding: content/output/certificate_timestep_009.lean (deflated 31%)\n",
            "  adding: content/output/per_shell_timestep_036.png (deflated 22%)\n",
            "  adding: content/output/inequality_timestep_028.png (deflated 20%)\n",
            "  adding: content/output/inequality_timestep_086.png (deflated 20%)\n",
            "  adding: content/output/inequality_timestep_025.png (deflated 20%)\n",
            "  adding: content/output/per_shell_timestep_002.png (deflated 23%)\n",
            "  adding: content/output/per_shell_timestep_004.png (deflated 23%)\n",
            "  adding: content/output/per_shell_timestep_013.png (deflated 22%)\n",
            "  adding: content/output/per_shell_timestep_077.png (deflated 23%)\n",
            "  adding: content/output/per_shell_timestep_051.png (deflated 22%)\n",
            "  adding: content/output/certificate_timestep_015.lean (deflated 31%)\n",
            "  adding: content/output/inequality_timestep_094.png (deflated 21%)\n",
            "  adding: content/output/per_shell_timestep_050.png (deflated 23%)\n",
            "  adding: content/output/diagnostics_log_timestep_047.json (deflated 67%)\n",
            "  adding: content/output/certificate_timestep_023.lean (deflated 32%)\n",
            "  adding: content/output/certificate_timestep_097.lean (deflated 32%)\n",
            "  adding: content/output/per_shell_timestep_025.png (deflated 23%)\n",
            "  adding: content/output/diagnostics_log_timestep_037.json (deflated 67%)\n",
            "  adding: content/output/certificate_timestep_094.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_076.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_095.png (deflated 22%)\n",
            "  adding: content/output/certificate_timestep_020.lean (deflated 31%)\n",
            "  adding: content/output/lean_validation_summary.csv (deflated 78%)\n",
            "  adding: content/output/per_shell_timestep_092.png (deflated 23%)\n",
            "  adding: content/output/per_shell_timestep_006.png (deflated 24%)\n",
            "  adding: content/output/certificate_timestep_080.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_001.json (deflated 67%)\n",
            "  adding: content/output/per_shell_timestep_032.png (deflated 22%)\n",
            "  adding: content/output/diagnostics_log_timestep_079.json (deflated 67%)\n",
            "  adding: content/output/per_shell_timestep_034.png (deflated 22%)\n",
            "  adding: content/output/inequality_timestep_056.png (deflated 21%)\n",
            "  adding: content/output/inequality_timestep_026.png (deflated 20%)\n",
            "  adding: content/output/diagnostics_log_timestep_075.json (deflated 67%)\n",
            "  adding: content/output/per_shell_timestep_020.png (deflated 23%)\n",
            "  adding: content/output/per_shell_timestep_065.png (deflated 22%)\n",
            "  adding: content/output/certificate_timestep_083.lean (deflated 31%)\n",
            "  adding: content/output/test_adversarial_combo_run4_4fae59cf96_config.json (deflated 42%)\n",
            "  adding: content/output/diagnostics_log_timestep_069.json (deflated 67%)\n",
            "  adding: content/output/diagnostics_log_timestep_029.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_032.png (deflated 20%)\n",
            "  adding: content/output/certificate_timestep_021.lean (deflated 31%)\n",
            "  adding: content/output/certificate_timestep_070.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_071.json (deflated 67%)\n",
            "  adding: content/output/certificate_timestep_044.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_038.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_046.png (deflated 21%)\n",
            "  adding: content/output/inequality_timestep_002.png (deflated 21%)\n",
            "  adding: content/output/certificate_timestep_071.lean (deflated 31%)\n",
            "  adding: content/output/certificate_timestep_024.lean (deflated 32%)\n",
            "  adding: content/output/counterexample_bundle.zip (stored 0%)\n",
            "  adding: content/output/certificate_timestep_002.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_006.json (deflated 68%)\n",
            "  adding: content/output/inequality_timestep_053.png (deflated 21%)\n",
            "  adding: content/output/certificate_timestep_012.lean (deflated 31%)\n",
            "  adding: content/output/certificate_timestep_038.lean (deflated 31%)\n",
            "  adding: content/output/inequality_timestep_069.png (deflated 21%)\n",
            "  adding: content/output/inequality_timestep_021.png (deflated 19%)\n",
            "  adding: content/output/per_shell_timestep_093.png (deflated 22%)\n",
            "  adding: content/output/certificate_timestep_068.lean (deflated 31%)\n",
            "  adding: content/output/certificate_timestep_088.lean (deflated 31%)\n",
            "  adding: content/output/certificate_timestep_004.lean (deflated 31%)\n",
            "  adding: content/output/certificate_timestep_033.lean (deflated 31%)\n",
            "  adding: content/output/certificate_timestep_096.lean (deflated 31%)\n",
            "  adding: content/output/certificate_timestep_067.lean (deflated 31%)\n",
            "  adding: content/output/inequality_timestep_058.png (deflated 22%)\n",
            "  adding: content/output/diagnostics_log_timestep_039.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_067.png (deflated 21%)\n",
            "  adding: content/output/inequality_timestep_004.png (deflated 20%)\n",
            "  adding: content/output/per_shell_timestep_063.png (deflated 21%)\n",
            "  adding: content/output/per_shell_timestep_096.png (deflated 22%)\n",
            "  adding: content/output/inequality_timestep_048.png (deflated 21%)\n",
            "  adding: content/output/certificate_timestep_043.lean (deflated 32%)\n",
            "  adding: content/output/per_shell_timestep_031.png (deflated 23%)\n",
            "  adding: content/output/inequality_timestep_088.png (deflated 20%)\n",
            "  adding: content/output/per_shell_timestep_068.png (deflated 23%)\n",
            "  adding: content/output/diagnostics_log_timestep_061.json (deflated 67%)\n",
            "  adding: content/output/certificate_timestep_003.lean (deflated 31%)\n",
            "  adding: content/output/certificate_timestep_019.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_074.json (deflated 67%)\n",
            "  adding: content/output/certificate_timestep_031.lean (deflated 32%)\n",
            "  adding: content/output/per_shell_timestep_012.png (deflated 23%)\n",
            "  adding: content/output/certificate_timestep_011.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_010.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_072.png (deflated 21%)\n",
            "  adding: content/output/diagnostics_log_timestep_042.json (deflated 67%)\n",
            "  adding: content/output/per_shell_timestep_052.png (deflated 22%)\n",
            "  adding: content/output/inequality_timestep_037.png (deflated 21%)\n",
            "  adding: content/output/per_shell_timestep_081.png (deflated 22%)\n",
            "  adding: content/output/diagnostics_log_timestep_099.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_027.png (deflated 21%)\n",
            "  adding: content/output/inequality_timestep_043.png (deflated 21%)\n",
            "  adding: content/output/inequality_timestep_018.png (deflated 21%)\n",
            "  adding: content/output/per_shell_timestep_024.png (deflated 23%)\n",
            "  adding: content/output/per_shell_timestep_058.png (deflated 22%)\n",
            "  adding: content/output/per_shell_timestep_098.png (deflated 23%)\n",
            "  adding: content/output/inequality_timestep_031.png (deflated 20%)\n",
            "  adding: content/output/per_shell_timestep_018.png (deflated 23%)\n",
            "  adding: content/output/diagnostics_log_timestep_018.json (deflated 67%)\n",
            "  adding: content/output/diagnostics_log_timestep_012.json (deflated 68%)\n",
            "  adding: content/output/inequality_timestep_010.png (deflated 20%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r navier_stokes_proof_full_output.zip /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYv23UdfgUpy",
        "outputId": "b331d97f-a919-4a52-f50f-5656ac5c00e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/ (stored 0%)\n",
            "  adding: content/.config/ (stored 0%)\n",
            "  adding: content/.config/default_configs.db (deflated 98%)\n",
            "  adding: content/.config/.last_update_check.json (deflated 22%)\n",
            "  adding: content/.config/.last_survey_prompt.yaml (stored 0%)\n",
            "  adding: content/.config/config_sentinel (stored 0%)\n",
            "  adding: content/.config/gce (stored 0%)\n",
            "  adding: content/.config/.last_opt_in_prompt.yaml (stored 0%)\n",
            "  adding: content/.config/configurations/ (stored 0%)\n",
            "  adding: content/.config/configurations/config_default (deflated 15%)\n",
            "  adding: content/.config/hidden_gcloud_config_universe_descriptor_data_cache_configs.db (deflated 97%)\n",
            "  adding: content/.config/logs/ (stored 0%)\n",
            "  adding: content/.config/logs/2025.03.05/ (stored 0%)\n",
            "  adding: content/.config/logs/2025.03.05/14.26.32.612701.log (deflated 58%)\n",
            "  adding: content/.config/logs/2025.03.05/14.26.41.012425.log (deflated 57%)\n",
            "  adding: content/.config/logs/2025.03.05/14.26.30.965194.log (deflated 86%)\n",
            "  adding: content/.config/logs/2025.03.05/14.26.22.754300.log (deflated 58%)\n",
            "  adding: content/.config/logs/2025.03.05/14.26.00.059844.log (deflated 92%)\n",
            "  adding: content/.config/logs/2025.03.05/14.26.41.645539.log (deflated 56%)\n",
            "  adding: content/.config/active_config (stored 0%)\n",
            "  adding: content/navier_stokes_proof_output.zip (stored 0%)\n",
            "  adding: content/omega_t_config.json (deflated 34%)\n",
            "  adding: content/proof_colab.py (deflated 77%)\n",
            "  adding: content/omega_tpdt.npy (deflated 4%)\n",
            "  adding: content/proof_falsifier_engine.py (deflated 68%)\n",
            "  adding: content/certificate_packager.py (deflated 70%)\n",
            "  adding: content/omega_t_tpdt.npy (deflated 4%)\n",
            "  adding: content/generate_random_fields.py (deflated 66%)\n",
            "  adding: content/output/ (stored 0%)\n",
            "  adding: content/output/inequality_timestep_081.png (deflated 20%)\n",
            "  adding: content/output/diagnostics_log_timestep_094.json (deflated 67%)\n",
            "  adding: content/output/certificate_timestep_051.lean (deflated 31%)\n",
            "  adding: content/output/inequality_timestep_093.png (deflated 20%)\n",
            "  adding: content/output/certificate_timestep_099.lean (deflated 31%)\n",
            "  adding: content/output/inequality_timestep_008.png (deflated 20%)\n",
            "  adding: content/output/per_shell_timestep_028.png (deflated 23%)\n",
            "  adding: content/output/diagnostics_log_timestep_081.json (deflated 67%)\n",
            "  adding: content/output/diagnostics_log_timestep_044.json (deflated 67%)\n",
            "  adding: content/output/certificate_timestep_048.lean (deflated 32%)\n",
            "  adding: content/output/diagnostics_log_timestep_051.json (deflated 67%)\n",
            "  adding: content/output/diagnostics_log_timestep_033.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_015.png (deflated 21%)\n",
            "  adding: content/output/certificate_timestep_072.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_063.json (deflated 67%)\n",
            "  adding: content/output/certificate_timestep_073.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_041.json (deflated 68%)\n",
            "  adding: content/output/inequality_timestep_076.png (deflated 21%)\n",
            "  adding: content/output/certificate_timestep_017.lean (deflated 31%)\n",
            "  adding: content/output/per_shell_timestep_039.png (deflated 22%)\n",
            "  adding: content/output/certificate_timestep_064.lean (deflated 31%)\n",
            "  adding: content/output/inequality_timestep_024.png (deflated 20%)\n",
            "  adding: content/output/inequality_timestep_052.png (deflated 21%)\n",
            "  adding: content/output/diagnostics_log_timestep_043.json (deflated 67%)\n",
            "  adding: content/output/certificate_timestep_030.lean (deflated 31%)\n",
            "  adding: content/output/per_shell_timestep_069.png (deflated 22%)\n",
            "  adding: content/output/inequality_timestep_073.png (deflated 21%)\n",
            "  adding: content/output/inequality_timestep_070.png (deflated 20%)\n",
            "  adding: content/output/certificate_timestep_045.lean (deflated 31%)\n",
            "  adding: content/output/inequality_timestep_000.png (deflated 20%)\n",
            "  adding: content/output/per_shell_timestep_074.png (deflated 23%)\n",
            "  adding: content/output/test_shell_j5_run2_47a2d52362_config.json (deflated 40%)\n",
            "  adding: content/output/inequality_timestep_038.png (deflated 21%)\n",
            "  adding: content/output/per_shell_timestep_097.png (deflated 22%)\n",
            "  adding: content/output/diagnostics_log_timestep_008.json (deflated 68%)\n",
            "  adding: content/output/per_shell_timestep_085.png (deflated 23%)\n",
            "  adding: content/output/per_shell_timestep_062.png (deflated 22%)\n",
            "  adding: content/output/diagnostics_log_timestep_053.json (deflated 67%)\n",
            "  adding: content/output/diagnostics_log_timestep_083.json (deflated 67%)\n",
            "  adding: content/output/per_shell_timestep_084.png (deflated 22%)\n",
            "  adding: content/output/diagnostics_log_timestep_022.json (deflated 68%)\n",
            "  adding: content/output/inequality_timestep_098.png (deflated 21%)\n",
            "  adding: content/output/per_shell_timestep_035.png (deflated 22%)\n",
            "  adding: content/output/diagnostics_log_timestep_048.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_092.png (deflated 22%)\n",
            "  adding: content/output/inequality_timestep_096.png (deflated 20%)\n",
            "  adding: content/output/inequality_timestep_097.png (deflated 21%)\n",
            "  adding: content/output/per_shell_timestep_054.png (deflated 21%)\n",
            "  adding: content/output/per_shell_timestep_008.png (deflated 24%)\n",
            "  adding: content/output/certificate_timestep_005.lean (deflated 31%)\n",
            "  adding: content/output/per_shell_timestep_005.png (deflated 24%)\n",
            "  adding: content/output/diagnostics_log_timestep_040.json (deflated 67%)\n",
            "  adding: content/output/diagnostics_log_timestep_019.json (deflated 67%)\n",
            "  adding: content/output/per_shell_timestep_066.png (deflated 23%)\n",
            "  adding: content/output/per_shell_timestep_015.png (deflated 23%)\n",
            "  adding: content/output/inequality_timestep_075.png (deflated 21%)\n",
            "  adding: content/output/diagnostics_log_timestep_060.json (deflated 67%)\n",
            "  adding: content/output/certificate_timestep_026.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_050.json (deflated 67%)\n",
            "  adding: content/output/per_shell_timestep_026.png (deflated 23%)\n",
            "  adding: content/output/certificate_timestep_061.lean (deflated 32%)\n",
            "  adding: content/output/certificate_timestep_047.lean (deflated 32%)\n",
            "  adding: content/output/counterexamples/ (stored 0%)\n",
            "  adding: content/output/counterexamples/test_shell_j3_run1_ec23a7ff2c/ (stored 0%)\n",
            "  adding: content/output/counterexamples/test_shell_j3_run1_ec23a7ff2c/test_shell_j3_run1_ec23a7ff2c_omega_tpdt.npy (deflated 4%)\n",
            "  adding: content/output/counterexamples/test_shell_j3_run1_ec23a7ff2c/test_shell_j3_run1_ec23a7ff2c_omega_t.npy (deflated 8%)\n",
            "  adding: content/output/counterexamples/test_shell_j3_run1_ec23a7ff2c/test_shell_j3_run1_ec23a7ff2c_proof_stdout.txt (stored 0%)\n",
            "  adding: content/output/counterexamples/test_shell_j3_run1_ec23a7ff2c/test_shell_j3_run1_ec23a7ff2c_config.json (deflated 40%)\n",
            "  adding: content/output/counterexamples/test_shell_j3_run1_ec23a7ff2c/test_shell_j3_run1_ec23a7ff2c_proof_stderr.txt (deflated 46%)\n",
            "  adding: content/output/counterexamples/lean_validator_metadata.json (deflated 9%)\n",
            "  adding: content/output/counterexamples/test_random_noise_run5_cda5c21d99/ (stored 0%)\n",
            "  adding: content/output/counterexamples/test_random_noise_run5_cda5c21d99/test_random_noise_run5_cda5c21d99_omega_t.npy (deflated 7%)\n",
            "  adding: content/output/counterexamples/test_random_noise_run5_cda5c21d99/test_random_noise_run5_cda5c21d99_proof_stderr.txt (deflated 46%)\n",
            "  adding: content/output/counterexamples/test_random_noise_run5_cda5c21d99/test_random_noise_run5_cda5c21d99_config.json (deflated 42%)\n",
            "  adding: content/output/counterexamples/test_random_noise_run5_cda5c21d99/test_random_noise_run5_cda5c21d99_omega_tpdt.npy (deflated 4%)\n",
            "  adding: content/output/counterexamples/test_random_noise_run5_cda5c21d99/test_random_noise_run5_cda5c21d99_proof_stdout.txt (stored 0%)\n",
            "  adding: content/output/counterexamples/test_shell_j5_run2_47a2d52362/ (stored 0%)\n",
            "  adding: content/output/counterexamples/test_shell_j5_run2_47a2d52362/test_shell_j5_run2_47a2d52362_config.json (deflated 40%)\n",
            "  adding: content/output/counterexamples/test_shell_j5_run2_47a2d52362/test_shell_j5_run2_47a2d52362_proof_stdout.txt (stored 0%)\n",
            "  adding: content/output/counterexamples/test_shell_j5_run2_47a2d52362/test_shell_j5_run2_47a2d52362_omega_tpdt.npy (deflated 4%)\n",
            "  adding: content/output/counterexamples/test_shell_j5_run2_47a2d52362/test_shell_j5_run2_47a2d52362_omega_t.npy (deflated 7%)\n",
            "  adding: content/output/counterexamples/test_shell_j5_run2_47a2d52362/test_shell_j5_run2_47a2d52362_proof_stderr.txt (deflated 45%)\n",
            "  adding: content/output/counterexamples/test_aligned_blowup_run3_296c65368f/ (stored 0%)\n",
            "  adding: content/output/counterexamples/test_aligned_blowup_run3_296c65368f/test_aligned_blowup_run3_296c65368f_omega_t.npy (deflated 78%)\n",
            "  adding: content/output/counterexamples/test_aligned_blowup_run3_296c65368f/test_aligned_blowup_run3_296c65368f_proof_stdout.txt (stored 0%)\n",
            "  adding: content/output/counterexamples/test_aligned_blowup_run3_296c65368f/test_aligned_blowup_run3_296c65368f_proof_stderr.txt (deflated 46%)\n",
            "  adding: content/output/counterexamples/test_aligned_blowup_run3_296c65368f/test_aligned_blowup_run3_296c65368f_config.json (deflated 40%)\n",
            "  adding: content/output/counterexamples/test_aligned_blowup_run3_296c65368f/test_aligned_blowup_run3_296c65368f_omega_tpdt.npy (deflated 4%)\n",
            "  adding: content/output/counterexamples/lean_validation_report.md (deflated 34%)\n",
            "  adding: content/output/counterexamples/test_adversarial_combo_run4_4fae59cf96/ (stored 0%)\n",
            "  adding: content/output/counterexamples/test_adversarial_combo_run4_4fae59cf96/test_adversarial_combo_run4_4fae59cf96_proof_stderr.txt (deflated 46%)\n",
            "  adding: content/output/counterexamples/test_adversarial_combo_run4_4fae59cf96/test_adversarial_combo_run4_4fae59cf96_omega_tpdt.npy (deflated 3%)\n",
            "  adding: content/output/counterexamples/test_adversarial_combo_run4_4fae59cf96/test_adversarial_combo_run4_4fae59cf96_proof_stdout.txt (stored 0%)\n",
            "  adding: content/output/counterexamples/test_adversarial_combo_run4_4fae59cf96/test_adversarial_combo_run4_4fae59cf96_omega_t.npy (deflated 7%)\n",
            "  adding: content/output/counterexamples/test_adversarial_combo_run4_4fae59cf96/test_adversarial_combo_run4_4fae59cf96_config.json (deflated 42%)\n",
            "  adding: content/output/counterexamples/lean_validation_summary.csv (deflated 38%)\n",
            "  adding: content/output/per_shell_timestep_088.png (deflated 23%)\n",
            "  adding: content/output/diagnostics_log_timestep_088.json (deflated 67%)\n",
            "  adding: content/output/per_shell_timestep_073.png (deflated 22%)\n",
            "  adding: content/output/inequality_timestep_091.png (deflated 20%)\n",
            "  adding: content/output/diagnostics_log_timestep_096.json (deflated 67%)\n",
            "  adding: content/output/diagnostics_log_timestep_002.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_084.png (deflated 21%)\n",
            "  adding: content/output/inequality_timestep_035.png (deflated 20%)\n",
            "  adding: content/output/diagnostics_log_timestep_072.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_074.png (deflated 21%)\n",
            "  adding: content/output/per_shell_timestep_080.png (deflated 23%)\n",
            "  adding: content/output/per_shell_timestep_044.png (deflated 22%)\n",
            "  adding: content/output/certificate_timestep_029.lean (deflated 32%)\n",
            "  adding: content/output/diagnostics_log_timestep_080.json (deflated 67%)\n",
            "  adding: content/output/per_shell_timestep_037.png (deflated 21%)\n",
            "  adding: content/output/diagnostics_log_timestep_055.json (deflated 67%)\n",
            "  adding: content/output/certificate_timestep_079.lean (deflated 31%)\n",
            "  adding: content/output/per_shell_timestep_040.png (deflated 22%)\n",
            "  adding: content/output/per_shell_timestep_071.png (deflated 23%)\n",
            "  adding: content/output/certificate_timestep_007.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_mainrun.json (deflated 66%)\n",
            "  adding: content/output/diagnostics_log_timestep_021.json (deflated 68%)\n",
            "  adding: content/output/inequality_timestep_065.png (deflated 21%)\n",
            "  adding: content/output/diagnostics_log_timestep_054.json (deflated 67%)\n",
            "  adding: content/output/per_shell_timestep_095.png (deflated 22%)\n",
            "  adding: content/output/inequality_timestep_014.png (deflated 21%)\n",
            "  adding: content/output/certificate_timestep_039.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_time_reverse_t0.json (deflated 65%)\n",
            "  adding: content/output/per_shell_timestep_076.png (deflated 23%)\n",
            "  adding: content/output/certificate_timestep_016.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_073.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_044.png (deflated 21%)\n",
            "  adding: content/output/per_shell_timestep_079.png (deflated 22%)\n",
            "  adding: content/output/per_shell_timestep_055.png (deflated 22%)\n",
            "  adding: content/output/per_shell_timestep_061.png (deflated 22%)\n",
            "  adding: content/output/diagnostics_log_timestep_093.json (deflated 67%)\n",
            "  adding: content/output/certificate_timestep_078.lean (deflated 31%)\n",
            "  adding: content/output/per_shell_timestep_082.png (deflated 22%)\n",
            "  adding: content/output/diagnostics_log_timestep_024.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_059.png (deflated 22%)\n",
            "  adding: content/output/diagnostics_log_timestep_034.json (deflated 67%)\n",
            "  adding: content/output/diagnostics_log_timestep_058.json (deflated 67%)\n",
            "  adding: content/output/certificate_timestep_065.lean (deflated 31%)\n",
            "  adding: content/output/per_shell_timestep_010.png (deflated 24%)\n",
            "  adding: content/output/inequality_timestep_087.png (deflated 21%)\n",
            "  adding: content/output/certificate_timestep_034.lean (deflated 31%)\n",
            "  adding: content/output/certificate_timestep_098.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_046.json (deflated 67%)\n",
            "  adding: content/output/certificate_timestep_085.lean (deflated 31%)\n",
            "  adding: content/output/per_shell_timestep_056.png (deflated 22%)\n",
            "  adding: content/output/certificate_timestep_025.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_070.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_099.png (deflated 21%)\n",
            "  adding: content/output/inequality_timestep_050.png (deflated 20%)\n",
            "  adding: content/output/certificate_timestep_001.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_091.json (deflated 67%)\n",
            "  adding: content/output/per_shell_timestep_072.png (deflated 22%)\n",
            "  adding: content/output/certificate_timestep_036.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_005.json (deflated 68%)\n",
            "  adding: content/output/diagnostics_log_timestep_052.json (deflated 67%)\n",
            "  adding: content/output/diagnostics_log_timestep_086.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_054.png (deflated 21%)\n",
            "  adding: content/output/certificate_timestep_014.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_011.json (deflated 68%)\n",
            "  adding: content/output/diagnostics_log_timestep_026.json (deflated 68%)\n",
            "  adding: content/output/certificate_timestep_037.lean (deflated 32%)\n",
            "  adding: content/output/inequality_timestep_034.png (deflated 20%)\n",
            "  adding: content/output/diagnostics_log_timestep_077.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_042.png (deflated 22%)\n",
            "  adding: content/output/per_shell_timestep_021.png (deflated 23%)\n",
            "  adding: content/output/diagnostics_log_timestep_015.json (deflated 67%)\n",
            "  adding: content/output/diagnostics_log_timestep_031.json (deflated 67%)\n",
            "  adding: content/output/per_shell_timestep_016.png (deflated 23%)\n",
            "  adding: content/output/inequality_timestep_023.png (deflated 19%)\n",
            "  adding: content/output/diagnostics_log_timestep_030.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_061.png (deflated 21%)\n",
            "  adding: content/output/diagnostics_log_timestep_035.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_003.png (deflated 21%)\n",
            "  adding: content/output/inequality_timestep_071.png (deflated 20%)\n",
            "  adding: content/output/certificate_timestep_075.lean (deflated 31%)\n",
            "  adding: content/output/per_shell_timestep_007.png (deflated 26%)\n",
            "  adding: content/output/inequality_timestep_022.png (deflated 20%)\n",
            "  adding: content/output/inequality_timestep_062.png (deflated 21%)\n",
            "  adding: content/output/diagnostics_log_timestep_032.json (deflated 67%)\n",
            "  adding: content/output/diagnostics_log_timestep_036.json (deflated 67%)\n",
            "  adding: content/output/diagnostics_log_timestep_025.json (deflated 68%)\n",
            "  adding: content/output/certificate_timestep_032.lean (deflated 32%)\n",
            "  adding: content/output/diagnostics_log_timestep_066.json (deflated 67%)\n",
            "  adding: content/output/per_shell_timestep_043.png (deflated 23%)\n",
            "  adding: content/output/inequality_timestep_080.png (deflated 21%)\n",
            "  adding: content/output/certificate_timestep_089.lean (deflated 31%)\n",
            "  adding: content/output/per_shell_timestep_048.png (deflated 22%)\n",
            "  adding: content/output/diagnostics_log_timestep_084.json (deflated 67%)\n",
            "  adding: content/output/certificate_timestep_022.lean (deflated 31%)\n",
            "  adding: content/output/per_shell_timestep_089.png (deflated 23%)\n",
            "  adding: content/output/certificate_timestep_069.lean (deflated 31%)\n",
            "  adding: content/output/certificate_timestep_060.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_003.json (deflated 68%)\n",
            "  adding: content/output/certificate_timestep_027.lean (deflated 31%)\n",
            "  adding: content/output/per_shell_timestep_003.png (deflated 25%)\n",
            "  adding: content/output/certificate_timestep_056.lean (deflated 31%)\n",
            "  adding: content/output/per_shell_timestep_094.png (deflated 23%)\n",
            "  adding: content/output/per_shell_timestep_011.png (deflated 23%)\n",
            "  adding: content/output/diagnostics_log_timestep_059.json (deflated 67%)\n",
            "  adding: content/output/per_shell_timestep_083.png (deflated 23%)\n",
            "  adding: content/output/inequality_timestep_079.png (deflated 20%)\n",
            "  adding: content/output/inequality_timestep_068.png (deflated 21%)\n",
            "  adding: content/output/inequality_timestep_083.png (deflated 21%)\n",
            "  adding: content/output/certificate_timestep_006.lean (deflated 31%)\n",
            "  adding: content/output/certificate_timestep_081.lean (deflated 31%)\n",
            "  adding: content/output/inequality_timestep_066.png (deflated 20%)\n",
            "  adding: content/output/per_shell_timestep_070.png (deflated 22%)\n",
            "  adding: content/output/lean_validator_metadata.json (deflated 92%)\n",
            "  adding: content/output/certificate_timestep_084.lean (deflated 31%)\n",
            "  adding: content/output/certificate_timestep_053.lean (deflated 32%)\n",
            "  adding: content/output/per_shell_timestep_057.png (deflated 22%)\n",
            "  adding: content/output/inequality_timestep_006.png (deflated 20%)\n",
            "  adding: content/output/diagnostics_log_timestep_004.json (deflated 68%)\n",
            "  adding: content/output/inequality_timestep_040.png (deflated 21%)\n",
            "  adding: content/output/certificate_timestep_086.lean (deflated 31%)\n",
            "  adding: content/output/per_shell_timestep_059.png (deflated 22%)\n",
            "  adding: content/output/diagnostics_log_timestep_085.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_085.png (deflated 20%)\n",
            "  adding: content/output/diagnostics_log_timestep_016.json (deflated 68%)\n",
            "  adding: content/output/diagnostics_log_timestep_014.json (deflated 67%)\n",
            "  adding: content/output/certificate_timestep_093.lean (deflated 31%)\n",
            "  adding: content/output/certificate_timestep_054.lean (deflated 32%)\n",
            "  adding: content/output/per_shell_timestep_027.png (deflated 22%)\n",
            "  adding: content/output/inequality_timestep_012.png (deflated 21%)\n",
            "  adding: content/output/certificate_timestep_082.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_087.json (deflated 67%)\n",
            "  adding: content/output/per_shell_timestep_064.png (deflated 23%)\n",
            "  adding: content/output/certificate_timestep_018.lean (deflated 31%)\n",
            "  adding: content/output/certificate_timestep_092.lean (deflated 31%)\n",
            "  adding: content/output/certificate_timestep_095.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_023.json (deflated 68%)\n",
            "  adding: content/output/certificate_timestep_049.lean (deflated 31%)\n",
            "  adding: content/output/per_shell_timestep_001.png (deflated 24%)\n",
            "  adding: content/output/diagnostics_log_timestep_095.json (deflated 67%)\n",
            "  adding: content/output/diagnostics_log_timestep_097.json (deflated 67%)\n",
            "  adding: content/output/diagnostics_log_timestep_068.json (deflated 67%)\n",
            "  adding: content/output/diagnostics_log_timestep_027.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_001.png (deflated 21%)\n",
            "  adding: content/output/per_shell_timestep_042.png (deflated 22%)\n",
            "  adding: content/output/diagnostics_log_timestep_007.json (deflated 68%)\n",
            "  adding: content/output/certificate_timestep_042.lean (deflated 32%)\n",
            "  adding: content/output/certificate_timestep_087.lean (deflated 31%)\n",
            "  adding: content/output/per_shell_timestep_099.png (deflated 22%)\n",
            "  adding: content/output/per_shell_timestep_086.png (deflated 22%)\n",
            "  adding: content/output/certificate_timestep_028.lean (deflated 31%)\n",
            "  adding: content/output/per_shell_timestep_000.png (deflated 23%)\n",
            "  adding: content/output/inequality_timestep_041.png (deflated 21%)\n",
            "  adding: content/output/certificate_timestep_040.lean (deflated 32%)\n",
            "  adding: content/output/inequality_timestep_016.png (deflated 21%)\n",
            "  adding: content/output/diagnostics_log_blowup_test_t0.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_045.png (deflated 21%)\n",
            "  adding: content/output/inequality_timestep_063.png (deflated 21%)\n",
            "  adding: content/output/inequality_timestep_007.png (deflated 20%)\n",
            "  adding: content/output/certificate_timestep_050.lean (deflated 31%)\n",
            "  adding: content/output/test_aligned_blowup_run3_296c65368f_config.json (deflated 40%)\n",
            "  adding: content/output/diagnostics_log_timestep_028.json (deflated 67%)\n",
            "  adding: content/output/per_shell_timestep_090.png (deflated 23%)\n",
            "  adding: content/output/certificate_timestep_000.lean (deflated 31%)\n",
            "  adding: content/output/inequality_timestep_089.png (deflated 21%)\n",
            "  adding: content/output/inequality_timestep_019.png (deflated 20%)\n",
            "  adding: content/output/certificate_timestep_013.lean (deflated 31%)\n",
            "  adding: content/output/certificate_timestep_057.lean (deflated 31%)\n",
            "  adding: content/output/inequality_timestep_057.png (deflated 22%)\n",
            "  adding: content/output/per_shell_timestep_045.png (deflated 21%)\n",
            "  adding: content/output/per_shell_timestep_019.png (deflated 22%)\n",
            "  adding: content/output/certificate_timestep_055.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_065.json (deflated 67%)\n",
            "  adding: content/output/diagnostics_log_timestep_057.json (deflated 67%)\n",
            "  adding: content/output/certificate_timestep_074.lean (deflated 31%)\n",
            "  adding: content/output/inequality_timestep_029.png (deflated 19%)\n",
            "  adding: content/output/diagnostics_log_timestep_045.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_017.png (deflated 22%)\n",
            "  adding: content/output/per_shell_timestep_029.png (deflated 24%)\n",
            "  adding: content/output/inequality_timestep_064.png (deflated 21%)\n",
            "  adding: content/output/inequality_timestep_020.png (deflated 19%)\n",
            "  adding: content/output/diagnostics_log_timestep_082.json (deflated 67%)\n",
            "  adding: content/output/certificate_timestep_035.lean (deflated 31%)\n",
            "  adding: content/output/inequality_timestep_039.png (deflated 21%)\n",
            "  adding: content/output/certificate_timestep_066.lean (deflated 31%)\n",
            "  adding: content/output/per_shell_timestep_091.png (deflated 23%)\n",
            "  adding: content/output/per_shell_timestep_060.png (deflated 22%)\n",
            "  adding: content/output/inequality_timestep_090.png (deflated 21%)\n",
            "  adding: content/output/inequality_timestep_049.png (deflated 21%)\n",
            "  adding: content/output/diagnostics_log_timestep_078.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_055.png (deflated 21%)\n",
            "  adding: content/output/per_shell_timestep_009.png (deflated 23%)\n",
            "  adding: content/output/inequality_timestep_033.png (deflated 19%)\n",
            "  adding: content/output/diagnostics_log_timestep_020.json (deflated 68%)\n",
            "  adding: content/output/inequality_timestep_011.png (deflated 20%)\n",
            "  adding: content/output/inequality_timestep_060.png (deflated 22%)\n",
            "  adding: content/output/certificate_timestep_010.lean (deflated 31%)\n",
            "  adding: content/output/per_shell_timestep_030.png (deflated 23%)\n",
            "  adding: content/output/diagnostics_log_timestep_017.json (deflated 68%)\n",
            "  adding: content/output/certificate_timestep_091.lean (deflated 31%)\n",
            "  adding: content/output/per_shell_timestep_047.png (deflated 22%)\n",
            "  adding: content/output/diagnostics_log_timestep_062.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_051.png (deflated 20%)\n",
            "  adding: content/output/per_shell_timestep_033.png (deflated 22%)\n",
            "  adding: content/output/diagnostics_log_timestep_064.json (deflated 67%)\n",
            "  adding: content/output/per_shell_timestep_022.png (deflated 23%)\n",
            "  adding: content/output/diagnostics_log_timestep_000.json (deflated 68%)\n",
            "  adding: content/output/per_shell_timestep_075.png (deflated 23%)\n",
            "  adding: content/output/per_shell_timestep_067.png (deflated 23%)\n",
            "  adding: content/output/diagnostics_log_timestep_092.json (deflated 67%)\n",
            "  adding: content/output/lean_validation_report.md (deflated 95%)\n",
            "  adding: content/output/certificate_timestep_059.lean (deflated 32%)\n",
            "  adding: content/output/per_shell_timestep_078.png (deflated 23%)\n",
            "  adding: content/output/inequality_timestep_030.png (deflated 19%)\n",
            "  adding: content/output/diagnostics_log_timestep_067.json (deflated 67%)\n",
            "  adding: content/output/diagnostics_log_timestep_089.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_005.png (deflated 20%)\n",
            "  adding: content/output/per_shell_timestep_038.png (deflated 22%)\n",
            "  adding: content/output/certificate_timestep_063.lean (deflated 31%)\n",
            "  adding: content/output/certificate_timestep_077.lean (deflated 31%)\n",
            "  adding: content/output/per_shell_timestep_014.png (deflated 23%)\n",
            "  adding: content/output/per_shell_timestep_017.png (deflated 23%)\n",
            "  adding: content/output/test_random_noise_run5_cda5c21d99_config.json (deflated 42%)\n",
            "  adding: content/output/test_shell_j3_run1_ec23a7ff2c_config.json (deflated 40%)\n",
            "  adding: content/output/certificate_timestep_090.lean (deflated 31%)\n",
            "  adding: content/output/inequality_timestep_036.png (deflated 20%)\n",
            "  adding: content/output/inequality_timestep_047.png (deflated 21%)\n",
            "  adding: content/output/inequality_timestep_013.png (deflated 21%)\n",
            "  adding: content/output/inequality_timestep_077.png (deflated 21%)\n",
            "  adding: content/output/certificate_timestep_046.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_098.json (deflated 67%)\n",
            "  adding: content/output/certificate_timestep_062.lean (deflated 31%)\n",
            "  adding: content/output/inequality_timestep_009.png (deflated 20%)\n",
            "  adding: content/output/per_shell_timestep_049.png (deflated 22%)\n",
            "  adding: content/output/inequality_timestep_078.png (deflated 21%)\n",
            "  adding: content/output/per_shell_timestep_041.png (deflated 22%)\n",
            "  adding: content/output/per_shell_timestep_046.png (deflated 22%)\n",
            "  adding: content/output/diagnostics_log_timestep_056.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_082.png (deflated 20%)\n",
            "  adding: content/output/per_shell_timestep_053.png (deflated 22%)\n",
            "  adding: content/output/diagnostics_log_timestep_013.json (deflated 68%)\n",
            "  adding: content/output/per_shell_timestep_087.png (deflated 23%)\n",
            "  adding: content/output/per_shell_timestep_023.png (deflated 23%)\n",
            "  adding: content/output/certificate_timestep_058.lean (deflated 31%)\n",
            "  adding: content/output/certificate_timestep_008.lean (deflated 31%)\n",
            "  adding: content/output/certificate_timestep_076.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_049.json (deflated 67%)\n",
            "  adding: content/output/diagnostics_log_timestep_009.json (deflated 68%)\n",
            "  adding: content/output/certificate_timestep_052.lean (deflated 31%)\n",
            "  adding: content/output/certificate_timestep_041.lean (deflated 32%)\n",
            "  adding: content/output/diagnostics_log_timestep_090.json (deflated 67%)\n",
            "  adding: content/output/certificate_timestep_009.lean (deflated 31%)\n",
            "  adding: content/output/per_shell_timestep_036.png (deflated 22%)\n",
            "  adding: content/output/inequality_timestep_028.png (deflated 20%)\n",
            "  adding: content/output/inequality_timestep_086.png (deflated 20%)\n",
            "  adding: content/output/inequality_timestep_025.png (deflated 20%)\n",
            "  adding: content/output/per_shell_timestep_002.png (deflated 23%)\n",
            "  adding: content/output/per_shell_timestep_004.png (deflated 23%)\n",
            "  adding: content/output/per_shell_timestep_013.png (deflated 22%)\n",
            "  adding: content/output/per_shell_timestep_077.png (deflated 23%)\n",
            "  adding: content/output/per_shell_timestep_051.png (deflated 22%)\n",
            "  adding: content/output/certificate_timestep_015.lean (deflated 31%)\n",
            "  adding: content/output/inequality_timestep_094.png (deflated 21%)\n",
            "  adding: content/output/per_shell_timestep_050.png (deflated 23%)\n",
            "  adding: content/output/diagnostics_log_timestep_047.json (deflated 67%)\n",
            "  adding: content/output/certificate_timestep_023.lean (deflated 32%)\n",
            "  adding: content/output/certificate_timestep_097.lean (deflated 32%)\n",
            "  adding: content/output/per_shell_timestep_025.png (deflated 23%)\n",
            "  adding: content/output/diagnostics_log_timestep_037.json (deflated 67%)\n",
            "  adding: content/output/certificate_timestep_094.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_076.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_095.png (deflated 22%)\n",
            "  adding: content/output/certificate_timestep_020.lean (deflated 31%)\n",
            "  adding: content/output/lean_validation_summary.csv (deflated 78%)\n",
            "  adding: content/output/per_shell_timestep_092.png (deflated 23%)\n",
            "  adding: content/output/per_shell_timestep_006.png (deflated 24%)\n",
            "  adding: content/output/certificate_timestep_080.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_001.json (deflated 67%)\n",
            "  adding: content/output/per_shell_timestep_032.png (deflated 22%)\n",
            "  adding: content/output/diagnostics_log_timestep_079.json (deflated 67%)\n",
            "  adding: content/output/per_shell_timestep_034.png (deflated 22%)\n",
            "  adding: content/output/inequality_timestep_056.png (deflated 21%)\n",
            "  adding: content/output/inequality_timestep_026.png (deflated 20%)\n",
            "  adding: content/output/diagnostics_log_timestep_075.json (deflated 67%)\n",
            "  adding: content/output/per_shell_timestep_020.png (deflated 23%)\n",
            "  adding: content/output/per_shell_timestep_065.png (deflated 22%)\n",
            "  adding: content/output/certificate_timestep_083.lean (deflated 31%)\n",
            "  adding: content/output/test_adversarial_combo_run4_4fae59cf96_config.json (deflated 42%)\n",
            "  adding: content/output/diagnostics_log_timestep_069.json (deflated 67%)\n",
            "  adding: content/output/diagnostics_log_timestep_029.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_032.png (deflated 20%)\n",
            "  adding: content/output/certificate_timestep_021.lean (deflated 31%)\n",
            "  adding: content/output/certificate_timestep_070.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_071.json (deflated 67%)\n",
            "  adding: content/output/certificate_timestep_044.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_038.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_046.png (deflated 21%)\n",
            "  adding: content/output/inequality_timestep_002.png (deflated 21%)\n",
            "  adding: content/output/certificate_timestep_071.lean (deflated 31%)\n",
            "  adding: content/output/certificate_timestep_024.lean (deflated 32%)\n",
            "  adding: content/output/counterexample_bundle.zip (stored 0%)\n",
            "  adding: content/output/certificate_timestep_002.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_006.json (deflated 68%)\n",
            "  adding: content/output/inequality_timestep_053.png (deflated 21%)\n",
            "  adding: content/output/certificate_timestep_012.lean (deflated 31%)\n",
            "  adding: content/output/certificate_timestep_038.lean (deflated 31%)\n",
            "  adding: content/output/inequality_timestep_069.png (deflated 21%)\n",
            "  adding: content/output/inequality_timestep_021.png (deflated 19%)\n",
            "  adding: content/output/per_shell_timestep_093.png (deflated 22%)\n",
            "  adding: content/output/certificate_timestep_068.lean (deflated 31%)\n",
            "  adding: content/output/certificate_timestep_088.lean (deflated 31%)\n",
            "  adding: content/output/certificate_timestep_004.lean (deflated 31%)\n",
            "  adding: content/output/certificate_timestep_033.lean (deflated 31%)\n",
            "  adding: content/output/certificate_timestep_096.lean (deflated 31%)\n",
            "  adding: content/output/certificate_timestep_067.lean (deflated 31%)\n",
            "  adding: content/output/inequality_timestep_058.png (deflated 22%)\n",
            "  adding: content/output/diagnostics_log_timestep_039.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_067.png (deflated 21%)\n",
            "  adding: content/output/inequality_timestep_004.png (deflated 20%)\n",
            "  adding: content/output/per_shell_timestep_063.png (deflated 21%)\n",
            "  adding: content/output/per_shell_timestep_096.png (deflated 22%)\n",
            "  adding: content/output/inequality_timestep_048.png (deflated 21%)\n",
            "  adding: content/output/certificate_timestep_043.lean (deflated 32%)\n",
            "  adding: content/output/per_shell_timestep_031.png (deflated 23%)\n",
            "  adding: content/output/inequality_timestep_088.png (deflated 20%)\n",
            "  adding: content/output/per_shell_timestep_068.png (deflated 23%)\n",
            "  adding: content/output/diagnostics_log_timestep_061.json (deflated 67%)\n",
            "  adding: content/output/certificate_timestep_003.lean (deflated 31%)\n",
            "  adding: content/output/certificate_timestep_019.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_074.json (deflated 67%)\n",
            "  adding: content/output/certificate_timestep_031.lean (deflated 32%)\n",
            "  adding: content/output/per_shell_timestep_012.png (deflated 23%)\n",
            "  adding: content/output/certificate_timestep_011.lean (deflated 31%)\n",
            "  adding: content/output/diagnostics_log_timestep_010.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_072.png (deflated 21%)\n",
            "  adding: content/output/diagnostics_log_timestep_042.json (deflated 67%)\n",
            "  adding: content/output/per_shell_timestep_052.png (deflated 22%)\n",
            "  adding: content/output/inequality_timestep_037.png (deflated 21%)\n",
            "  adding: content/output/per_shell_timestep_081.png (deflated 22%)\n",
            "  adding: content/output/diagnostics_log_timestep_099.json (deflated 67%)\n",
            "  adding: content/output/inequality_timestep_027.png (deflated 21%)\n",
            "  adding: content/output/inequality_timestep_043.png (deflated 21%)\n",
            "  adding: content/output/inequality_timestep_018.png (deflated 21%)\n",
            "  adding: content/output/per_shell_timestep_024.png (deflated 23%)\n",
            "  adding: content/output/per_shell_timestep_058.png (deflated 22%)\n",
            "  adding: content/output/per_shell_timestep_098.png (deflated 23%)\n",
            "  adding: content/output/inequality_timestep_031.png (deflated 20%)\n",
            "  adding: content/output/per_shell_timestep_018.png (deflated 23%)\n",
            "  adding: content/output/diagnostics_log_timestep_018.json (deflated 67%)\n",
            "  adding: content/output/diagnostics_log_timestep_012.json (deflated 68%)\n",
            "  adding: content/output/inequality_timestep_010.png (deflated 20%)\n",
            "  adding: content/omega_t.npy (deflated 7%)\n",
            "  adding: content/recursive_ode_falsifier.py (deflated 66%)\n",
            "  adding: content/omega_t_preview.png (deflated 0%)\n",
            "  adding: content/lean_validator.py (deflated 68%)\n",
            "  adding: content/sample_data/ (stored 0%)\n",
            "  adding: content/sample_data/README.md (deflated 39%)\n",
            "  adding: content/sample_data/anscombe.json (deflated 83%)\n",
            "  adding: content/sample_data/california_housing_test.csv (deflated 76%)\n",
            "  adding: content/sample_data/mnist_test.csv (deflated 88%)\n",
            "  adding: content/sample_data/mnist_train_small.csv (deflated 88%)\n",
            "  adding: content/sample_data/california_housing_train.csv (deflated 79%)\n"
          ]
        }
      ]
    }
  ]
}